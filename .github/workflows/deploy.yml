name: üöÄ Production Deployment - Enterprise Grade

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_DEFAULT_REGION: us-east-1
  STACK_NAME: subscriber-migration-portal-prod
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'
  # Timeouts and retry settings
  CLEANUP_TIMEOUT_MINUTES: 15
  RDS_DELETE_TIMEOUT_MINUTES: 12
  STACK_DELETE_TIMEOUT_MINUTES: 15
  MAX_RETRY_ATTEMPTS: 5

permissions:
  contents: read
  id-token: write # <-- IMPORTANT: Add this for OIDC Security

jobs:
  validate:
    name: üîç Validate Architecture
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install validation tools
        run: |
          set -euo pipefail
          pip install --upgrade pip
          pip install aws-sam-cli boto3 jq
      
      - name: Validate SAM Template
        run: |
          set -euo pipefail
          cd aws
          
          echo "üîç Validating SAM template syntax..."
          if sam validate --template template.yaml --region ${{ env.AWS_DEFAULT_REGION }}; then
            echo "‚úÖ SAM template is valid"
          else
            echo "‚ùå SAM template validation failed"
            exit 1
          fi
      
      - name: Validate Step Functions Definitions
        run: |
          set -euo pipefail
          
          if [ ! -d "aws/stepfunctions" ]; then
            echo "‚ö†Ô∏è No Step Functions directory found, skipping validation"
            exit 0
          fi
          
          echo "üîç Validating Step Functions definitions..."
          
          for file in aws/stepfunctions/*.json; do
            if [[ -f "$file" ]]; then
              filename=$(basename "$file")
              echo "  Validating: $filename"
              
              if ! jq empty "$file" 2>/dev/null; then
                echo "  ‚ùå Invalid JSON in $file"
                exit 1
              fi
              
              if ! jq -e '.StartAt' "$file" >/dev/null 2>&1; then
                echo "  ‚ùå Missing StartAt in $file"
                exit 1
              fi
              
              if ! jq -e '.States' "$file" >/dev/null 2>&1; then
                echo "  ‚ùå Missing States in $file"
                exit 1
              fi
              
              echo "  ‚úÖ Valid: $filename"
            fi
          done
          
          echo "‚úÖ All validations passed"

  discover-infrastructure:
    name: üîç Discover VPC Infrastructure
    runs-on: ubuntu-latest
    needs: validate
    outputs:
      vpc-id: ${{ steps.discover.outputs.vpc_id }}
      private-subnet-1: ${{ steps.discover.outputs.private_subnet_1 }}
      private-subnet-2: ${{ steps.discover.outputs.private_subnet_2 }}
      public-subnet-1: ${{ steps.discover.outputs.public_subnet_1 }}
      public-subnet-2: ${{ steps.discover.outputs.public_subnet_2 }}
    steps:
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          # ‚ö†Ô∏è SECURITY RISK: Replace with OIDC (see notes below)
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
      
      - name: üîç Auto-discover VPC and Subnets with validation
        id: discover
        run: |
          set -euo pipefail
          
          echo "üîç Discovering VPC infrastructure in ${{ env.AWS_DEFAULT_REGION }}..."
          
          # Discover VPC
          VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=is-default,Values=true" \
            --query 'Vpcs[0].VpcId' \
            --output text 2>/dev/null || echo "None")
          
          if [[ "$VPC_ID" == "None" || -z "$VPC_ID" ]]; then
            echo "‚ö†Ô∏è No default VPC found, searching for any available VPC..."
            VPC_ID=$(aws ec2 describe-vpcs \
              --query 'Vpcs[0].VpcId' \
              --output text 2>/dev/null || echo "None")
          fi
          
          if [[ "$VPC_ID" == "None" || -z "$VPC_ID" ]]; then
            echo "‚ùå CRITICAL: No VPC found in region ${{ env.AWS_DEFAULT_REGION }}"
            echo "Please create a VPC or use a different region"
            exit 1
          fi
          
          echo "‚úÖ Found VPC: $VPC_ID"
          
          # Validate VPC state
          VPC_STATE=$(aws ec2 describe-vpcs \
            --vpc-ids "$VPC_ID" \
            --query 'Vpcs[0].State' \
            --output text 2>/dev/null || echo "unknown")
          
          if [[ "$VPC_STATE" != "available" ]]; then
            echo "‚ùå VPC is not in available state: $VPC_STATE"
            exit 1
          fi
          
          # Discover private subnets
          echo "üîç Discovering private subnets..."
          PRIVATE_SUBNETS=($(aws ec2 describe-subnets \
            --filters "Name=vpc-id,Values=$VPC_ID" "Name=map-public-ip-on-launch,Values=false" \
            --query 'Subnets[?State==`available`].SubnetId' \
            --output text || echo ""))
          
          PRIVATE_1=${PRIVATE_SUBNETS[0]:-""}
          PRIVATE_2=${PRIVATE_SUBNETS[1]:-""}
          
          # Discover public subnets
          echo "üîç Discovering public subnets..."
          PUBLIC_SUBNETS=($(aws ec2 describe-subnets \
            --filters "Name=vpc-id,Values=$VPC_ID" "Name=map-public-ip-on-launch,Values=true" \
            --query 'Subnets[?State==`available`].SubnetId' \
            --output text || echo ""))
          
          PUBLIC_1=${PUBLIC_SUBNETS[0]:-""}
          PUBLIC_2=${PUBLIC_SUBNETS[1]:-""}
          
          # Validation
          if [[ -z "$PRIVATE_1" || -z "$PRIVATE_2" ]]; then
            echo "‚ùå CRITICAL: Need at least 2 private subnets in VPC $VPC_ID"
            echo "Found private subnets: ${PRIVATE_SUBNETS[@]:-none}"
            echo ""
            echo "Available subnets in VPC:"
            aws ec2 describe-subnets \
              --filters "Name=vpc-id,Values=$VPC_ID" \
              --query 'Subnets[].[SubnetId,AvailabilityZone,MapPublicIpOnLaunch,State]' \
              --output table
            exit 1
          fi
          
          # Verify subnets are in different AZs
          AZ_1=$(aws ec2 describe-subnets --subnet-ids "$PRIVATE_1" --query 'Subnets[0].AvailabilityZone' --output text)
          AZ_2=$(aws ec2 describe-subnets --subnet-ids "$PRIVATE_2" --query 'Subnets[0].AvailabilityZone' --output text)
          
          if [[ "$AZ_1" == "$AZ_2" ]]; then
            echo "‚ö†Ô∏è WARNING: Both private subnets are in the same AZ ($AZ_1)"
            echo "This may impact high availability"
          fi
          
          echo ""
          echo "‚úÖ Infrastructure discovered and validated:"
          echo "  VPC:              $VPC_ID (state: $VPC_STATE)"
          echo "  Private 1:        $PRIVATE_1 (AZ: $AZ_1)"
          echo "  Private 2:        $PRIVATE_2 (AZ: $AZ_2)"
          echo "  Public 1:         ${PUBLIC_1:-<none>}"
          echo "  Public 2:         ${PUBLIC_2:-<none>}"
          
          # Export outputs
          echo "vpc_id=$VPC_ID" >> $GITHUB_OUTPUT
          echo "private_subnet_1=$PRIVATE_1" >> $GITHUB_OUTPUT
          echo "private_subnet_2=$PRIVATE_2" >> $GITHUB_OUTPUT
          echo "public_subnet_1=$PUBLIC_1" >> $GITHUB_OUTPUT
          echo "public_subnet_2=$PUBLIC_2" >> $GITHUB_OUTPUT

  cleanup-and-deploy:
    name: üèóÔ∏è Deploy Infrastructure
    runs-on: ubuntu-latest
    needs: discover-infrastructure # <-- CRITICAL FIX: Added this dependency
    environment: production
    env:
      STACK_DELETE_TIMEOUT_MINUTES: 15
    outputs:
      api-endpoint: ${{ steps.export-outputs.outputs.api_endpoint }}
      schema-function-name: ${{ steps.export-outputs.outputs.schema_function_name }}
    steps:
      - uses: actions/checkout@v4
      
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          # ‚ö†Ô∏è SECURITY RISK: Replace with OIDC (see notes below)
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
      
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install Tools
        run: pip install aws-sam-cli boto3 jq

      - name: üî• BULLETPROOF SMART CLEANUP - Conditional & Comprehensive
        id: cleanup
        timeout-minutes: 20
        continue-on-error: false
        run: |
          set -euo pipefail
          STACK="${{ env.STACK_NAME }}"
          
          echo "üîç ============================================"
          echo "üîç  STACK HEALTH CHECK & CLEANUP DECISION"
          echo "üîç ============================================"
          echo ""
          
          # ============================================
          # STEP 0: Check Stack Status & Decide
          # ============================================
          
          CLEANUP_NEEDED=false
          STACK_EXISTS=false
          
          if aws cloudformation describe-stacks --stack-name "$STACK" >/dev/null 2>&1; then
            STACK_EXISTS=true
            STATUS=$(aws cloudformation describe-stacks \
              --stack-name "$STACK" \
              --query 'Stacks[0].StackStatus' \
              --output text)
            
            echo "üìä Stack Status: $STATUS"
            echo ""
            
            # Decision Matrix
            case "$STATUS" in
              # ‚úÖ HEALTHY STATES - No cleanup needed
              CREATE_COMPLETE|UPDATE_COMPLETE)
                echo "‚úÖ ============================================"
                echo "‚úÖ  STACK IS HEALTHY"
                echo "‚úÖ ============================================"
                echo ""
                echo "‚ÑπÔ∏è  Action: UPDATE deployment (fast path)"
                echo "‚ÑπÔ∏è  Cleanup: SKIPPED (not needed)"
                echo "‚ÑπÔ∏è  Estimated time: 2-3 minutes"
                echo ""
                CLEANUP_NEEDED=false
                ;;
              
              # ‚ö†Ô∏è ERROR STATES - Cleanup required
              ROLLBACK_COMPLETE|ROLLBACK_FAILED|CREATE_FAILED|DELETE_FAILED|UPDATE_ROLLBACK_COMPLETE|UPDATE_ROLLBACK_FAILED)
                echo "‚ö†Ô∏è ============================================"
                echo "‚ö†Ô∏è  STACK IN ERROR STATE"
                echo "‚ö†Ô∏è ============================================"
                echo ""
                echo "‚ÑπÔ∏è  Action: FULL CLEANUP + FRESH DEPLOY"
                echo "‚ÑπÔ∏è  Cleanup: REQUIRED (error recovery)"
                echo "‚ÑπÔ∏è  Estimated time: 25-30 minutes"
                echo ""
                CLEANUP_NEEDED=true
                ;;
              
              # üîÑ IN-PROGRESS STATES - Wait and update
              CREATE_IN_PROGRESS|UPDATE_IN_PROGRESS)
                echo "‚è≥ ============================================"
                echo "‚è≥  STACK OPERATION IN PROGRESS"
                echo "‚è≥ ============================================"
                echo ""
                echo "‚ÑπÔ∏è  Action: WAIT 60s then UPDATE"
                echo "‚ÑπÔ∏è  Cleanup: SKIPPED"
                sleep 60
                CLEANUP_NEEDED=false
                ;;
              
              # üóëÔ∏è DELETE IN PROGRESS - Wait
              DELETE_IN_PROGRESS)
                echo "üóëÔ∏è ============================================"
                echo "üóëÔ∏è  STACK DELETION IN PROGRESS"
                echo "üóëÔ∏è ============================================"
                echo ""
                echo "‚ÑπÔ∏è  Action: WAIT for deletion to complete"
                echo "‚ÑπÔ∏è  Cleanup: IN PROGRESS"
                sleep 30
                CLEANUP_NEEDED=false
                ;;
              
              # ‚ùì UNKNOWN STATES - Skip cleanup, proceed with caution
              *)
                echo "‚ùì ============================================"
                echo "‚ùì  UNEXPECTED STACK STATUS"
                echo "‚ùì ============================================"
                echo ""
                echo "‚ÑπÔ∏è  Status: $STATUS"
                echo "‚ÑπÔ∏è  Action: PROCEED WITH UPDATE (no cleanup)"
                echo "‚ÑπÔ∏è  Cleanup: SKIPPED"
                CLEANUP_NEEDED=false
                ;;
            esac
          else
            echo "‚ÑπÔ∏è ============================================"
            echo "‚ÑπÔ∏è  NO EXISTING STACK FOUND"
            echo "‚ÑπÔ∏è ============================================"
            echo ""
            echo "‚ÑπÔ∏è  Action: CREATE NEW STACK"
            echo "‚ÑπÔ∏è  Cleanup: SKIPPED (nothing to clean)"
            STACK_EXISTS=false
            CLEANUP_NEEDED=false
          fi
          
          # Export cleanup status
          echo "cleanup_performed=$CLEANUP_NEEDED" >> $GITHUB_OUTPUT
          
          # ============================================
          # EXIT EARLY IF NO CLEANUP NEEDED
          # ============================================
          
          if [[ "$CLEANUP_NEEDED" == "false" ]]; then
            echo ""
            echo "üöÄ ============================================"
            echo "üöÄ  SKIPPING CLEANUP - PROCEEDING TO DEPLOY"
            echo "üöÄ ============================================"
            echo ""
            exit 0
          fi
          
          # ============================================
          # CLEANUP CODE BELOW (Only runs if needed)
          # ============================================
          
          echo ""
          echo "üî• ============================================"
          echo "üî•  COMPREHENSIVE CLEANUP - PRODUCTION GRADE"
          echo "üî• ============================================"
          echo ""
          
          # Function: Retry command with exponential backoff
          retry_command() {
            local max_attempts=$1
            shift
            local command=("$@")
            local attempt=1
            local delay=5
            
            while [ $attempt -le $max_attempts ]; do
              if "${command[@]}" 2>/dev/null; then
                return 0
              fi
              
              if [ $attempt -lt $max_attempts ]; then
                echo "    ‚è≥ Retry $attempt/$max_attempts in ${delay}s..."
                sleep $delay
                delay=$((delay * 2))
              fi
              attempt=$((attempt + 1))
            done
            
            return 1
          }
          
          # ============================================
          # STEP 1: CloudFormation Stack Deletion
          # ============================================
          
          echo "üìä STEP 1: CloudFormation Stack Deletion"
          echo "=============================================="
          
          if [[ "$STACK_EXISTS" == "true" ]]; then
            echo "  üóëÔ∏è Deleting CloudFormation stack..."
            
            if aws cloudformation delete-stack --stack-name "$STACK"; then
              echo "  ‚úÖ Delete initiated"
              
              # Use built-in waiter
              echo "  ‚è≥ Waiting for stack deletion (max ${{ env.STACK_DELETE_TIMEOUT_MINUTES }} min)..."
              if timeout $((${{ env.STACK_DELETE_TIMEOUT_MINUTES }} * 60)) \
                 aws cloudformation wait stack-delete-complete --stack-name "$STACK" 2>/dev/null; then
                echo "  ‚úÖ Stack deleted via CloudFormation"
              else
                echo "  ‚ö†Ô∏è Stack deletion timeout - will clean resources manually"
              fi
            else
              echo "  ‚ö†Ô∏è Stack deletion failed - will clean resources manually"
            fi
          else
            echo "  ‚úÖ No stack to delete"
          fi
          
          # ============================================
          # STEP 2: Resource-Level Cleanup (Parallel)
          # ============================================
          
          echo ""
          echo "üßπ STEP 2: Resource-Level Cleanup"
          echo "=============================================="
          
          # Step 2.1: Lambda ENIs (CRITICAL - must be deleted first)
          echo ""
          echo "üîå [2.1] Lambda Network Interfaces..."
          ENIS=$(aws ec2 describe-network-interfaces \
            --filters "Name=description,Values=*AWS Lambda VPC ENI*" "Name=status,Values=available" \
            --query 'NetworkInterfaces[].NetworkInterfaceId' \
            --output text 2>/dev/null || true)
          
          if [[ -n "$ENIS" ]]; then
            for eni in $ENIS; do
              echo "  üóëÔ∏è Deleting ENI: $eni"
              retry_command 3 aws ec2 delete-network-interface --network-interface-id "$eni" &
            done
            wait
            echo "  ‚úÖ Lambda ENIs cleanup initiated"
          else
            echo "  ‚úÖ No Lambda ENIs found"
          fi
          
          # Step 2.2: RDS Instances (IMPROVED with built-in waiter)
          echo ""
          echo "üóÑÔ∏è [2.2] RDS Database Instances..."
          RDS_INSTANCES=$(aws rds describe-db-instances \
            --query "DBInstances[?contains(DBInstanceIdentifier, '$STACK')].DBInstanceIdentifier" \
            --output text 2>/dev/null || true)
          
          if [[ -n "$RDS_INSTANCES" ]]; then
            for db in $RDS_INSTANCES; do
              DB_STATUS=$(aws rds describe-db-instances \
                --db-instance-identifier "$db" \
                --query 'DBInstances[0].DBInstanceStatus' \
                --output text 2>/dev/null || echo "not-found")
              
              echo "  üìä RDS: $db (status: $DB_STATUS)"
              
              if [[ "$DB_STATUS" == "deleting" ]]; then
                echo "    ‚è≥ Already deleting, waiting..."
                timeout 300 aws rds wait db-instance-deleted --db-instance-identifier "$db" 2>/dev/null || echo "    ‚ö†Ô∏è Timeout, continuing..."
              elif [[ "$DB_STATUS" != "not-found" ]]; then
                echo "    üóëÔ∏è Initiating deletion (skip snapshot)..."
                aws rds delete-db-instance \
                  --db-instance-identifier "$db" \
                  --skip-final-snapshot \
                  --delete-automated-backups 2>/dev/null || true
                
                echo "    ‚è≥ Waiting for deletion (max 5 min)..."
                timeout 300 aws rds wait db-instance-deleted --db-instance-identifier "$db" 2>/dev/null || echo "    ‚ö†Ô∏è Timeout, continuing..."
                echo "    ‚úÖ Deleted or timed out"
              fi
            done
          else
            echo "  ‚úÖ No RDS instances found"
          fi
          
          # Step 2.3: VPC Endpoints
          echo ""
          echo "üîó [2.3] VPC Endpoints..."
          VPCE_COUNT=0
          for vpce in $(aws ec2 describe-vpc-endpoints --query 'VpcEndpoints[].VpcEndpointId' --output text 2>/dev/null || true); do
            TAGS=$(aws ec2 describe-vpc-endpoints \
              --vpc-endpoint-ids "$vpce" \
              --query 'VpcEndpoints[0].Tags[?Key==`aws:cloudformation:stack-name`].Value' \
              --output text 2>/dev/null || true)
            
            if echo "$TAGS" | grep -q "$STACK"; then
              echo "  üóëÔ∏è Deleting VPC Endpoint: $vpce"
              retry_command 3 aws ec2 delete-vpc-endpoints --vpc-endpoint-ids "$vpce" &
              VPCE_COUNT=$((VPCE_COUNT + 1))
            fi
          done
          wait
          
          if [ $VPCE_COUNT -gt 0 ]; then
            echo "  ‚úÖ Deleted $VPCE_COUNT VPC endpoint(s)"
            sleep 15
          else
            echo "  ‚úÖ No VPC endpoints found"
          fi
          
          # Step 2.4: RDS Subnet Groups
          echo ""
          echo "üîß [2.4] RDS Subnet Groups..."
          for attempt in {1..3}; do
            SUBNET_GROUPS=$(aws rds describe-db-subnet-groups \
              --query "DBSubnetGroups[?contains(DBSubnetGroupName, '$STACK')].DBSubnetGroupName" \
              --output text 2>/dev/null || true)
            
            if [[ -z "$SUBNET_GROUPS" ]]; then
              echo "  ‚úÖ No RDS subnet groups found"
              break
            fi
            
            echo "  üîÑ Attempt $attempt/3..."
            for sg in $SUBNET_GROUPS; do
              if aws rds delete-db-subnet-group --db-subnet-group-name "$sg" 2>/dev/null; then
                echo "    ‚úÖ Deleted: $sg"
              else
                echo "    ‚è≠Ô∏è Still in use: $sg"
              fi
            done
            
            [ $attempt -lt 3 ] && sleep 10
          done
          
          # Step 2.5: S3 Buckets
          echo ""
          echo "ü™£ [2.5] S3 Buckets..."
          BUCKETS=$(aws s3api list-buckets \
            --query 'Buckets[].Name' \
            --output text 2>/dev/null | tr '\t' '\n' | grep "$STACK" 2>/dev/null || true)
          
          if [[ -n "$BUCKETS" ]]; then
            for bucket in $BUCKETS; do
              echo "  üóëÔ∏è Emptying bucket: $bucket"
              aws s3 rm "s3://$bucket" --recursive 2>/dev/null || true
              aws s3 rb "s3://$bucket" --force 2>/dev/null || true &
            done
            wait
            echo "  ‚úÖ S3 buckets cleaned"
          else
            echo "  ‚úÖ No S3 buckets found"
          fi
          
          # Step 2.6: Secrets Manager
          echo ""
          echo "üîê [2.6] Secrets Manager..."
          SECRETS=$(aws secretsmanager list-secrets \
            --query 'SecretList[].Name' \
            --output text 2>/dev/null | tr '\t' '\n' | grep "$STACK" 2>/dev/null || true)
          
          if [[ -n "$SECRETS" ]]; then
            for secret in $SECRETS; do
              echo "  üóëÔ∏è Deleting secret: $secret"
              retry_command 3 aws secretsmanager delete-secret \
                --secret-id "$secret" \
                --force-delete-without-recovery &
            done
            wait
            echo "  ‚úÖ Secrets deleted"
          else
            echo "  ‚úÖ No secrets found"
          fi
          
          # Step 2.7: Security Groups
          echo ""
          echo "üõ°Ô∏è [2.7] Security Groups..."
          for attempt in {1..3}; do
            SG_DELETED=0
            echo "  üîÑ Attempt $attempt/3..."
            
            for sg in $(aws ec2 describe-security-groups \
              --query 'SecurityGroups[?GroupName!=`default`].GroupId' \
              --output text 2>/dev/null || true); do
              
              SG_NAME=$(aws ec2 describe-security-groups \
                --group-ids "$sg" \
                --query 'SecurityGroups[0].GroupName' \
                --output text 2>/dev/null || true)
              
              if echo "$SG_NAME" | grep -q "$STACK"; then
                if aws ec2 delete-security-group --group-id "$sg" 2>/dev/null; then
                  echo "    ‚úÖ Deleted: $sg ($SG_NAME)"
                  SG_DELETED=$((SG_DELETED + 1))
                fi
              fi
            done
            
            [ $SG_DELETED -eq 0 ] && break
            [ $attempt -lt 3 ] && sleep 15
          done
          echo "  ‚úÖ Security groups cleanup complete"
          
          # Step 2.8: Lambda Layers
          echo ""
          echo "üì¶ [2.8] Lambda Layers..."
          LAYERS=$(aws lambda list-layers \
            --query 'Layers[].LayerName' \
            --output text 2>/dev/null | tr '\t' '\n' | grep "$STACK" 2>/dev/null || true)
          
          if [[ -n "$LAYERS" ]]; then
            for layer in $LAYERS; do
              echo "  üóëÔ∏è Deleting layer: $layer"
              for version in $(aws lambda list-layer-versions \
                --layer-name "$layer" \
                --query 'LayerVersions[].Version' \
                --output text 2>/dev/null || true); do
                aws lambda delete-layer-version \
                  --layer-name "$layer" \
                  --version-number "$version" 2>/dev/null &
              done
            done
            wait
            echo "  ‚úÖ Lambda layers deleted"
          else
            echo "  ‚úÖ No Lambda layers found"
          fi
          
          # Step 2.9: CloudWatch Logs
          echo ""
          echo "üìù [2.9] CloudWatch Log Groups..."
          for prefix in "/aws/lambda/${STACK}" "/aws/vendedlogs/states/${STACK}"; do
            LOGS=$(aws logs describe-log-groups \
              --log-group-name-prefix "$prefix" \
              --query 'logGroups[].logGroupName' \
              --output text 2>/dev/null || true)
            
            if [[ -n "$LOGS" ]]; then
              for lg in $LOGS; do
                aws logs delete-log-group --log-group-name "$lg" 2>/dev/null &
              done
            fi
          done
          wait
          echo "  ‚úÖ Log groups cleaned"
          
          # ============================================
          # STEP 3: Orphan Resources Cleanup
          # ============================================
          
          echo ""
          echo "üß© STEP 3: Orphan Resources Cleanup"
          echo "=============================================="
          
          # Step 3.1: IAM Roles & Policies (NEW)
          echo ""
          echo "üë§ [3.1] IAM Roles and Policies..."
          ROLES=$(aws iam list-roles \
            --query 'Roles[?contains(RoleName, `'$STACK'`)].RoleName' \
            --output text 2>/dev/null || true)
          
          if [[ -n "$ROLES" ]]; then
            for role in $ROLES; do
              echo "  üóëÔ∏è Processing role: $role"
              
              # Detach managed policies
              MANAGED_POLICIES=$(aws iam list-attached-role-policies \
                --role-name "$role" \
                --query 'AttachedPolicies[].PolicyArn' \
                --output text 2>/dev/null || true)
              
              if [[ -n "$MANAGED_POLICIES" ]]; then
                for policy in $MANAGED_POLICIES; do
                  echo "    üîó Detaching managed policy: $(basename $policy)"
                  aws iam detach-role-policy --role-name "$role" --policy-arn "$policy" 2>/dev/null &
                done
              fi
              
              # Delete inline policies
              INLINE_POLICIES=$(aws iam list-role-policies \
                --role-name "$role" \
                --query 'PolicyNames[]' \
                --output text 2>/dev/null || true)
              
              if [[ -n "$INLINE_POLICIES" ]]; then
                for policy in $INLINE_POLICIES; do
                  echo "    üìÑ Deleting inline policy: $policy"
                  aws iam delete-role-policy --role-name "$role" --policy-name "$policy" 2>/dev/null &
                done
              fi
            done
            wait  # Wait for all policy operations
            
            # Now delete the roles
            for role in $ROLES; do
              echo "  üóëÔ∏è Deleting role: $role"
              retry_command 3 aws iam delete-role --role-name "$role" &
            done
            wait
            echo "  ‚úÖ IAM Roles cleaned"
          else
            echo "  ‚úÖ No IAM roles found"
          fi
          
          # Step 3.2: DynamoDB Tables (NEW)
          echo ""
          echo "üìá [3.2] DynamoDB Tables..."
          TABLES=$(aws dynamodb list-tables \
            --query 'TableNames[]' \
            --output text 2>/dev/null | tr '\t' '\n' | grep "$STACK" 2>/dev/null || true)
          
          if [[ -n "$TABLES" ]]; then
            for table in $TABLES; do
              echo "  üóëÔ∏è Deleting table: $table"
              aws dynamodb delete-table --table-name "$table" 2>/dev/null &
            done
            wait
            echo "  ‚úÖ DynamoDB tables deletion initiated"
            
            # Wait for tables to be deleted
            echo "  ‚è≥ Waiting for tables to be deleted..."
            sleep 20
          else
            echo "  ‚úÖ No DynamoDB tables found"
          fi
          
          # Step 3.3: API Gateways (NEW)
          echo ""
          echo "üì° [3.3] API Gateways..."
          APIS=$(aws apigateway get-rest-apis \
            --query "items[?contains(name, '$STACK')].id" \
            --output text 2>/dev/null || true)
          
          if [[ -n "$APIS" ]]; then
            for api in $APIS; do
              API_NAME=$(aws apigateway get-rest-api --rest-api-id "$api" --query 'name' --output text 2>/dev/null || echo "unknown")
              echo "  üóëÔ∏è Deleting API Gateway: $api ($API_NAME)"
              aws apigateway delete-rest-api --rest-api-id "$api" 2>/dev/null &
            done
            wait
            echo "  ‚úÖ API Gateways deletion initiated"
          else
            echo "  ‚úÖ No API Gateways found"
          fi
          
          # Step 3.4: Lambda Functions (catch any orphans)
          echo ""
          echo "‚ö° [3.4] Lambda Functions..."
          FUNCTIONS=$(aws lambda list-functions \
            --query 'Functions[?contains(FunctionName, `'$STACK'`)].FunctionName' \
            --output text 2>/dev/null || true)
          
          if [[ -n "$FUNCTIONS" ]]; then
            for func in $FUNCTIONS; do
              echo "  üóëÔ∏è Deleting function: $func"
              aws lambda delete-function --function-name "$func" 2>/dev/null &
            done
            wait
            echo "  ‚úÖ Lambda functions deleted"
          else
            echo "  ‚úÖ No Lambda functions found"
          fi
          
          # Step 3.5: Step Functions State Machines
          echo ""
          echo "üîÑ [3.5] Step Functions State Machines..."
          STATE_MACHINES=$(aws stepfunctions list-state-machines \
            --query 'stateMachines[?contains(name, `'$STACK'`)].stateMachineArn' \
            --output text 2>/dev/null || true)
          
          if [[ -n "$STATE_MACHINES" ]]; then
            for sm in $STATE_MACHINES; do
              SM_NAME=$(basename "$sm")
              echo "  üóëÔ∏è Deleting state machine: $SM_NAME"
              aws stepfunctions delete-state-machine --state-machine-arn "$sm" 2>/dev/null &
            done
            wait
            echo "  ‚úÖ State machines deleted"
          else
            echo "  ‚úÖ No state machines found"
          fi
          
          # Step 3.6: EventBridge Rules
          echo ""
          echo "‚è∞ [3.6] EventBridge Rules..."
          RULES=$(aws events list-rules \
            --query 'Rules[?contains(Name, `'$STACK'`)].Name' \
            --output text 2>/dev/null || true)
          
          if [[ -n "$RULES" ]]; then
            for rule in $RULES; do
              echo "  üóëÔ∏è Removing targets from rule: $rule"
              # Remove all targets first
              TARGETS=$(aws events list-targets-by-rule --rule "$rule" --query 'Targets[].Id' --output text 2>/dev/null || true)
              if [[ -n "$TARGETS" ]]; then
                aws events remove-targets --rule "$rule" --ids $TARGETS 2>/dev/null || true
              fi
              
              echo "  üóëÔ∏è Deleting rule: $rule"
              aws events delete-rule --name "$rule" 2>/dev/null &
            done
            wait
            echo "  ‚úÖ EventBridge rules deleted"
          else
            echo "  ‚úÖ No EventBridge rules found"
          fi
          
          echo ""
          echo "‚úÖ ============================================"
          echo "‚úÖ  CLEANUP COMPLETED SUCCESSFULLY"
          echo "‚úÖ ============================================"
          echo ""
          echo "üìä Cleanup Summary:"
          echo "  Stack deletion:      ‚úÖ"
          echo "  Core resources:      ‚úÖ"
          echo "  Orphan resources:    ‚úÖ"
          echo "  Total duration:      ~$SECONDS seconds"
      
      - name: üöÄ Deploy SAM Application
        id: sam-deploy
        run: |
          set -euo pipefail
          cd aws
          
          # Setup deployment bucket
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          BUCKET="sam-deployment-${ACCOUNT_ID}-${{ env.AWS_DEFAULT_REGION }}"
          
          echo "üì¶ Preparing S3 deployment bucket: $BUCKET"
          
          if ! aws s3api head-bucket --bucket "$BUCKET" 2>/dev/null; then
            echo "üÜï Creating deployment bucket..."
            if [[ "${{ env.AWS_DEFAULT_REGION }}" == "us-east-1" ]]; then
              aws s3api create-bucket --bucket "$BUCKET"
            else
              aws s3api create-bucket \
                --bucket "$BUCKET" \
                --create-bucket-configuration LocationConstraint="${{ env.AWS_DEFAULT_REGION }}"
            fi
            
            # Enable versioning for safety
            aws s3api put-bucket-versioning \
              --bucket "$BUCKET" \
              --versioning-configuration Status=Enabled
            
            echo "‚úÖ Deployment bucket created"
          else
            echo "‚úÖ Deployment bucket exists"
          fi
          
          # Generate secure JWT secret
          JWT_SECRET=$(openssl rand -base64 48)
          
          # Get infrastructure from discovery
          VPC_ID="${{ needs.discover-infrastructure.outputs.vpc-id }}"
          PRIVATE_1="${{ needs.discover-infrastructure.outputs.private-subnet-1 }}"
          PRIVATE_2="${{ needs.discover-infrastructure.outputs.private-subnet-2 }}"
          PUBLIC_1="${{ needs.discover-infrastructure.outputs.public-subnet-1 }}"
          PUBLIC_2="${{ needs.discover-infrastructure.outputs.public-subnet-2 }}"
          
          echo ""
          echo "üîß Deployment Configuration:"
          echo "  VPC:        $VPC_ID"
          echo "  Private 1:  $PRIVATE_1"
          echo "  Private 2:  $PRIVATE_2"
          echo "  Public 1:   ${PUBLIC_1:-<none>}"
          echo "  Public 2:   ${PUBLIC_2:-<none>}"
          
          # Build parameter overrides
          PARAMS=(
            "Stage=prod"
            "JwtSecret=$JWT_SECRET"
            "CorsOrigins=https://yourdomain.com"
            "VpcId=$VPC_ID"
            "PrivateSubnetId1=$PRIVATE_1"
            "PrivateSubnetId2=$PRIVATE_2"
          )
          
          if [[ -n "$PUBLIC_1" ]]; then
            PARAMS+=("PublicSubnetId1=$PUBLIC_1")
          fi
          
          if [[ -n "$PUBLIC_2" ]]; then
            PARAMS+=("PublicSubnetId2=$PUBLIC_2")
          fi
          
          echo ""
          echo "üì¶ Deploying stack with ${#PARAMS[@]} parameters..."
          
          # Deploy with retries
          MAX_DEPLOY_RETRIES=3
          DEPLOY_ATTEMPT=1
          
          while [ $DEPLOY_ATTEMPT -le $MAX_DEPLOY_RETRIES ]; do
            echo "üöÄ Deployment attempt $DEPLOY_ATTEMPT/$MAX_DEPLOY_RETRIES..."
            
            if sam deploy \
              --stack-name "${{ env.STACK_NAME }}" \
              --region ${{ env.AWS_DEFAULT_REGION }} \
              --s3-bucket "$BUCKET" \
              --parameter-overrides "${PARAMS[@]}" \
              --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \
              --no-fail-on-empty-changeset \
              --no-confirm-changeset \
              --on-failure ROLLBACK 2>&1 | tee deploy.log; then
              
              echo "‚úÖ SAM deployment successful"
              echo "deploy_status=success" >> $GITHUB_OUTPUT
              break
            else
              echo "‚ùå Deployment attempt $DEPLOY_ATTEMPT failed"
              
              if [ $DEPLOY_ATTEMPT -lt $MAX_DEPLOY_RETRIES ]; then
                echo "‚è≥ Waiting 30s before retry..."
                sleep 30
              else
                echo "‚ùå All deployment attempts failed"
                echo "deploy_status=failed" >> $GITHUB_OUTPUT
                cat deploy.log || true
                exit 1
              fi
            fi
            
            DEPLOY_ATTEMPT=$((DEPLOY_ATTEMPT + 1))
          done

      - name: üì§ Export Stack Outputs
        id: export-outputs
        run: |
          set -euo pipefail
          STACK="${{ env.STACK_NAME }}"
          
          echo "üì§ Fetching CloudFormation outputs..."
          
          # Wait for stack to be in stable state
          for i in {1..30}; do
            STATUS=$(aws cloudformation describe-stacks \
              --stack-name "$STACK" \
              --query 'Stacks[0].StackStatus' \
              --output text 2>/dev/null || echo "NOT_FOUND")
            
            if [[ "$STATUS" =~ (CREATE_COMPLETE|UPDATE_COMPLETE) ]]; then
              echo "‚úÖ Stack is ready: $STATUS"
              break
            elif [[ "$STATUS" =~ (FAILED|ROLLBACK) ]]; then
              echo "‚ùå Stack in error state: $STATUS"
              exit 1
            fi
            
            echo "‚è≥ Waiting for stack to stabilize... ($i/30)"
            sleep 10
          done
          
          # Get outputs
          API_ENDPOINT=$(aws cloudformation describe-stacks \
            --stack-name "$STACK" \
            --query 'Stacks[0].Outputs[?OutputKey==`ApiEndpoint`].OutputValue' \
            --output text)
          
          SCHEMA_FUNCTION_NAME=$(aws cloudformation describe-stacks \
            --stack-name "$STACK" \
            --query 'Stacks[0].Outputs[?OutputKey==`SchemaInitializerFunctionName`].OutputValue' \
            --output text)
          
          if [[ -z "$API_ENDPOINT" || "$API_ENDPOINT" == "None" ]]; then
            echo "‚ùå API endpoint not found in outputs"
            exit 1
          fi
          
          if [[ -z "$SCHEMA_FUNCTION_NAME" || "$SCHEMA_FUNCTION_NAME" == "None" ]]; then
            echo "‚ùå Schema function name not found in outputs"
            exit 1
          fi
          
          echo "api_endpoint=$API_ENDPOINT" >> $GITHUB_OUTPUT
          echo "schema_function_name=$SCHEMA_FUNCTION_NAME" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Outputs exported:"
          echo "  API Endpoint: $API_ENDPOINT"
          echo "  Schema Function: $SCHEMA_FUNCTION_NAME"
      
      - name: üìä Deployment Status Summary
        id: deploy-status
        run: |
          echo "status=success" >> $GITHUB_OUTPUT
          echo "‚úÖ Deployment phase completed successfully"

  initialize-database:
    name: üóÉÔ∏è Initialize Database Schema
    runs-on: ubuntu-latest
    needs: cleanup-and-deploy
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          # ‚ö†Ô∏è SECURITY RISK: Replace with OIDC (see notes below)
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
      
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: pip install boto3
      
      - name: üóÉÔ∏è Parse SQL Schema File
        id: parse-sql
        run: |
          set -euo pipefail
          
          if [ -f database/rds_schema_update.sql ]; then
            echo "üìÑ Parsing SQL schema file..."
            
            python3 <<'PYEOF'
          import json
          import sys
          
          try:
              with open('database/rds_schema_update.sql', 'r', encoding='utf-8') as f:
                  sql = f.read()
              
              # Split by semicolon and filter out comments and empty statements
              statements = [
                  s.strip() 
                  for s in sql.split(';') 
                  if s.strip() and not s.strip().startswith('--') and len(s.strip()) > 5
              ]
              
              with open('sql_statements.json', 'w') as out:
                  json.dump(statements, out, indent=2)
              
              print(f"‚úÖ Successfully parsed {len(statements)} SQL statements")
              sys.exit(0)
              
          except Exception as e:
              print(f"‚ùå Error parsing SQL file: {str(e)}")
              sys.exit(1)
          PYEOF
            
          else
            echo "‚ö†Ô∏è No SQL schema file found at database/rds_schema_update.sql"
            echo "Using default empty schema"
            echo '[]' > sql_statements.json
          fi
      
      - name: üöÄ Invoke Schema Initializer Lambda
        timeout-minutes: 8
        run: |
          set -euo pipefail
          STACK="${{ env.STACK_NAME }}"
          
          echo "üîç Locating schema initializer Lambda..."
          
          FUNCTION_NAME="${{ needs.cleanup-and-deploy.outputs.schema-function-name }}"
          
          if [[ -z "$FUNCTION_NAME" || "$FUNCTION_NAME" == "None" ]]; then
            echo "‚ùå Schema initializer Lambda function not found"
            echo "Available stack outputs:"
            aws cloudformation describe-stacks \
              --stack-name "$STACK" \
              --query 'Stacks[0].Outputs[].[OutputKey,OutputValue]' \
              --output table
            exit 1
          fi
          
          echo "‚úÖ Found function: $FUNCTION_NAME"
          
          # Verify function exists and is active
          FUNCTION_STATE=$(aws lambda get-function \
            --function-name "$FUNCTION_NAME" \
            --query 'Configuration.State' \
            --output text 2>/dev/null || echo "NOT_FOUND")
          
          if [[ "$FUNCTION_STATE" != "Active" ]]; then
            echo "‚ö†Ô∏è Lambda function state: $FUNCTION_STATE"
            echo "Waiting for function to become active..."
            
            for i in {1..30}; do
              FUNCTION_STATE=$(aws lambda get-function \
                --function-name "$FUNCTION_NAME" \
                --query 'Configuration.State' \
                --output text 2>/dev/null || echo "NOT_FOUND")
              
              if [[ "$FUNCTION_STATE" == "Active" ]]; then
                echo "‚úÖ Function is now active"
                break
              fi
              
              echo "‚è≥ Waiting... ($i/30)"
              sleep 10
            done
          fi
          
          # Load and validate SQL statements
          SQL_STATEMENTS=$(cat sql_statements.json)
          STMT_COUNT=$(echo "$SQL_STATEMENTS" | jq 'length')
          
          echo "üìù Prepared payload with $STMT_COUNT SQL statements"
          
          # Create Lambda payload
          PAYLOAD=$(jq -n --argjson stmts "$SQL_STATEMENTS" '{sql_statements: $stmts}')
          
          # Invoke Lambda with retry
          MAX_RETRIES=3
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "üì§ Invoking schema initializer (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)..."
            
            if aws lambda invoke \
              --function-name "$FUNCTION_NAME" \
              --payload "$PAYLOAD" \
              --cli-binary-format raw-in-base64-out \
              --log-type Tail \
              response.json 2>&1; then
              
              echo "‚úÖ Lambda invocation successful"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚è≥ Retrying in 10 seconds..."
                sleep 10
              else
                echo "‚ùå Lambda invocation failed after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done
          
          # Parse and validate response
          echo ""
          echo "üì• Lambda Response:"
          cat response.json | jq '.' || cat response.json
          
          # Check for Lambda execution errors
          if jq -e '.errorMessage' response.json >/dev/null 2>&1; then
            echo ""
            echo "‚ùå Lambda execution error:"
            jq -r '.errorMessage' response.json
            exit 1
          fi
          
          # Parse response body
          BODY=$(jq -r '.body' response.json 2>/dev/null || echo "null")
          
          if [[ "$BODY" == "null" || -z "$BODY" ]]; then
            echo "‚ùå No response body returned from Lambda"
            exit 1
          fi
          
          # Extract execution summary
          SUCCESS=$(echo "$BODY" | jq -r '.success // false')
          ERRORS=$(echo "$BODY" | jq -r '.summary.errors // 0')
          EXECUTED=$(echo "$BODY" | jq -r '.summary.executed // 0')
          SKIPPED=$(echo "$BODY" | jq -r '.summary.skipped // 0')
          TOTAL=$(echo "$BODY" | jq -r '.summary.total // 0')
          
          echo ""
          echo "üìä Schema Initialization Summary:"
          echo "  ‚úÖ Executed: $EXECUTED"
          echo "  ‚è≠Ô∏è  Skipped:  $SKIPPED (already exists)"
          echo "  ‚ùå Errors:   $ERRORS"
          echo "  üìä Total:    $TOTAL"
          
          # Determine overall success
          if [[ "$SUCCESS" == "true" ]]; then
            echo ""
            echo "‚úÖ Schema initialization completed successfully!"
            exit 0
          # Allow non-zero errors if at least one statement executed (for idempotent runs)
          elif [[ "$ERRORS" -gt 0 && "$EXECUTED" -gt 0 ]]; then
            echo ""
            echo "‚úÖ Schema initialization completed (with non-fatal 'already exists' errors)."
            exit 0
          elif [[ "$ERRORS" -gt 0 && "$EXECUTED" -eq 0 && "$SKIPPED" -gt 0 ]]; then
            echo ""
            echo "‚úÖ Schema initialization complete (all items skipped or already exist)."
            exit 0
          else
            echo ""
            echo "‚ùå Critical schema initialization failure"
            echo ""
            echo "Detailed errors:"
            echo "$BODY" | jq '.results[] | select(.status == "error")'
            exit 1
          fi

  deploy-frontend:
    name: üåê Deploy Frontend with Enhanced Error Handling
    runs-on: ubuntu-latest
    needs: [cleanup-and-deploy, initialize-database]
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4
      
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          # ‚ö†Ô∏è SECURITY RISK: Replace with OIDC (see notes below)
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      
      - name: üì¶ Setup npm cache with graceful fallback
        uses: actions/cache@v3
        id: npm-cache
        with:
          path: |
            frontend/node_modules
            ~/.npm
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('frontend/package-lock.json', 'frontend/package.json') }}
          restore-keys: |
            ${{ runner.os }}-node-${{ env.NODE_VERSION }}-
            ${{ runner.os }}-node-
        continue-on-error: true
      
      - name: üìä Cache Status
        run: |
          if [[ "${{ steps.npm-cache.outputs.cache-hit }}" == "true" ]]; then
            echo "‚úÖ Cache hit - dependencies restored from cache"
          else
            echo "‚ö†Ô∏è Cache miss - will install fresh dependencies"
          fi
      
      - name: üì¶ Install Dependencies with comprehensive retry logic
        timeout-minutes: 10
        run: |
          set -euo pipefail
          cd frontend
          
          echo "üì¶ ============================================"
          echo "üì¶  FRONTEND DEPENDENCY INSTALLATION"
          echo "üì¶ ============================================"
          echo ""
          
          # Function: Retry with exponential backoff
          retry_npm() {
            local max_attempts=3
            local attempt=1
            local delay=10
            local command=$1
            
            while [ $attempt -le $max_attempts ]; do
              echo "üîÑ Attempt $attempt/$max_attempts: $command"
              
              if eval "$command" 2>&1; then
                echo "‚úÖ Success on attempt $attempt"
                return 0
              fi
              
              if [ $attempt -lt $max_attempts ]; then
                echo "‚ö†Ô∏è Failed, waiting ${delay}s before retry..."
                sleep $delay
                delay=$((delay * 2))
              fi
              
              attempt=$((attempt + 1))
            done
            
            return 1
          }
          
          # Check if package.json exists
          if [[ ! -f package.json ]]; then
            echo "‚ùå CRITICAL: package.json not found in frontend directory"
            exit 1
          fi
          
          echo "üìã package.json found"
          echo "Node version: $(node --version)"
          echo "npm version: $(npm --version)"
          echo ""
          
          # Strategy 1: npm ci with lockfile
          if [[ -f package-lock.json ]]; then
            echo "üéØ Strategy 1: npm ci (using lockfile)"
            
            if retry_npm "npm ci"; then
              echo "‚úÖ npm ci completed successfully"
              exit 0
            fi
            
            echo "‚ö†Ô∏è npm ci failed, trying with legacy peer deps..."
            rm -rf node_modules
            
            if retry_npm "npm ci --legacy-peer-deps"; then
              echo "‚úÖ npm ci --legacy-peer-deps completed successfully"
              exit 0
            fi
            
            echo "‚ö†Ô∏è npm ci --legacy-peer-deps failed, removing lockfile..."
            rm -rf node_modules package-lock.json
          else
            echo "‚ö†Ô∏è No package-lock.json found, skipping npm ci"
          fi
          
          # Strategy 2: npm install with legacy peer deps
          echo ""
          echo "üéØ Strategy 2: npm install --legacy-peer-deps"
          
          if retry_npm "npm install --legacy-peer-deps"; then
            echo "‚úÖ npm install --legacy-peer-deps completed successfully"
          else
            # Strategy 3: Nuclear option - clean install with force
            echo ""
            echo "üéØ Strategy 3: Clean npm install --force"
            
            rm -rf node_modules package-lock.json ~/.npm/_cacache
            
            if retry_npm "npm install --force --legacy-peer-deps"; then
              echo "‚úÖ npm install --force completed successfully"
            else
              echo "‚ùå All npm install strategies failed"
              echo ""
              echo "üîç Debugging information:"
              echo "  Current directory: $(pwd)"
              echo "  package.json exists: $([ -f package.json ] && echo 'yes' || echo 'no')"
              echo "  npm config:"
              npm config list
              exit 1
            fi
          fi
          
          # Generate lockfile for future runs
          if [[ ! -f package-lock.json ]]; then
            echo ""
            echo "üìù Generating package-lock.json for future builds..."
            npm install --package-lock-only || echo "‚ö†Ô∏è Could not generate lockfile"
          fi
          
          # Verify installation
          echo ""
          echo "üîç Verifying installation..."
          
          if [[ ! -d node_modules ]]; then
            echo "‚ùå node_modules directory not created"
            exit 1
          fi
          
          MODULE_COUNT=$(find node_modules -maxdepth 1 -type d | wc -l)
          echo "‚úÖ Installation verified: $MODULE_COUNT modules installed"
          echo ""
          echo "‚úÖ ============================================"
          echo "‚úÖ  DEPENDENCY INSTALLATION COMPLETE"
          echo "‚úÖ ============================================"
      
      - name: üèóÔ∏è Build React Application with error handling
        timeout-minutes: 10
        run: |
          set -euo pipefail
          cd frontend
          
          echo "üèóÔ∏è ============================================"
          echo "üèóÔ∏è  FRONTEND BUILD PROCESS"
          echo "üèóÔ∏è ============================================"
          echo ""
          
          # Validate API endpoint
          API_ENDPOINT="${{ needs.cleanup-and-deploy.outputs.api-endpoint }}"
          
          if [[ -z "$API_ENDPOINT" || "$API_ENDPOINT" == "None" || "$API_ENDPOINT" == "null" ]]; then
            echo "‚ùå CRITICAL: API endpoint not available"
            echo "Received value: '$API_ENDPOINT'"
            exit 1
          fi
          
          echo "‚úÖ API endpoint validated: $API_ENDPOINT"
          
          # Create environment configuration
          echo ""
          echo "üìù Creating production environment configuration..."
          
          cat > .env.production << EOF
          REACT_APP_API_URL=$API_ENDPOINT
          REACT_APP_STAGE=prod
          REACT_APP_VERSION=$(date +%Y%m%d-%H%M%S)
          REACT_APP_BUILD_TIME=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          EOF
          
          echo "üìã Environment configuration:"
          cat .env.production
          echo ""
          
          # Pre-build checks
          echo "üîç Pre-build validation..."
          
          if [[ ! -d node_modules ]]; then
            echo "‚ùå node_modules directory missing"
            exit 1
          fi
          
          if [[ ! -f package.json ]]; then
            echo "‚ùå package.json missing"
            exit 1
          fi
          
          # Check if build script exists
          if ! grep -q '"build"' package.json; then
            echo "‚ùå No build script found in package.json"
            exit 1
          fi
          
          echo "‚úÖ Pre-build validation passed"
          echo ""
          
          # Execute build
          echo "üî® Starting React build process..."
          echo "Build environment: CI=false (warnings won't fail build)"
          echo ""
          
          BUILD_START=$(date +%s)
          
          if CI=false npm run build 2>&1 | tee build.log; then
            BUILD_END=$(date +%s)
            BUILD_DURATION=$((BUILD_END - BUILD_START))
            
            echo ""
            echo "‚úÖ Build completed in ${BUILD_DURATION}s"
          else
            echo ""
            echo "‚ùå Build failed - checking logs..."
            
            if [[ -f build.log ]]; then
              echo "Last 50 lines of build output:"
              tail -50 build.log
            fi
            
            exit 1
          fi
          
          # Post-build validation
          echo ""
          echo "üîç Post-build validation..."
          
          if [[ ! -d build ]]; then
            echo "‚ùå build directory was not created"
            exit 1
          fi
          
          if [[ ! -f build/index.html ]]; then
            echo "‚ùå build/index.html not found"
            echo "Build directory contents:"
            ls -la build/ || true
            exit 1
          fi
          
          # Check for critical files
          CRITICAL_FILES=("index.html" "static")
          for file in "${CRITICAL_FILES[@]}"; do
            if [[ ! -e "build/$file" ]]; then
              echo "‚ö†Ô∏è Warning: build/$file not found"
            else
              echo "‚úÖ Found: build/$file"
            fi
          done
          
          # Build size analysis
          echo ""
          echo "üìä Build Analysis:"
          echo "  Total size: $(du -sh build/ | cut -f1)"
          
          if [[ -d build/static ]]; then
            echo "  Static files: $(du -sh build/static/ | cut -f1)"
          fi
          
          FILE_COUNT=$(find build -type f | wc -l)
          echo "  File count: $FILE_COUNT files"
          
          echo ""
          echo "‚úÖ ============================================"
          echo "‚úÖ  BUILD VALIDATION COMPLETE"
          echo "‚úÖ ============================================"
      
      - name: üöÄ Deploy to S3 with enhanced reliability
        timeout-minutes: 10
        run: |
          set -euo pipefail
          FRONTEND_BUCKET="${{ env.STACK_NAME }}-frontend"
          
          echo "üöÄ ============================================"
          echo "üöÄ  S3 FRONTEND DEPLOYMENT"
          echo "üöÄ ============================================"
          echo ""
          
          echo "ü™£ Target bucket: $FRONTEND_BUCKET"
          echo "üìç Region: ${{ env.AWS_DEFAULT_REGION }}"
          echo ""
          
          # Check if bucket exists
          echo "üîç Checking if bucket exists..."
          
          if aws s3api head-bucket --bucket "$FRONTEND_BUCKET" 2>/dev/null; then
            echo "‚úÖ Bucket exists: $FRONTEND_BUCKET"
          else
            echo "üÜï Creating S3 bucket: $FRONTEND_BUCKET"
            
            # Create bucket with region-specific configuration
            if [[ "${{ env.AWS_DEFAULT_REGION }}" == "us-east-1" ]]; then
              if aws s3api create-bucket --bucket "$FRONTEND_BUCKET"; then
                echo "‚úÖ Bucket created in us-east-1"
              else
                echo "‚ùå Failed to create bucket"
                exit 1
              fi
            else
              if aws s3api create-bucket \
                --bucket "$FRONTEND_BUCKET" \
                --create-bucket-configuration LocationConstraint="${{ env.AWS_DEFAULT_REGION }}"; then
                echo "‚úÖ Bucket created in ${{ env.AWS_DEFAULT_REGION }}"
              else
                echo "‚ùå Failed to create bucket"
                exit 1
              fi
            fi
            
            # Wait for bucket to be available
            echo "‚è≥ Waiting for bucket to be available..."
            sleep 5
          fi
          
          # Upload static assets (JS, CSS, images) with long-term caching
          echo ""
          echo "üì§ Uploading static assets with cache optimization..."
          
          aws s3 sync frontend/build/ "s3://$FRONTEND_BUCKET" \
            --delete \
            --cache-control "public,max-age=31536000,immutable" \
            --exclude "*.html" \
            --exclude "service-worker.js" \
            --exclude "asset-manifest.json" \
            --exclude "manifest.json" \
            --exclude "robots.txt"
          
          STATIC_RESULT=$?
          
          if [ $STATIC_RESULT -eq 0 ]; then
            echo "‚úÖ Static assets uploaded successfully"
          else
            echo "‚ùå Static asset upload failed with code: $STATIC_RESULT"
            exit 1
          fi
          
          # Upload HTML and dynamic files with no-cache
          echo ""
          echo "üì§ Uploading HTML and dynamic files with no-cache..."
          
          aws s3 sync frontend/build/ "s3://$FRONTEND_BUCKET" \
            --exclude "*" \
            --include "*.html" \
            --include "service-worker.js" \
            --include "asset-manifest.json" \
            --include "manifest.json" \
            --include "robots.txt" \
            --cache-control "no-cache,no-store,must-revalidate" \
            --metadata-directive REPLACE
          
          HTML_RESULT=$?
          
          if [ $HTML_RESULT -eq 0 ]; then
            echo "‚úÖ HTML files uploaded successfully"
          else
            echo "‚ùå HTML upload failed with code: $HTML_RESULT"
            exit 1
          fi
          
          # Configure static website hosting
          echo ""
          echo "üåê Configuring static website hosting..."
          
          if aws s3api put-bucket-website \
            --bucket "$FRONTEND_BUCKET" \
            --website-configuration '{
              "IndexDocument": {"Suffix": "index.html"},
              "ErrorDocument": {"Key": "index.html"}
            }'; then
            echo "‚úÖ Website hosting configured"
          else
            echo "‚ùå Failed to configure website hosting"
            exit 1
          fi
          
          # Configure CORS (if needed for API calls)
          echo ""
          echo "üîó Configuring CORS..."
          
          aws s3api put-bucket-cors \
            --bucket "$FRONTEND_BUCKET" \
            --cors-configuration '{
              "CORSRules": [{
                "AllowedOrigins": ["*"],
                "AllowedMethods": ["GET", "HEAD"],
                "AllowedHeaders": ["*"],
                "MaxAgeSeconds": 3000
              }]
            }' 2>/dev/null || echo "‚ö†Ô∏è CORS configuration skipped"
          
          # Set bucket policy for public read access
          echo ""
          echo "üîì Configuring public access policy..."
          
          if aws s3api put-bucket-policy \
            --bucket "$FRONTEND_BUCKET" \
            --policy '{
              "Version": "2012-10-17",
              "Statement": [{
                "Sid": "PublicReadGetObject",
                "Effect": "Allow",
                "Principal": "*",
                "Action": "s3:GetObject",
                "Resource": "arn:aws:s3:::'$FRONTEND_BUCKET'/*"
              }]
            }'; then
            echo "‚úÖ Bucket policy set"
          else
            echo "‚ùå Failed to set bucket policy"
            exit 1
          fi
          
          # Disable block public access
          echo ""
          echo "üîì Disabling block public access settings..."
          
          if aws s3api put-public-access-block \
            --bucket "$FRONTEND_BUCKET" \
            --public-access-block-configuration \
            "BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false"; then
            echo "‚úÖ Public access configured"
          else
            echo "‚ùå Failed to configure public access"
            exit 1
          fi
          
          # Generate website URL
          WEBSITE_URL="http://$FRONTEND_BUCKET.s3-website-${{ env.AWS_DEFAULT_REGION }}.amazonaws.com"
          
          # Verify deployment
          echo ""
          echo "üîç Verifying deployment..."
          
          sleep 5  # Wait for S3 to propagate
          
          if curl -sf "$WEBSITE_URL" >/dev/null 2>&1; then
            echo "‚úÖ Website is accessible"
          else
            echo "‚ö†Ô∏è Website may need a few moments to propagate"
          fi
          
          # List uploaded files
          echo ""
          echo "üìã Uploaded files summary:"
          FILE_COUNT=$(aws s3 ls "s3://$FRONTEND_BUCKET" --recursive | wc -l)
          TOTAL_SIZE=$(aws s3 ls "s3://$FRONTEND_BUCKET" --recursive --summarize | grep "Total Size" | awk '{print $3}')
          
          echo "  Total files: $FILE_COUNT"
          echo "  Total size: $TOTAL_SIZE bytes"
          
          echo ""
          echo "‚úÖ ============================================"
          echo "‚úÖ  FRONTEND DEPLOYMENT COMPLETE"
          echo "‚úÖ ============================================"
          echo ""
          echo "üåê Website URL: $WEBSITE_URL"
          echo "üì¶ Bucket: s3://$FRONTEND_BUCKET"
          echo "üìç Region: ${{ env.AWS_DEFAULT_REGION }}"
          echo ""
      
      - name: üß™ Post-Deployment Validation
        timeout-minutes: 5
        run: |
          set -euo pipefail
          
          WEBSITE_URL="http://${{ env.STACK_NAME }}-frontend.s3-website-${{ env.AWS_DEFAULT_REGION }}.amazonaws.com"
          
          echo "üß™ Testing frontend accessibility..."
          echo "URL: $WEBSITE_URL"
          echo ""
          
          MAX_RETRIES=12
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if curl -sf -o /tmp/index.html "$WEBSITE_URL" 2>/dev/null; then
              echo "‚úÖ Frontend is accessible!"
              
              # Verify it's HTML content
              if grep -q "<!DOCTYPE html>" /tmp/index.html || grep -q "<html" /tmp/index.html; then
                echo "‚úÖ Valid HTML content detected"
                
                # Check for React app
                if grep -q "root" /tmp/index.html; then
                  echo "‚úÖ React root element found"
                fi
                
                break
              else
                echo "‚ö†Ô∏è Response doesn't appear to be HTML"
              fi
            fi
            
            RETRY_COUNT=$((RETRY_COUNT + 1))
            
            if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
              echo "‚è≥ Retry $RETRY_COUNT/$MAX_RETRIES - waiting 10s..."
              sleep 10
            else
              echo "‚ö†Ô∏è Frontend validation timeout (non-fatal)"
              echo "Website may still be propagating - check manually:"
              echo "  $WEBSITE_URL"
            fi
          done
          
          echo ""
          echo "‚úÖ Post-deployment validation complete"

  smoke-tests:
    name: üß™ Smoke Tests & Validation
    runs-on: ubuntu-latest
    needs: [cleanup-and-deploy, initialize-database, deploy-frontend]
    timeout-minutes: 10
    steps:
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: üß™ Comprehensive Smoke Tests
        env:
          API_ENDPOINT: ${{ needs.cleanup-and-deploy.outputs.api-endpoint }}
        run: |
          set -euo pipefail
          
          echo "üß™ Starting comprehensive smoke tests"
          echo "API Endpoint: $API_ENDPOINT"
          echo "======================================"
          
          # Test 1: Health Check with retry
          echo ""
          echo "üè• Test 1: API Health Check"
          RETRY_COUNT=0
          MAX_RETRIES=24  # 4 minutes max
          RETRY_DELAY=10
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if curl -sf "${API_ENDPOINT}/health" -o health_response.txt 2>/dev/null; then
              echo "‚úÖ Health check passed (attempt $((RETRY_COUNT + 1)))"
              
              # Validate JSON response
              if python3 -m json.tool < health_response.txt >/dev/null 2>&1; then
                echo "‚úÖ Valid JSON response"
                cat health_response.txt | python3 -m json.tool
              fi
              
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚è≥ Health check failed, retry $RETRY_COUNT/$MAX_RETRIES in ${RETRY_DELAY}s..."
                sleep $RETRY_DELAY
              else
                echo "‚ö†Ô∏è Health check timeout after $MAX_RETRIES attempts"
                echo "‚ö†Ô∏è This is non-fatal - API may still be warming up"
              fi
            fi
          done
          
          # Test 2: API Gateway Connectivity
          echo ""
          echo "üåê Test 2: API Gateway Status"
          if curl -I "${API_ENDPOINT}/health" 2>/dev/null | head -1; then
            echo "‚úÖ API Gateway is responding"
          else
            echo "‚ö†Ô∏è API Gateway check inconclusive"
          fi
          
          # Test 3: Frontend Accessibility
          echo ""
          echo "üåê Test 3: Frontend Website"
          FRONTEND_URL="http://${{ env.STACK_NAME }}-frontend.s3-website-${{ env.AWS_DEFAULT_REGION }}.amazonaws.com"
          
          if curl -sf "$FRONTEND_URL" >/dev/null 2>&1; then
            echo "‚úÖ Frontend is accessible at: $FRONTEND_URL"
          else
            echo "‚ö†Ô∏è Frontend may still be propagating"
          fi
          
          echo ""
          echo "‚úÖ Smoke tests completed"

  deployment-summary:
    name: üìä Deployment Summary
    runs-on: ubuntu-latest
    needs: [cleanup-and-deploy, discover-infrastructure, initialize-database, deploy-frontend, smoke-tests]
    if: always()
    steps:
      - name: üéâ Generate Deployment Report
        run: |
          echo "üéÜ ============================================================"
          echo "üéÜ  PRODUCTION DEPLOYMENT COMPLETE"
          echo "üéÜ ============================================================"
          echo ""
          echo "üìä Deployment Summary:"
          echo "  Stack Name:          ${{ env.STACK_NAME }}"
          echo "  Region:              ${{ env.AWS_DEFAULT_REGION }}"
          echo "  Timestamp:           $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo ""
          echo "üèóÔ∏è Infrastructure:"
          echo "  VPC ID:              ${{ needs.discover-infrastructure.outputs.vpc-id }}"
          echo "  Private Subnet 1:    ${{ needs.discover-infrastructure.outputs.private-subnet-1 }}"
          echo "  Private Subnet 2:    ${{ needs.discover-infrastructure.outputs.private-subnet-2 }}"
          echo "  Public Subnet 1:     ${{ needs.discover-infrastructure.outputs.public-subnet-1 }}"
          echo "  Public Subnet 2:     ${{ needs.discover-infrastructure.outputs.public-subnet-2 }}"
          echo ""
          echo "üîó Endpoints:"
          echo "  API Endpoint:        ${{ needs.cleanup-and-deploy.outputs.api-endpoint }}"
          echo "  API Health:          ${{ needs.cleanup-and-deploy.outputs.api-endpoint }}/health"
          echo "  Frontend:            http://${{ env.STACK_NAME }}-frontend.s3-website-${{ env.AWS_DEFAULT_REGION }}.amazonaws.com"
          echo "  Schema Function:     ${{ needs.cleanup-and-deploy.outputs.schema-function-name }}"
          echo ""
          echo "‚úÖ Deployed Components:"
          echo "  ‚úÖ CloudFormation Stack"
          echo "  ‚úÖ API Gateway"
          echo "  ‚úÖ Lambda Functions (VPC-enabled)"
          echo "  ‚úÖ Step Functions (Migration, Audit, Export)"
          echo "  ‚úÖ DynamoDB Tables (Cloud Storage)"
          echo "  ‚úÖ RDS MySQL (Legacy Database)"
          echo "  ‚úÖ VPC Endpoints (Secure connectivity)"
          echo "  ‚úÖ Security Groups"
          echo "  ‚úÖ Secrets Manager"
          echo "  ‚úÖ S3 Buckets (Frontend + Uploads)"
          echo "  ‚úÖ CloudWatch Logs"
          echo "  ‚úÖ React Frontend"
          echo ""
          echo "üéØ Deployment Status:"
          
          # Check all job statuses
          CLEANUP_STATUS="${{ needs.cleanup-and-deploy.result }}"
          DB_STATUS="${{ needs.initialize-database.result }}"
          FRONTEND_STATUS="${{ needs.deploy-frontend.result }}"
          SMOKE_STATUS="${{ needs.smoke-tests.result }}"
          
          echo "  Cleanup & Deploy:    $CLEANUP_STATUS"
          echo "  Database Init:       $DB_STATUS"
          echo "  Frontend Deploy:     $FRONTEND_STATUS"
          echo "  Smoke Tests:         $SMOKE_STATUS"
          echo ""
          
          if [[ "$CLEANUP_STATUS" == "success" ]] && \
             [[ "$DB_STATUS" == "success" ]] && \
             [[ "$FRONTEND_STATUS" == "success" ]]; then
            echo "üéâ ============================================================"
            echo "üéâ  DEPLOYMENT SUCCESSFUL - ALL SYSTEMS OPERATIONAL"
            echo "üéâ ============================================================"
            exit 0
          elif [[ "$CLEANUP_STATUS" == "success" ]]; then
            echo "‚ö†Ô∏è ============================================================"
            echo "‚ö†Ô∏è  INFRASTRUCTURE DEPLOYED - MINOR ISSUES DETECTED"
            echo "‚ö†Ô∏è ============================================================"
            echo ""
            echo "üõ†Ô∏è Troubleshooting:"
            echo "  1. Check CloudWatch Logs for detailed error messages"
            echo "  2. Verify RDS database connectivity from VPC"
            echo "  3. Check Lambda function IAM permissions"
            echo "  4. Validate VPC endpoint configurations"
            echo "  5. Review Step Functions execution history"
            exit 0
          else
            echo "‚ùå ============================================================"
            echo "‚ùå  DEPLOYMENT FAILED - REVIEW LOGS"
            echo "‚ùå ============================================================"
            exit 1
          fi