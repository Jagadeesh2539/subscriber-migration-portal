name: Deploy Subscriber Migration Portal

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      stage:
        description: 'Deployment stage'
        required: true
        default: 'prod'
        type: choice
        options: [dev, test, prod]

env:
  AWS_DEFAULT_REGION: us-west-2
  AWS_REGION: us-west-2
  STACK_NAME: subscriber-migration-portal-prod
  BUCKET_SUFFIX: '20251031'
  STAGE: prod

jobs:
  build-test-deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 75
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup SAM CLI
        uses: aws-actions/setup-sam@v2
        with:
          use-installer: true

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install boto3 pymysql

      - name: Build SAM application
        working-directory: aws
        run: sam build --use-container

      - name: Deploy with Aurora EngineVersion fallback (us-west-2)
        id: deploy
        working-directory: aws
        env:
          ENGINE_VERSIONS: "5.7.mysql_aurora.2.07.1 5.7.mysql_aurora.2.07.2 5.7.mysql_aurora.2.08.1 5.7.mysql_aurora.2.10.2"
        run: |
          set -euo pipefail
          STACK="$STACK_NAME"
          if [ "${{ inputs.stage || '' }}" != "" ] && [ "${{ inputs.stage }}" != "prod" ]; then
            STACK="subscriber-migration-portal-${{ inputs.stage }}"
          fi
          for EV in $ENGINE_VERSIONS; do
            echo "Attempting deploy with AuroraEngineVersion=$EV in $AWS_REGION"
            if sam deploy \
              --stack-name "$STACK" \
              --region "$AWS_REGION" \
              --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \
              --no-confirm-changeset \
              --no-fail-on-empty-changeset \
              --parameter-overrides \
                Stage="${{ inputs.stage || env.STAGE }}" \
                JwtSecret="${{ secrets.JWT_SECRET }}" \
                CorsOrigins="${{ secrets.CORS_ORIGINS || 'https://yourdomain.com' }}" \
                BucketSuffix="$BUCKET_SUFFIX" \
                AuroraEngineVersion="$EV"; then
              echo "engine_version=$EV" >> $GITHUB_OUTPUT
              echo "‚úÖ Deploy succeeded with $EV"
              exit 0
            else
              echo "‚ö†Ô∏è Deploy failed with $EV, trying next..."
              if aws cloudformation describe-stacks --region "$AWS_REGION" --stack-name "$STACK" >/dev/null 2>&1; then
                STATUS=$(aws cloudformation describe-stacks --region "$AWS_REGION" --stack-name "$STACK" --query "Stacks[0].StackStatus" --output text || true)
                echo "Stack status: $STATUS"
                if [[ "$STATUS" == *"ROLLBACK"* || "$STATUS" == *"FAILED"* ]]; then
                  echo "üóëÔ∏è Deleting bad stack $STACK"
                  aws cloudformation delete-stack --region "$AWS_REGION" --stack-name "$STACK"
                  aws cloudformation wait stack-delete-complete --region "$AWS_REGION" --stack-name "$STACK" || true
                  UPB="${STACK}-uploads-${BUCKET_SUFFIX}"
                  echo "üßπ Force-empty S3 bucket: $UPB in $AWS_REGION"
                  while true; do
                    VERS=$(aws s3api list-object-versions --bucket "$UPB" --query '{Objects: Versions[].{Key:Key,VersionId:VersionId}}' --output json --region "$AWS_REGION" || echo '{"Objects":[]}')
                    if [ "$(echo "$VERS" | python -c 'import sys,json;print(len(json.load(sys.stdin)["Objects"]))')" = "0" ]; then break; fi
                    aws s3api delete-objects --bucket "$UPB" --delete "$VERS" --region "$AWS_REGION" || true
                  done
                  while true; do
                    MKRS=$(aws s3api list-object-versions --bucket "$UPB" --query '{Objects: DeleteMarkers[].{Key:Key,VersionId:VersionId}}' --output json --region "$AWS_REGION" || echo '{"Objects":[]}')
                    if [ "$(echo "$MKRS" | python -c 'import sys,json;print(len(json.load(sys.stdin)["Objects"]))')" = "0" ]; then break; fi
                    aws s3api delete-objects --bucket "$UPB" --delete "$MKRS" --region "$AWS_REGION" || true
                  done
                  aws s3api delete-bucket --bucket "$UPB" --region "$AWS_REGION" || true
                fi
              fi
            fi
          done
          echo "‚ùå All Aurora engine versions failed"
          exit 1

      - name: Export CloudFormation outputs
        if: steps.deploy.outcome == 'success'
        id: cfn-outputs
        run: |
          set -euo pipefail
          STACK="$STACK_NAME"
          if [ "${{ inputs.stage || '' }}" != "" ] && [ "${{ inputs.stage }}" != "prod" ]; then
            STACK="subscriber-migration-portal-${{ inputs.stage }}"
          fi
          OUT=$(aws cloudformation describe-stacks --region "$AWS_REGION" --stack-name "$STACK" --query "Stacks[0].Outputs" --output json)
          echo "CFN_OUTPUTS=$OUT" >> $GITHUB_ENV
          python3 << 'PY'
import os, json
outs=json.loads(os.environ['CFN_OUTPUTS'])
m={o['OutputKey']:o['OutputValue'] for o in outs}
with open(os.environ['GITHUB_ENV'],'a') as f:
  for k in ['ApiEndpoint','LegacyDbSecretArn','LegacyDbHost','SchemaInitFunctionName','UploadsBucketName']:
    f.write(f"{k}={m.get(k,'')}\n")
print('‚úÖ Outputs exported')
PY

      - name: Initialize Aurora schema (Lambda)
        if: steps.deploy.outcome == 'success'
        run: |
          set -euo pipefail
          echo "üîß Initializing schema via: $SCHEMA_INIT_FUNCTION_NAME in $AWS_REGION"
          aws lambda invoke \
            --region "$AWS_REGION" \
            --function-name "$SCHEMA_INIT_FUNCTION_NAME" \
            --payload '{}' \
            --log-type Tail \
            --query 'LogResult' \
            --output text \
            out.json | base64 -d || true
          echo
          cat out.json || true
          echo
          OK=$(cat out.json 2>/dev/null | python -c 'import sys,json;print(json.load(sys.stdin).get("success", False))' || echo False)
          if [ "$OK" != "True" ]; then
            echo "‚ùå Schema initialization reported errors (see logs above)"
            exit 1
          fi
          echo "‚úÖ Schema initialization completed"
