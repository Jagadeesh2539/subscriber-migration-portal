name: Deploy Subscriber Migration Portal

on:
  push:
    branches:
      - main
  workflow_dispatch:

env:
  STACK_NAME: subscriber-migration-stack-prod

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Check AWS Account ID
        run: |
          echo "Checking AWS identity..."
          aws sts get-caller-identity

      # Health-check stack to avoid manual deletions
      - name: Ensure stack is healthy or removed if stuck
        run: |
          set -e
          STATUS=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --query 'Stacks[0].StackStatus' --output text 2>/dev/null || true)
          echo "Current stack status: $STATUS"
          if [ "$STATUS" = "ROLLBACK_COMPLETE" ] || [ "$STATUS" = "ROLLBACK_FAILED" ] || [ "$STATUS" = "DELETE_FAILED" ]; then
            echo "Stack is stuck. Deleting..."
            aws cloudformation delete-stack --stack-name "$STACK_NAME"
            aws cloudformation wait stack-delete-complete --stack-name "$STACK_NAME"
            echo "Deleted stuck stack."
          fi
      
      # ---------------------
      # Step 1: Build & Deploy Backend
      # ---------------------
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install and Package All Backends
        run: |
          echo "--- Packaging Main Flask API ---"
          cd backend
          pip install --no-cache-dir -r requirements.txt -t .
          if [ -d "migration_processor" ] && [ -f "legacy_db.py" ]; then
            cp legacy_db.py migration_processor/
          fi
          zip -r ../backend.zip . -x "*.pyc" "__pycache__/*" "*.git*" "migration_processor/*"
          cd ..

          echo "--- Packaging Migration Processor ---"
          if [ -d "backend/migration_processor" ]; then
            cd backend/migration_processor
            if [ ! -f "requirements.txt" ]; then
               echo "::error:: File 'backend/migration_processor/requirements.txt' not found!"
               exit 1
            fi
            pip install --no-cache-dir -r requirements.txt -t .
            zip -r ../../processor.zip . -x "*.pyc" "__pycache__/*"
            cd ../..
          else
            echo "::error:: The 'backend/migration_processor' directory was not found. Please create it."
            exit 1
          fi

      - name: Deploy CloudFormation Stack
        run: |
          cd aws
          aws cloudformation deploy \
            --template-file cloudformation.yaml \
            --stack-name "$STACK_NAME" \
            --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \
            --parameter-overrides \
              DomainName='${{ secrets.DOMAIN_NAME }}' \
              LegacyDBPassword='${{ secrets.LEGACY_DB_PASSWORD }}'

      - name: Get CloudFormation Outputs
        id: cfn_outputs
        run: |
          STACK_NAME="${STACK_NAME}"
          FUNCTION_NAME=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='BackendLambdaName'].OutputValue" --output text)
          SUBSCRIBER_TABLE=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='SubscriberTableName'].OutputValue" --output text)
          AUDIT_TABLE=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='AuditLogTableName'].OutputValue" --output text)
          API_ID=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='BackendApiId'].OutputValue" --output text)
          API_URL=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='BackendApiUrl'].OutputValue" --output text)
          FRONTEND_URL=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='FrontendURL'].OutputValue" --output text)
          MIG_JOBS_TABLE=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='MigrationJobsTableName'].OutputValue" --output text)
          MIG_UPLOAD_BUCKET=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='MigrationUploadBucketName'].OutputValue" --output text)
          MIG_PROCESSOR_NAME=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='MigrationProcessorFunctionName'].OutputValue" --output text)
          LEGACY_DB_SECRET_ARN=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='LegacyDBSecretArn'].OutputValue" --output text)
          LEGACY_DB_HOST=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='LegacyDBEndpoint'].OutputValue" --output text)

          echo "function_name=$FUNCTION_NAME" >> $GITHUB_OUTPUT
          echo "subscriber_table=$SUBSCRIBER_TABLE" >> $GITHUB_OUTPUT
          echo "audit_table=$AUDIT_TABLE" >> $GITHUB_OUTPUT
          echo "api_id=$API_ID" >> $GITHUB_OUTPUT
          echo "frontend_url=$FRONTEND_URL" >> $GITHUB_OUTPUT
          echo "mig_jobs_table=$MIG_JOBS_TABLE" >> $GITHUB_OUTPUT
          echo "mig_upload_bucket=$MIG_UPLOAD_BUCKET" >> $GITHUB_OUTPUT
          echo "mig_processor_name=$MIG_PROCESSOR_NAME" >> $GITHUB_OUTPUT
          echo "legacy_db_secret_arn=$LEGACY_DB_SECRET_ARN" >> $GITHUB_OUTPUT
          echo "legacy_db_host=$LEGACY_DB_HOST" >> $GITHUB_OUTPUT

          echo "::notice:: API URL: $API_URL"

      - name: Update backend Lambda code
        run: |
          aws lambda update-function-code --function-name ${{ steps.cfn_outputs.outputs.function_name }} --zip-file fileb://backend.zip

      - name: Update MAIN Lambda Environment Variables
        run: |
          aws lambda update-function-configuration \
            --function-name ${{ steps.cfn_outputs.outputs.function_name }} \
            --environment "Variables={ \
              FRONTEND_DOMAIN_URL=${{ steps.cfn_outputs.outputs.frontend_url }}, \
              SUBSCRIBER_TABLE_NAME=${{ steps.cfn_outputs.outputs.subscriber_table }}, \
              AUDIT_LOG_TABLE_NAME=${{ steps.cfn_outputs.outputs.audit_table }}, \
              MIGRATION_JOBS_TABLE_NAME=${{ steps.cfn_outputs.outputs.mig_jobs_table }}, \
              MIGRATION_UPLOAD_BUCKET_NAME=${{ steps.cfn_outputs.outputs.mig_upload_bucket }}, \
              LEGACY_DB_SECRET_ARN=${{ steps.cfn_outputs.outputs.legacy_db_secret_arn }}, \
              LEGACY_DB_HOST=${{ steps.cfn_outputs.outputs.legacy_db_host }} \
            }"

      - name: Upload MIGRATION Processor code to S3
        env:
          FRONTEND_URL: ${{ steps.cfn_outputs.outputs.frontend_url }}
        run: |
          BUCKET_NAME=$(echo "$FRONTEND_URL" | sed -n 's|http://\([^.]*\)\.s3-website.*|\1|p')
          if [ -z "$BUCKET_NAME" ]; then echo "::error:: Could not extract bucket name from FrontendURL: $FRONTEND_URL"; exit 1; fi
          aws s3 cp processor.zip s3://$BUCKET_NAME/processor.zip

      - name: Update MIGRATION Processor Lambda code
        env:
          FRONTEND_URL: ${{ steps.cfn_outputs.outputs.frontend_url }}
          MIG_PROCESSOR_NAME: ${{ steps.cfn_outputs.outputs.mig_processor_name }}
        run: |
          BUCKET_NAME=$(echo "$FRONTEND_URL" | sed -n 's|http://\([^.]*\)\.s3-website.*|\1|p')
          if [ -z "$BUCKET_NAME" ]; then echo "::error:: Could not extract bucket name from FrontendURL: $FRONTEND_URL"; exit 1; fi
          aws lambda update-function-code --function-name "$MIG_PROCESSOR_NAME" --s3-bucket "$BUCKET_NAME" --s3-key "processor.zip"
      
      - name: Update MIGRATION Lambda Environment Variables
        run: |
           aws lambda update-function-configuration \
            --function-name ${{ steps.cfn_outputs.outputs.mig_processor_name }} \
            --environment "Variables={ \
              SUBSCRIBER_TABLE_NAME=${{ steps.cfn_outputs.outputs.subscriber_table }}, \
              AUDIT_LOG_TABLE_NAME=${{ steps.cfn_outputs.outputs.audit_table }}, \
              MIGRATION_JOBS_TABLE_NAME=${{ steps.cfn_outputs.outputs.mig_jobs_table }}, \
              REPORT_BUCKET_NAME=${{ steps.cfn_outputs.outputs.mig_upload_bucket }}, \
              LEGACY_DB_SECRET_ARN=${{ steps.cfn_outputs.outputs.legacy_db_secret_arn }}, \
              LEGACY_DB_HOST=${{ steps.cfn_outputs.outputs.legacy_db_host }} \
            }"

      - name: Wait for Lambda function updates to complete
        run: |
          aws lambda wait function-updated --function-name ${{ steps.cfn_outputs.outputs.function_name }}
          if [ -n "${{ steps.cfn_outputs.outputs.mig_processor_name }}" ]; then
            aws lambda wait function-updated --function-name ${{ steps.cfn_outputs.outputs.mig_processor_name }}
          fi

      - name: Configure S3 bucket notification for migration processor
        run: |
          MIG_PROCESSOR_ARN=$(aws lambda get-function --function-name "${{ steps.cfn_outputs.outputs.mig_processor_name }}" --query 'Configuration.FunctionArn' --output text)
          aws s3api put-bucket-notification-configuration \
            --bucket "${{ steps.cfn_outputs.outputs.mig_upload_bucket }}" \
            --notification-configuration '{
              "LambdaFunctionConfigurations": [{
                "LambdaFunctionArn": "'"$MIG_PROCESSOR_ARN"'",
                "Events": ["s3:ObjectCreated:Put"],
                "Filter": {"Key": {"FilterRules": [
                  {"Name":"prefix","Value":"uploads/"},
                  {"Name":"suffix","Value":".csv"}
                ]}}
              }]}'

      - name: Deploy API Gateway Stage
        env:
          API_ID: ${{ steps.cfn_outputs.outputs.api_id }}
        run: |
          DEPLOYMENT_ID=$(aws apigateway create-deployment --rest-api-id "$API_ID" --description "CI/CD update $(date)" --query 'id' --output text)
          if [ -z "$DEPLOYMENT_ID" ]; then echo "Failed to create deployment"; exit 1; fi
          aws apigateway update-stage --rest-api-id "$API_ID" --stage-name prod --patch-operations op='replace',path='/deploymentId',value=$DEPLOYMENT_ID
          echo "API Gateway stage 'prod' updated"

      # ---------------------
      # Step 2: Build & Deploy Frontend
      # ---------------------
      - name: Install frontend dependencies
        run: |
          cd frontend
          npm install

      - name: Build frontend
        run: |
          cd frontend
          npm run build

      - name: Deploy frontend to S3
        env:
          FRONTEND_URL: ${{ steps.cfn_outputs.outputs.frontend_url }}
        run: |
          BUCKET_NAME=$(echo "$FRONTEND_URL" | sed -n 's|http://\([^.]*\)\.s3-website.*|\1|p')
          if [ -z "$BUCKET_NAME" ]; then echo "::error:: Could not extract bucket name from FrontendURL: $FRONTEND_URL"; exit 1; fi
          aws s3 sync frontend/build/ s3://$BUCKET_NAME --delete

      - name: Workflow completed successfully
        run: |
          echo "🎉 Deployment completed successfully!"
          echo "Frontend URL: ${{ steps.cfn_outputs.outputs.frontend_url }}"
          echo "API Gateway URL: https://${{ steps.cfn_outputs.outputs.api_id }}.execute-api.us-east-1.amazonaws.com/prod"
          echo "Migration Upload Bucket: ${{ steps.cfn_outputs.outputs.mig_upload_bucket }}"