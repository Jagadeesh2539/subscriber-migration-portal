name: üöÄ Deploy Subscriber Migration Portal

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment Environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod
      force_recreate:
        description: 'Force recreate CloudFormation stack'
        required: false
        default: false
        type: boolean
      cleanup_resources:
        description: 'Cleanup failed/orphaned resources'
        required: false
        default: false
        type: boolean

env:
  AWS_DEFAULT_REGION: us-east-1
  SAM_CLI_TELEMETRY: 0
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  # ==========================================
  # PRE-DEPLOYMENT VALIDATION
  # ==========================================
  validate:
    name: üîç Pre-deployment Validation
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.set-env.outputs.environment }}
      stack-name: ${{ steps.set-env.outputs.stack-name }}
      force-recreate: ${{ steps.set-env.outputs.force-recreate }}
      cleanup-resources: ${{ steps.set-env.outputs.cleanup-resources }}
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: üéØ Set environment variables
        id: set-env
        run: |
          set -euo pipefail
          
          # Determine environment
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            ENV="${{ github.event.inputs.environment }}"
            FORCE_RECREATE="${{ github.event.inputs.force_recreate }}"
            CLEANUP_RESOURCES="${{ github.event.inputs.cleanup_resources }}"
          elif [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            ENV="prod"
            FORCE_RECREATE="false"
            CLEANUP_RESOURCES="false"
          elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
            ENV="staging"
            FORCE_RECREATE="false"
            CLEANUP_RESOURCES="false"
          else
            ENV="dev"
            FORCE_RECREATE="false"
            CLEANUP_RESOURCES="false"
          fi
          
          STACK_NAME="subscriber-migration-portal-${ENV}"
          
          echo "environment=${ENV}" >> $GITHUB_OUTPUT
          echo "stack-name=${STACK_NAME}" >> $GITHUB_OUTPUT
          echo "force-recreate=${FORCE_RECREATE}" >> $GITHUB_OUTPUT
          echo "cleanup-resources=${CLEANUP_RESOURCES}" >> $GITHUB_OUTPUT
          
          echo "üéØ Deployment Target: ${ENV}"
          echo "üì¶ Stack Name: ${STACK_NAME}"
          echo "üîÑ Force Recreate: ${FORCE_RECREATE}"
          echo "üßπ Cleanup Resources: ${CLEANUP_RESOURCES}"

      - name: üõ†Ô∏è Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: üõ†Ô∏è Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: üìã Performing comprehensive template validation...
        run: |
          set -euo pipefail
          echo "üîç Validating SAM template structure..."
          
          # Install SAM CLI
          pip install aws-sam-cli
          
          # Validate template syntax
          cd aws
          sam validate --template template.yaml --region ${{ env.AWS_DEFAULT_REGION }}
          
          echo "‚úÖ SAM template validation passed"
          
          # Validate Lambda function code exists
          echo "üîç Validating Lambda function structure..."
          
          REQUIRED_FUNCTIONS=(
            "lambda/authorizer/handler.py"
            "lambda/auth/login.py"
            "lambda/dashboard/stats.py"
            "lambda/subscribers/get_subscribers.py"
            "layers/common/python/common_utils.py"
          )
          
          for func in "${REQUIRED_FUNCTIONS[@]}"; do
            if [[ ! -f "$func" ]]; then
              echo "‚ùå Missing required Lambda function: $func"
              exit 1
            fi
            echo "‚úÖ Found: $func"
          done
          
          echo "üéâ All Lambda functions validated successfully"

      - name: üîç Frontend validation
        run: |
          set -euo pipefail
          echo "üîç Validating frontend structure..."
          
          cd frontend
          
          # Check package.json exists and is valid
          if [[ ! -f package.json ]]; then
            echo "‚ùå package.json not found"
            exit 1
          fi
          
          # Validate package.json syntax
          node -e "JSON.parse(require('fs').readFileSync('package.json', 'utf8'))"
          echo "‚úÖ package.json is valid JSON"
          
          # Check required files
          REQUIRED_FILES=(
            "src/App.js"
            "src/api/apiClient.js"
            "src/hooks/useApiQueries.js"
            "public/index.html"
          )
          
          for file in "${REQUIRED_FILES[@]}"; do
            if [[ ! -f "$file" ]]; then
              echo "‚ùå Missing required frontend file: $file"
              exit 1
            fi
            echo "‚úÖ Found: $file"
          done
          
          echo "üéâ Frontend validation completed successfully"

  # ==========================================
  # AWS INFRASTRUCTURE DEPLOYMENT
  # ==========================================
  deploy-infrastructure:
    name: üèóÔ∏è Deploy AWS Infrastructure
    runs-on: ubuntu-latest
    needs: validate
    environment: ${{ needs.validate.outputs.environment }}
    outputs:
      api-endpoint: ${{ steps.deploy.outputs.api-endpoint }}
      upload-bucket: ${{ steps.deploy.outputs.upload-bucket }}
      subscriber-table: ${{ steps.deploy.outputs.subscriber-table }}
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üîß Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: üõ†Ô∏è Setup Python and SAM
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: üì¶ Install SAM CLI
        run: |
          pip install aws-sam-cli boto3
          sam --version

      - name: üóÑÔ∏è Caching stack outputs to avoid repeated API calls...
        id: cache-stack
        run: |
          set -euo pipefail
          
          STACK_NAME="${{ needs.validate.outputs.stack-name }}"
          CACHE_FILE="/tmp/stack-${STACK_NAME}-cache.json"
          
          echo "üìã Checking if stack exists: ${STACK_NAME}"
          
          if aws cloudformation describe-stacks --stack-name "${STACK_NAME}" --region ${{ env.AWS_DEFAULT_REGION }} 2>/dev/null; then
            echo "stack-exists=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Stack exists: ${STACK_NAME}"
            
            # Cache current outputs
            aws cloudformation describe-stacks \
              --stack-name "${STACK_NAME}" \
              --region ${{ env.AWS_DEFAULT_REGION }} \
              --query 'Stacks[0].Outputs' > "${CACHE_FILE}"
            
            echo "üì¶ Stack outputs cached"
          else
            echo "stack-exists=false" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è Stack does not exist: ${STACK_NAME}"
          fi

      - name: üßπ Cleanup failed/orphaned resources
        if: ${{ needs.validate.outputs.cleanup-resources == 'true' }}
        run: |
          set -euo pipefail
          
          STACK_NAME="${{ needs.validate.outputs.stack-name }}"
          
          echo "üßπ Cleaning up failed/orphaned resources for: ${STACK_NAME}"
          
          # Check for failed stacks
          FAILED_STACKS=$(aws cloudformation list-stacks \
            --stack-status-filter CREATE_FAILED UPDATE_FAILED DELETE_FAILED ROLLBACK_FAILED \
            --query "StackSummaries[?contains(StackName, '${STACK_NAME}')].StackName" \
            --output text || echo "")
          
          if [[ -n "${FAILED_STACKS}" ]]; then
            echo "üîÑ Found failed stacks: ${FAILED_STACKS}"
            for stack in ${FAILED_STACKS}; do
              echo "üóëÔ∏è Deleting failed stack: ${stack}"
              aws cloudformation delete-stack --stack-name "${stack}" || echo "‚ö†Ô∏è Failed to delete ${stack}"
            done
          else
            echo "‚úÖ No failed stacks found"
          fi
          
          # Cleanup orphaned S3 buckets
          echo "üßπ Cleaning up orphaned S3 buckets..."
          ORPHANED_BUCKETS=$(aws s3api list-buckets \
            --query "Buckets[?contains(Name, '${STACK_NAME}')].Name" \
            --output text || echo "")
          
          if [[ -n "${ORPHANED_BUCKETS}" ]]; then
            for bucket in ${ORPHANED_BUCKETS}; do
              echo "üóëÔ∏è Checking bucket: ${bucket}"
              # Only delete if bucket is empty or force cleanup
              aws s3 rb "s3://${bucket}" --force || echo "‚ö†Ô∏è Could not delete bucket ${bucket}"
            done
          fi

      - name: üîÑ Force recreate stack
        if: ${{ needs.validate.outputs.force-recreate == 'true' && steps.cache-stack.outputs.stack-exists == 'true' }}
        run: |
          set -euo pipefail
          
          STACK_NAME="${{ needs.validate.outputs.stack-name }}"
          
          echo "üîÑ Force recreating stack: ${STACK_NAME}"
          
          # Delete existing stack
          echo "üóëÔ∏è Deleting existing stack..."
          aws cloudformation delete-stack --stack-name "${STACK_NAME}"
          
          # Wait for deletion to complete
          echo "‚è≥ Waiting for stack deletion to complete..."
          aws cloudformation wait stack-delete-complete --stack-name "${STACK_NAME}" || {
            echo "‚ö†Ô∏è Stack deletion wait timed out or failed, continuing..."
          }
          
          echo "‚úÖ Stack deleted successfully"

      - name: üì¶ Build Lambda Layer
        run: |
          set -euo pipefail
          
          echo "üîß Building Lambda layer with dependencies..."
          cd aws/layers/common
          
          # Create python directory structure
          mkdir -p python
          
          # Copy common utilities
          cp common_utils.py python/
          
          # Install dependencies
          if [[ -f requirements.txt ]]; then
            echo "üì¶ Installing layer dependencies..."
            pip install -r requirements.txt -t python/ --no-deps
            
            # Install dependencies with dependencies
            pip install -r requirements.txt -t python/
          fi
          
          echo "‚úÖ Lambda layer built successfully"

      - name: üèóÔ∏è Ultra-robust CloudFormation deployment...
        id: deploy
        run: |
          set -euo pipefail
          
          cd aws
          
          STACK_NAME="${{ needs.validate.outputs.stack-name }}"
          ENVIRONMENT="${{ needs.validate.outputs.environment }}"
          
          # Generate secure JWT secret
          JWT_SECRET=$(openssl rand -base64 64)
          
          # Set CORS origins based on environment
          case "${ENVIRONMENT}" in
            "prod")
              CORS_ORIGINS="https://yourdomain.com"
              ;;
            "staging")
              CORS_ORIGINS="https://staging.yourdomain.com"
              ;;
            *)
              CORS_ORIGINS="https://localhost:3000,http://localhost:3000"
              ;;
          esac
          
          echo "üöÄ Deploying SAM application..."
          echo "üì¶ Stack: ${STACK_NAME}"
          echo "üåç Environment: ${ENVIRONMENT}"
          echo "üîó CORS Origins: ${CORS_ORIGINS}"
          
          # Create S3 bucket for deployment artifacts
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          DEPLOYMENT_BUCKET="sam-deployment-${ACCOUNT_ID}-${{ env.AWS_DEFAULT_REGION }}"
          
          # Create bucket if it doesn't exist
          if ! aws s3api head-bucket --bucket "${DEPLOYMENT_BUCKET}" 2>/dev/null; then
            echo "üì¶ Creating deployment bucket: ${DEPLOYMENT_BUCKET}"
            aws s3api create-bucket --bucket "${DEPLOYMENT_BUCKET}"
            aws s3api put-bucket-versioning --bucket "${DEPLOYMENT_BUCKET}" --versioning-configuration Status=Enabled
          fi
          
          # Build SAM application
          echo "üî® Building SAM application..."
          sam build --template template.yaml
          
          # Deploy with retries
          MAX_RETRIES=3
          RETRY_COUNT=0
          
          while [[ ${RETRY_COUNT} -lt ${MAX_RETRIES} ]]; do
            echo "üöÄ Deployment attempt $((RETRY_COUNT + 1))/${MAX_RETRIES}"
            
            if sam deploy \
              --stack-name "${STACK_NAME}" \
              --region ${{ env.AWS_DEFAULT_REGION }} \
              --s3-bucket "${DEPLOYMENT_BUCKET}" \
              --parameter-overrides \
                Stage="${ENVIRONMENT}" \
                JwtSecret="${JWT_SECRET}" \
                CorsOrigins="${CORS_ORIGINS}" \
              --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \
              --no-fail-on-empty-changeset \
              --no-confirm-changeset; then
              
              echo "‚úÖ SAM deployment successful!"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [[ ${RETRY_COUNT} -lt ${MAX_RETRIES} ]]; then
                echo "‚ö†Ô∏è Deployment failed, retrying in 30 seconds..."
                sleep 30
              else
                echo "‚ùå Deployment failed after ${MAX_RETRIES} attempts"
                exit 1
              fi
            fi
          done
          
          # Get stack outputs
          echo "üìã Retrieving stack outputs..."
          
          API_ENDPOINT=$(aws cloudformation describe-stacks \
            --stack-name "${STACK_NAME}" \
            --region ${{ env.AWS_DEFAULT_REGION }} \
            --query 'Stacks[0].Outputs[?OutputKey==`ApiEndpoint`].OutputValue' \
            --output text)
          
          UPLOAD_BUCKET=$(aws cloudformation describe-stacks \
            --stack-name "${STACK_NAME}" \
            --region ${{ env.AWS_DEFAULT_REGION }} \
            --query 'Stacks[0].Outputs[?OutputKey==`UploadBucketName`].OutputValue' \
            --output text)
          
          SUBSCRIBER_TABLE=$(aws cloudformation describe-stacks \
            --stack-name "${STACK_NAME}" \
            --region ${{ env.AWS_DEFAULT_REGION }} \
            --query 'Stacks[0].Outputs[?OutputKey==`SubscriberTableName`].OutputValue' \
            --output text)
          
          echo "api-endpoint=${API_ENDPOINT}" >> $GITHUB_OUTPUT
          echo "upload-bucket=${UPLOAD_BUCKET}" >> $GITHUB_OUTPUT
          echo "subscriber-table=${SUBSCRIBER_TABLE}" >> $GITHUB_OUTPUT
          
          echo "üéâ Infrastructure deployment completed!"
          echo "üîó API Endpoint: ${API_ENDPOINT}"
          echo "ü™£ Upload Bucket: ${UPLOAD_BUCKET}"
          echo "üóÉÔ∏è Subscriber Table: ${SUBSCRIBER_TABLE}"

      - name: üêõ Debugging and fixing Lambda configuration...
        run: |
          set -euo pipefail
          
          echo "üîç Debugging Lambda function configurations..."
          
          STACK_NAME="${{ needs.validate.outputs.stack-name }}"
          
          # Get all Lambda functions in the stack
          LAMBDA_FUNCTIONS=$(aws cloudformation list-stack-resources \
            --stack-name "${STACK_NAME}" \
            --query 'StackResourceSummaries[?ResourceType==`AWS::Lambda::Function`].PhysicalResourceId' \
            --output text)
          
          echo "üìã Found Lambda functions: ${LAMBDA_FUNCTIONS}"
          
          for func in ${LAMBDA_FUNCTIONS}; do
            echo "üîç Checking function: ${func}"
            
            # Get function configuration
            FUNC_CONFIG=$(aws lambda get-function-configuration --function-name "${func}")
            
            # Check runtime
            RUNTIME=$(echo "${FUNC_CONFIG}" | jq -r '.Runtime')
            echo "  Runtime: ${RUNTIME}"
            
            # Check timeout
            TIMEOUT=$(echo "${FUNC_CONFIG}" | jq -r '.Timeout')
            echo "  Timeout: ${TIMEOUT}s"
            
            # Check memory
            MEMORY=$(echo "${FUNC_CONFIG}" | jq -r '.MemorySize')
            echo "  Memory: ${MEMORY}MB"
            
            # Check environment variables
            echo "  Environment Variables:"
            echo "${FUNC_CONFIG}" | jq -r '.Environment.Variables // {} | to_entries[] | "    \(.key): \(.value)"'
            
            # Test function (for non-authorizer functions)
            if [[ ! "${func}" =~ [Aa]uthorizer ]]; then
              echo "üß™ Testing function: ${func}"
              aws lambda invoke \
                --function-name "${func}" \
                --payload '{}' \
                "/tmp/${func}-test.json" || echo "‚ö†Ô∏è Function test failed (expected for some functions)"
            fi
            
            echo "‚úÖ Function check completed: ${func}"
          done

  # ==========================================
  # DATABASE INITIALIZATION
  # ==========================================
  initialize-database:
    name: üóÑÔ∏è Initialize Database Schema
    runs-on: ubuntu-latest
    needs: [validate, deploy-infrastructure]
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üîß Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: üõ†Ô∏è Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: üì¶ Install dependencies
        run: |
          pip install boto3 bcrypt

      - name: üóÑÔ∏è Database schema initialization...
        run: |
          set -euo pipefail
          
          SUBSCRIBER_TABLE="${{ needs.deploy-infrastructure.outputs.subscriber-table }}"
          
          echo "üóÑÔ∏è Initializing database schema for: ${SUBSCRIBER_TABLE}"
          
          # Create initialization script
          cat > initialize_db.py << 'EOF'
          import boto3
          import json
          import bcrypt
          from datetime import datetime, timedelta
          import os
          
          def hash_password(password):
              salt = bcrypt.gensalt()
              hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
              return f"bcrypt${hashed.decode('utf-8')}"
          
          def initialize_database():
              dynamodb = boto3.resource('dynamodb')
              secrets_client = boto3.client('secretsmanager')
              
              # Initialize user credentials in Secrets Manager
              users_secret = {
                  "admin": {
                      "password_hash": hash_password("SecureAdmin123!"),
                      "role": "admin",
                      "permissions": ["read", "write", "admin"]
                  },
                  "operator": {
                      "password_hash": hash_password("SecureOperator123!"),
                      "role": "operator", 
                      "permissions": ["read", "write"]
                  },
                  "guest": {
                      "password_hash": hash_password("SecureGuest123!"),
                      "role": "guest",
                      "permissions": ["read"]
                  }
              }
              
              # Update users secret
              stack_name = os.environ.get('STACK_NAME', 'subscriber-migration-portal')
              secret_name = f"{stack_name}-users"
              
              try:
                  secrets_client.update_secret(
                      SecretId=secret_name,
                      SecretString=json.dumps(users_secret)
                  )
                  print(f"‚úÖ Updated users secret: {secret_name}")
              except Exception as e:
                  print(f"‚ö†Ô∏è Could not update users secret: {e}")
              
              # Add sample data to subscriber table if empty
              table_name = os.environ.get('SUBSCRIBER_TABLE')
              if table_name:
                  table = dynamodb.Table(table_name)
                  
                  # Check if table is empty
                  response = table.scan(Limit=1)
                  if response['Count'] == 0:
                      print(f"üìù Adding sample data to: {table_name}")
                      
                      sample_subscribers = [
                          {
                              "uid": "USER001",
                              "msisdn": "+1234567890",
                              "imsi": "123456789012345", 
                              "status": "ACTIVE",
                              "plan_id": "PREMIUM",
                              "created_at": datetime.utcnow().isoformat(),
                              "updated_at": datetime.utcnow().isoformat()
                          },
                          {
                              "uid": "USER002",
                              "msisdn": "+1234567891",
                              "imsi": "123456789012346",
                              "status": "ACTIVE", 
                              "plan_id": "BASIC",
                              "created_at": datetime.utcnow().isoformat(),
                              "updated_at": datetime.utcnow().isoformat()
                          }
                      ]
                      
                      for subscriber in sample_subscribers:
                          table.put_item(Item=subscriber)
                          print(f"‚úÖ Added subscriber: {subscriber['uid']}")
                  else:
                      print(f"‚ÑπÔ∏è Table {table_name} already contains data")
              
              print("üéâ Database initialization completed!")
          
          if __name__ == "__main__":
              initialize_database()
          EOF
          
          # Run initialization
          STACK_NAME="${{ needs.validate.outputs.stack-name }}" \
          SUBSCRIBER_TABLE="${SUBSCRIBER_TABLE}" \
          python initialize_db.py
          
          echo "‚úÖ Database schema initialization completed!"

  # ==========================================
  # FRONTEND DEPLOYMENT
  # ==========================================
  deploy-frontend:
    name: üåê Deploy React Frontend
    runs-on: ubuntu-latest
    needs: [validate, deploy-infrastructure, initialize-database]
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üîß Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: üõ†Ô∏è Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: üåê Deploying React frontend...
        run: |
          set -euo pipefail
          
          echo "üì¶ Building frontend from: frontend"
          cd frontend

      - name: üì¶ Installing frontend dependencies with cache management...
        run: |
          set -euo pipefail
          
          echo "üßπ Clearing npm cache to prevent EINTEGRITY errors..."
          
          # Set up npm configuration
          NPM_CACHE_DIR="/tmp/npm-cache-$$"
          mkdir -p "${NPM_CACHE_DIR}"
          
          npm config set cache "${NPM_CACHE_DIR}"
          npm config set fetch-retries 3
          npm config set fetch-retry-mintimeout 10000
          npm config set fetch-retry-maxtimeout 60000
          
          echo "üîß npm configuration:"
          echo "  Cache directory: ${NPM_CACHE_DIR}"
          echo "  Retry settings: 3 attempts with exponential backoff"
          
          # Try npm ci first
          if npm ci --prefer-offline --no-audit 2>/dev/null; then
            echo "‚úÖ npm ci succeeded"
          else
            echo "‚ö†Ô∏è npm ci failed, trying cache verification and cleanup..."
            
            # Verify and fix cache
            npm cache verify
            
            echo "üîÑ Attempting fresh npm install..."
            
            # Remove node_modules and package-lock.json
            rm -rf node_modules package-lock.json
            
            # Fresh install with force flag
            npm install --no-audit --prefer-offline || {
              echo "üîÑ Standard install failed, trying with --force..."
              npm install --force --no-audit
            }
            
            echo "‚úÖ npm install completed"
          fi
          
          # Verify installation
          echo "üîç Verifying installed packages..."
          npm list --depth=0 || echo "‚ö†Ô∏è Some packages might have issues, but continuing..."

      - name: üèóÔ∏è Build production frontend
        run: |
          set -euo pipefail
          
          cd frontend
          
          # Create production environment file
          cat > .env.production << EOF
          REACT_APP_API_URL=${{ needs.deploy-infrastructure.outputs.api-endpoint }}
          REACT_APP_STAGE=${{ needs.validate.outputs.environment }}
          REACT_APP_DEBUG_MODE=false
          REACT_APP_ENABLE_ANALYTICS=true
          REACT_APP_ENABLE_MONITORING=true
          REACT_APP_ENABLE_PWA=true
          EOF
          
          echo "üìã Production environment configuration:"
          cat .env.production
          
          # Build with production optimizations
          echo "üî® Building React application..."
          NODE_ENV=production npm run build
          
          # Verify build
          if [[ ! -d "build" ]]; then
            echo "‚ùå Build directory not created"
            exit 1
          fi
          
          BUILD_SIZE=$(du -sh build | cut -f1)
          echo "üì¶ Build completed successfully (${BUILD_SIZE})"
          
          # List build contents
          echo "üìã Build contents:"
          find build -type f -name "*.js" -o -name "*.css" -o -name "*.html" | head -20

      - name: üåê Deploy to S3 and configure website
        run: |
          set -euo pipefail
          
          cd frontend
          
          # Create S3 bucket for frontend
          FRONTEND_BUCKET="${{ needs.validate.outputs.stack-name }}-frontend"
          
          echo "ü™£ Setting up S3 bucket: ${FRONTEND_BUCKET}"
          
          # Create bucket if it doesn't exist
          if ! aws s3api head-bucket --bucket "${FRONTEND_BUCKET}" 2>/dev/null; then
            echo "üì¶ Creating frontend bucket: ${FRONTEND_BUCKET}"
            
            if [[ "${{ env.AWS_DEFAULT_REGION }}" == "us-east-1" ]]; then
              aws s3api create-bucket --bucket "${FRONTEND_BUCKET}"
            else
              aws s3api create-bucket \
                --bucket "${FRONTEND_BUCKET}" \
                --create-bucket-configuration LocationConstraint=${{ env.AWS_DEFAULT_REGION }}
            fi
          fi
          
          echo "üîß Configuring CORS and S3 website settings..."
          
          # Configure CORS
          cat > cors-config.json << EOF
          {
            "CORSRules": [
              {
                "AllowedHeaders": ["*"],
                "AllowedMethods": ["GET", "PUT", "POST", "DELETE"],
                "AllowedOrigins": ["*"],
                "MaxAgeSeconds": 3000
              }
            ]
          }
          EOF
          
          aws s3api put-bucket-cors \
            --bucket "${FRONTEND_BUCKET}" \
            --cors-configuration file://cors-config.json
          
          # Configure website hosting
          aws s3api put-bucket-website \
            --bucket "${FRONTEND_BUCKET}" \
            --website-configuration '{
              "IndexDocument": {"Suffix": "index.html"},
              "ErrorDocument": {"Key": "index.html"}
            }'
          
          # Make bucket public for website hosting
          aws s3api put-bucket-policy \
            --bucket "${FRONTEND_BUCKET}" \
            --policy '{
              "Version": "2012-10-17",
              "Statement": [
                {
                  "Sid": "PublicReadGetObject",
                  "Effect": "Allow",
                  "Principal": "*",
                  "Action": "s3:GetObject",
                  "Resource": "arn:aws:s3:::${FRONTEND_BUCKET}/*"
                }
              ]
            }'
          
          # Sync build to S3
          echo "üì§ Uploading frontend to S3..."
          aws s3 sync build/ "s3://${FRONTEND_BUCKET}" \
            --delete \
            --cache-control "public, max-age=31536000" \
            --exclude "*.html" \
            --exclude "service-worker.js"
          
          # Upload HTML files with no-cache
          aws s3 sync build/ "s3://${FRONTEND_BUCKET}" \
            --exclude "*" \
            --include "*.html" \
            --include "service-worker.js" \
            --cache-control "public, max-age=0, must-revalidate"
          
          # Get website URL
          WEBSITE_URL="http://${FRONTEND_BUCKET}.s3-website-${{ env.AWS_DEFAULT_REGION }}.amazonaws.com"
          
          echo "üéâ Frontend deployed successfully!"
          echo "üîó Website URL: ${WEBSITE_URL}"
          
          # Save URL to GitHub output
          echo "website-url=${WEBSITE_URL}" >> $GITHUB_OUTPUT

  # ==========================================
  # COMPREHENSIVE SMOKE TESTS
  # ==========================================
  smoke-tests:
    name: üß™ Run Comprehensive Smoke Tests
    runs-on: ubuntu-latest
    needs: [validate, deploy-infrastructure, initialize-database, deploy-frontend]
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üîß Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: üõ†Ô∏è Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: üì¶ Install test dependencies
        run: |
          pip install requests boto3 pytest

      - name: üß™ Run comprehensive smoke tests...
        run: |
          set -euo pipefail
          
          API_ENDPOINT="${{ needs.deploy-infrastructure.outputs.api-endpoint }}"
          
          echo "üß™ Running comprehensive smoke tests against: ${API_ENDPOINT}"
          
          # Create smoke test script
          cat > smoke_tests.py << 'EOF'
          import requests
          import json
          import time
          import sys
          import os
          
          def test_health_endpoint(base_url):
              print("üîç Testing health endpoint...")
              try:
                  response = requests.get(f"{base_url}/health", timeout=10)
                  assert response.status_code == 200, f"Expected 200, got {response.status_code}"
                  
                  data = response.json()
                  assert data.get('status') == 'success', f"Expected success status, got {data.get('status')}"
                  
                  print(f"‚úÖ Health check passed: {data}")
                  return True
              except Exception as e:
                  print(f"‚ùå Health check failed: {e}")
                  return False
          
          def test_auth_login(base_url):
              print("üîç Testing authentication...")
              try:
                  # Test login with default admin credentials
                  login_data = {
                      "username": "admin",
                      "password": "SecureAdmin123!"
                  }
                  
                  response = requests.post(
                      f"{base_url}/auth/login", 
                      json=login_data,
                      timeout=10
                  )
                  
                  if response.status_code == 200:
                      data = response.json()
                      token = data.get('data', {}).get('token')
                      assert token, "No token returned"
                      print(f"‚úÖ Authentication successful")
                      return token
                  else:
                      print(f"‚ö†Ô∏è Authentication failed with status {response.status_code}: {response.text}")
                      return None
              except Exception as e:
                  print(f"‚ùå Authentication test failed: {e}")
                  return None
          
          def test_protected_endpoint(base_url, token):
              print("üîç Testing protected endpoint...")
              try:
                  headers = {"Authorization": f"Bearer {token}"}
                  response = requests.get(
                      f"{base_url}/dashboard/stats",
                      headers=headers,
                      timeout=10
                  )
                  
                  if response.status_code == 200:
                      data = response.json()
                      print(f"‚úÖ Protected endpoint accessible: {data.get('data', {})}")
                      return True
                  else:
                      print(f"‚ö†Ô∏è Protected endpoint failed with status {response.status_code}")
                      return False
              except Exception as e:
                  print(f"‚ùå Protected endpoint test failed: {e}")
                  return False
          
          def test_database_connectivity(base_url, token):
              print("üîç Testing database connectivity...")
              try:
                  headers = {"Authorization": f"Bearer {token}"}
                  response = requests.get(
                      f"{base_url}/subscribers?limit=5",
                      headers=headers,
                      timeout=15
                  )
                  
                  if response.status_code == 200:
                      data = response.json()
                      subscribers = data.get('data', {}).get('subscribers', [])
                      print(f"‚úÖ Database connectivity successful. Found {len(subscribers)} subscribers")
                      return True
                  else:
                      print(f"‚ö†Ô∏è Database test failed with status {response.status_code}")
                      return False
              except Exception as e:
                  print(f"‚ùå Database connectivity test failed: {e}")
                  return False
          
          def run_smoke_tests():
              base_url = os.environ.get('API_ENDPOINT', '').rstrip('/')
              if not base_url:
                  print("‚ùå API_ENDPOINT environment variable not set")
                  return False
              
              print(f"üöÄ Starting smoke tests for: {base_url}")
              
              # Wait for API to be ready
              print("‚è≥ Waiting for API to be ready...")
              for i in range(12):  # 2 minutes max
                  try:
                      response = requests.get(f"{base_url}/health", timeout=5)
                      if response.status_code == 200:
                          print("‚úÖ API is ready")
                          break
                  except:
                      pass
                  print(f"‚è≥ Waiting... ({i+1}/12)")
                  time.sleep(10)
              else:
                  print("‚ùå API did not become ready in time")
                  return False
              
              # Run tests
              tests_passed = 0
              total_tests = 4
              
              # Test 1: Health check
              if test_health_endpoint(base_url):
                  tests_passed += 1
              
              # Test 2: Authentication
              token = test_auth_login(base_url)
              if token:
                  tests_passed += 1
                  
                  # Test 3: Protected endpoint (only if auth succeeded)
                  if test_protected_endpoint(base_url, token):
                      tests_passed += 1
                  
                  # Test 4: Database connectivity (only if auth succeeded)
                  if test_database_connectivity(base_url, token):
                      tests_passed += 1
              
              print(f"\nüìä Test Results: {tests_passed}/{total_tests} tests passed")
              
              if tests_passed == total_tests:
                  print("üéâ All smoke tests passed!")
                  return True
              else:
                  print("‚ö†Ô∏è Some smoke tests failed")
                  return tests_passed >= (total_tests * 0.75)  # Pass if 75% of tests pass
          
          if __name__ == "__main__":
              success = run_smoke_tests()
              sys.exit(0 if success else 1)
          EOF
          
          # Run smoke tests
          API_ENDPOINT="${API_ENDPOINT}" python smoke_tests.py

  # ==========================================
  # POST-DEPLOYMENT CONFIGURATION
  # ==========================================
  post-deployment-checks:
    name: üîß Post-deployment Configuration Checks
    runs-on: ubuntu-latest
    needs: [validate, deploy-infrastructure, initialize-database, deploy-frontend, smoke-tests]
    
    steps:
      - name: üîß Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: üîß Post configuration checks...
        run: |
          set -euo pipefail
          
          STACK_NAME="${{ needs.validate.outputs.stack-name }}"
          API_ENDPOINT="${{ needs.deploy-infrastructure.outputs.api-endpoint }}"
          UPLOAD_BUCKET="${{ needs.deploy-infrastructure.outputs.upload-bucket }}"
          
          echo "üîç Running post-deployment configuration checks..."
          
          # Check CloudWatch logs
          echo "üìã Checking CloudWatch log groups..."
          LOG_GROUPS=$(aws logs describe-log-groups \
            --log-group-name-prefix "/aws/lambda/${STACK_NAME}" \
            --query 'logGroups[].logGroupName' \
            --output text)
          
          if [[ -n "${LOG_GROUPS}" ]]; then
            echo "‚úÖ Found log groups: ${LOG_GROUPS}"
          else
            echo "‚ö†Ô∏è No log groups found"
          fi
          
          # Check DynamoDB table status
          echo "üìã Checking DynamoDB table status..."
          TABLE_STATUS=$(aws dynamodb describe-table \
            --table-name "${{ needs.deploy-infrastructure.outputs.subscriber-table }}" \
            --query 'Table.TableStatus' \
            --output text)
          
          echo "üóÉÔ∏è Subscriber table status: ${TABLE_STATUS}"
          
          # Check S3 bucket configuration
          echo "üìã Checking S3 bucket configuration..."
          
          # Check upload bucket
          if aws s3api head-bucket --bucket "${UPLOAD_BUCKET}" 2>/dev/null; then
            echo "‚úÖ Upload bucket accessible: ${UPLOAD_BUCKET}"
            
            # Check bucket encryption
            ENCRYPTION=$(aws s3api get-bucket-encryption \
              --bucket "${UPLOAD_BUCKET}" \
              --query 'ServerSideEncryptionConfiguration.Rules[0].ApplyServerSideEncryptionByDefault.SSEAlgorithm' \
              --output text 2>/dev/null || echo "None")
            echo "üîê Upload bucket encryption: ${ENCRYPTION}"
          else
            echo "‚ùå Upload bucket not accessible: ${UPLOAD_BUCKET}"
          fi
          
          # Performance and scaling checks
          echo "üìã Checking Lambda function configurations..."
          LAMBDA_FUNCTIONS=$(aws lambda list-functions \
            --query "Functions[?starts_with(FunctionName, '${STACK_NAME}')].FunctionName" \
            --output text)
          
          for func in ${LAMBDA_FUNCTIONS}; do
            CONCURRENCY=$(aws lambda get-function-concurrency \
              --function-name "${func}" \
              --query 'ReservedConcurrencyLimit' \
              --output text 2>/dev/null || echo "None")
            echo "‚ö° ${func}: Reserved concurrency = ${CONCURRENCY}"
          done
          
          # Check API Gateway throttling
          echo "üìã Checking API Gateway configuration..."
          API_ID=$(echo "${API_ENDPOINT}" | cut -d'.' -f1 | cut -d'/' -f3)
          
          USAGE_PLANS=$(aws apigateway get-usage-plans \
            --query 'items[].name' \
            --output text 2>/dev/null || echo "None")
          echo "üö¶ API Gateway usage plans: ${USAGE_PLANS}"
          
          # Final deployment summary
          echo ""
          echo "==============================================="
          echo "üéâ DEPLOYMENT SUMMARY"
          echo "==============================================="
          echo "Stack Name:       ${STACK_NAME}"
          echo "Environment:      ${{ needs.validate.outputs.environment }}"
          echo "Region:          ${{ env.AWS_DEFAULT_REGION }}"
          echo "API Endpoint:    ${API_ENDPOINT}"
          echo "Upload Bucket:   ${UPLOAD_BUCKET}"
          echo "Subscriber Table: ${{ needs.deploy-infrastructure.outputs.subscriber-table }}"
          echo "Table Status:    ${TABLE_STATUS}"
          echo "==============================================="
          echo "‚úÖ All post-deployment checks completed!"
          echo "üöÄ Your application is ready for use!"
          echo "==============================================="

  # ==========================================
  # NOTIFICATION
  # ==========================================
  notify:
    name: üì¢ Send Deployment Notification
    runs-on: ubuntu-latest
    needs: [validate, deploy-infrastructure, initialize-database, deploy-frontend, smoke-tests, post-deployment-checks]
    if: always()
    
    steps:
      - name: üì¢ Send deployment notification
        run: |
          set -euo pipefail
          
          STACK_NAME="${{ needs.validate.outputs.stack-name }}"
          ENVIRONMENT="${{ needs.validate.outputs.environment }}"
          API_ENDPOINT="${{ needs.deploy-infrastructure.outputs.api-endpoint || 'N/A' }}"
          
          if [[ "${{ needs.post-deployment-checks.result }}" == "success" ]]; then
            STATUS="üéâ SUCCESS"
            MESSAGE="Deployment completed successfully!"
          else
            STATUS="‚ùå FAILED"
            MESSAGE="Deployment encountered issues. Check logs for details."
          fi
          
          echo "==============================================="
          echo "üì¢ DEPLOYMENT NOTIFICATION"
          echo "==============================================="
          echo "Status:       ${STATUS}"
          echo "Stack:        ${STACK_NAME}"
          echo "Environment:  ${ENVIRONMENT}"
          echo "API Endpoint: ${API_ENDPOINT}"
          echo "Message:      ${MESSAGE}"
          echo "Commit:       ${{ github.sha }}"
          echo "Actor:        ${{ github.actor }}"
          echo "==============================================="
          
          # Here you could add Slack, Teams, or email notifications
          # Example: curl -X POST -H 'Content-type: application/json' \
          #   --data '{"text":"'${MESSAGE}'"}' ${SLACK_WEBHOOK_URL}

# ==========================================
# SECURITY AND PERMISSIONS
# ==========================================
permissions:
  contents: read
  id-token: write  # Required for OIDC