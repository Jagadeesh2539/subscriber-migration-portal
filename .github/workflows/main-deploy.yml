name: Deploy CloudFormation Stack with Ultra-Robust Auto-Management

on:
  push:
    branches: [ main ]
    paths:
      - 'aws/**'
      - '.github/workflows/**'
      - 'backend/**'
      - 'migration-processor/**'
      - 'frontend/**'
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      delete_stack_only:
        description: 'Delete stack only (true/false)'
        required: false
        default: 'false'
      force_recreate:
        description: 'Force recreate stack (true/false)'
        required: false
        default: 'false'
      cleanup_all_resources:
        description: 'Cleanup all orphaned resources (true/false)'
        required: false
        default: 'false'
      skip_validation:
        description: 'Skip template validation (true/false)'
        required: false
        default: 'false'
      s3_prefix:
        description: 'S3 key prefix'
        required: false
        default: 'uploads/'
      s3_suffix:
        description: 'S3 key suffix'
        required: false
        default: '.csv'

env:
  AWS_REGION: us-east-1
  STACK_NAME: subscriber-migration-portal-main
  TEMPLATE_FILE: aws/cloudformation.yaml
  MAX_DEPLOYMENT_ATTEMPTS: 5
  DEPLOYMENT_TIMEOUT: 2400
  RETRY_DELAY: 120

jobs:
  deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Install and configure AWS CLI
      run: |
        set -euo pipefail
        
        # Install AWS CLI v2
        curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
        unzip -q awscliv2.zip
        sudo ./aws/install --update
        
        # Install additional tools
        sudo apt-get update
        sudo apt-get install -y jq mysql-client zip python3 python3-pip
        curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
        sudo apt-get install -y nodejs
        
        # Verify installation
        aws --version
        jq --version
        node --version
        npm --version
        python3 --version
        python3 -m pip --version
        
        # Configure AWS CLI for better performance
        aws configure set max_concurrent_requests 20
        aws configure set max_queue_size 10000
        aws configure set region ${{ env.AWS_REGION }}
        aws configure set output json

    - name: Verify AWS credentials and permissions
      run: |
        set -euo pipefail
        
        echo "üîê Testing AWS credentials..."
        
        # Get caller identity
        CALLER_IDENTITY=$(aws sts get-caller-identity)
        echo "‚úÖ Caller Identity: $CALLER_IDENTITY"
        
        # Test CloudFormation permissions
        echo "üîç Testing CloudFormation permissions..."
        aws cloudformation list-stacks --query 'StackSummaries[0]' --output table || echo "‚ö†Ô∏è  Limited CloudFormation permissions"
        
        # Test S3 permissions
        echo "ü™£ Testing S3 permissions..."
        aws s3 ls || echo "‚ö†Ô∏è  Limited S3 permissions"

    - name: Create global functions file
      run: |
        # Create a global functions file that can be sourced by all steps
        cat > /tmp/stack_functions.sh << 'FUNCTIONS_EOF'
        #!/bin/bash
        
        # Enhanced stack existence check (FIXED: added || false to prevent step termination)
        stack_exists() {
          aws cloudformation describe-stacks --stack-name "$1" --region "$2" &>/dev/null || false
        }
        
        # Wait for Lambda function to be ready for next operation (optimized polling)
        wait_for_lambda_ready() {
          local function_name="$1"
          local operation_type="$2"
          local max_wait_time=300
          local wait_interval=15
          local elapsed_time=0
          
          echo "‚è≥ Waiting for Lambda function '$function_name' to be ready for $operation_type..."
          
          while [[ $elapsed_time -lt $max_wait_time ]]; do
            # Get current function state
            FUNCTION_STATE=$(aws lambda get-function --function-name "$function_name" --query 'Configuration.State' --output text 2>/dev/null || echo "UNKNOWN")
            LAST_UPDATE_STATUS=$(aws lambda get-function --function-name "$function_name" --query 'Configuration.LastUpdateStatus' --output text 2>/dev/null || echo "UNKNOWN")
            
            echo "üîç Function state: $FUNCTION_STATE, Last update status: $LAST_UPDATE_STATUS"
            
            # Check if function is ready
            if [[ "$FUNCTION_STATE" == "Active" && "$LAST_UPDATE_STATUS" == "Successful" ]]; then
              echo "‚úÖ Lambda function '$function_name' is ready for $operation_type"
              return 0
            elif [[ "$LAST_UPDATE_STATUS" == "Failed" ]]; then
              echo "‚ùå Lambda function '$function_name' update failed"
              return 1
            fi
            
            echo "‚è≥ Function not ready yet, waiting ${wait_interval}s..."
            sleep $wait_interval
            elapsed_time=$((elapsed_time + wait_interval))
          done
          
          echo "‚ö†Ô∏è  Timeout waiting for Lambda function '$function_name' to be ready"
          return 1
        }
        
        # Enhanced stack status retrieval
        get_stack_status() {
          if aws cloudformation describe-stacks --stack-name "$1" --region "$2" &>/dev/null; then
            aws cloudformation describe-stacks --stack-name "$1" --region "$2" --query 'Stacks[0].StackStatus' --output text 2>/dev/null || echo "UNKNOWN"
          else
            echo "STACK_NOT_EXISTS"
          fi
        }
        
        # Enhanced S3 bucket deletion function
        delete_s3_bucket_enhanced() {
          local bucket_name="$1"
          local max_retries=3
          local retry=1
          
          # Check if bucket exists
          if ! aws s3api head-bucket --bucket "$bucket_name" 2>/dev/null; then
            echo "‚ÑπÔ∏è  Bucket does not exist: $bucket_name"
            return 0
          fi
          
          echo "üóëÔ∏è  Processing bucket: $bucket_name"
          
          while [[ $retry -le $max_retries ]]; do
            echo "üîÑ Attempt $retry of $max_retries for bucket: $bucket_name"
            
            # Get bucket region
            BUCKET_REGION=$(aws s3api get-bucket-location --bucket "$bucket_name" --query 'LocationConstraint' --output text 2>/dev/null || echo "us-east-1")
            [[ "$BUCKET_REGION" == "None" || "$BUCKET_REGION" == "null" ]] && BUCKET_REGION="us-east-1"
            
            # Check bucket versioning
            VERSIONING=$(aws s3api get-bucket-versioning --bucket "$bucket_name" --region "$BUCKET_REGION" --query 'Status' --output text 2>/dev/null || echo "None")
            
            # Handle versioned buckets
            if [[ "$VERSIONING" == "Enabled" ]]; then
              echo "üì¶ Removing all versions from versioned bucket..."
              
              # Delete all object versions
              aws s3api list-object-versions --bucket "$bucket_name" --region "$BUCKET_REGION" \
                --query 'Versions[].{Key:Key,VersionId:VersionId}' --output text 2>/dev/null | \
              while read -r key version_id; do
                if [[ -n "$key" && -n "$version_id" && "$key" != "None" && "$version_id" != "None" ]]; then
                  aws s3api delete-object --bucket "$bucket_name" --key "$key" --version-id "$version_id" --region "$BUCKET_REGION" 2>/dev/null || true
                fi
              done
              
              # Delete all delete markers
              aws s3api list-object-versions --bucket "$bucket_name" --region "$BUCKET_REGION" \
                --query 'DeleteMarkers[].{Key:Key,VersionId:VersionId}' --output text 2>/dev/null | \
              while read -r key version_id; do
                if [[ -n "$key" && -n "$version_id" && "$key" != "None" && "$version_id" != "None" ]]; then
                  aws s3api delete-object --bucket "$bucket_name" --key "$key" --version-id "$version_id" --region "$BUCKET_REGION" 2>/dev/null || true
                fi
              done
            fi
            
            # Remove all objects
            echo "üßπ Removing all objects..."
            aws s3 rm "s3://$bucket_name" --recursive --region "$BUCKET_REGION" 2>/dev/null || true
            
            # Remove bucket configurations
            aws s3api delete-bucket-policy --bucket "$bucket_name" --region "$BUCKET_REGION" 2>/dev/null || true
            aws s3api put-bucket-notification-configuration --bucket "$bucket_name" --notification-configuration "{}" --region "$BUCKET_REGION" 2>/dev/null || true
            
            # Delete the bucket
            if aws s3api delete-bucket --bucket "$bucket_name" --region "$BUCKET_REGION" 2>/dev/null; then
              echo "‚úÖ Bucket deleted successfully: $bucket_name"
              return 0
            else
              echo "‚ö†Ô∏è  Failed to delete bucket on attempt $retry: $bucket_name"
              retry=$((retry + 1))
              [[ $retry -le $max_retries ]] && sleep 10
            fi
          done
          
          echo "‚ùå Failed to delete bucket after $max_retries attempts: $bucket_name"
          return 1
        }
        
        # Enhanced stack deletion with retry logic
        delete_failed_stack_robust() {
          local stack_name="$1"
          local region="$2"
          local max_retries=3
          local retry=1
          
          echo "üóëÔ∏è  Initiating robust stack deletion: $stack_name"
          
          # First check if stack actually exists
          if ! stack_exists "$stack_name" "$region"; then
            echo "‚ÑπÔ∏è  Stack does not exist: $stack_name"
            return 0
          fi
          
          while [[ $retry -le $max_retries ]]; do
            echo "üîÑ Deletion attempt $retry of $max_retries"
            
            # Get current status
            local current_status=$(get_stack_status "$stack_name" "$region")
            echo "üìä Current status: $current_status"
            
            # Handle different statuses
            case "$current_status" in
              DELETE_COMPLETE|STACK_NOT_EXISTS)
                echo "‚úÖ Stack deletion completed"
                return 0
                ;;
              DELETE_IN_PROGRESS)
                echo "‚è≥ Stack deletion already in progress, waiting..."
                ;;
              *)
                echo "üóëÔ∏è  Initiating stack deletion..."
                aws cloudformation delete-stack --stack-name "$stack_name" --region "$region" 2>/dev/null || true
                ;;
            esac
            
            # Wait for deletion with timeout
            echo "‚è≥ Waiting for stack deletion (timeout: 30 minutes)..."
            if timeout 1800 aws cloudformation wait stack-delete-complete --stack-name "$stack_name" --region "$region" 2>/dev/null; then
              echo "‚úÖ Stack deleted successfully: $stack_name"
              return 0
            else
              echo "‚ö†Ô∏è  Stack deletion timeout or failed on attempt $retry"
              retry=$((retry + 1))
              [[ $retry -le $max_retries ]] && sleep 60
            fi
          done
          
          echo "‚ùå Failed to delete stack after $max_retries attempts: $stack_name"
          return 1
        }
        FUNCTIONS_EOF
        
        # Make the functions file executable
        chmod +x /tmp/stack_functions.sh
        
        echo "‚úÖ Global functions file created"

    - name: Create dynamic parameters file
      run: |
        set -euo pipefail
        
        # Source the functions
        source /tmp/stack_functions.sh
        
        # Generate secure random password if not provided
        if [[ -z "${{ secrets.LEGACY_DB_PASSWORD }}" ]]; then
          DB_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-20)
          echo "‚ö†Ô∏è  Using auto-generated password (consider setting LEGACY_DB_PASSWORD secret)"
        else
          DB_PASSWORD="${{ secrets.LEGACY_DB_PASSWORD }}"
        fi
        
        # Get current timestamp for unique deployments
        CURRENT_TIME=$(date +%Y-%m-%d-%H-%M-%S)
        
        # Create parameters file
        cat > aws/parameters.json << EOF
        [
          {
            "ParameterKey": "Environment",
            "ParameterValue": "prod"
          },
          {
            "ParameterKey": "LegacyDbUsername",
            "ParameterValue": "admin"
          },
          {
            "ParameterKey": "LegacyDbPassword",
            "ParameterValue": "$DB_PASSWORD"
          },
          {
            "ParameterKey": "CurrentTime",
            "ParameterValue": "$CURRENT_TIME"
          },
          {
            "ParameterKey": "LogRetentionDays",
            "ParameterValue": "14"
          }
        ]
        EOF
        
        echo "üìã Parameters file created with timestamp: $CURRENT_TIME"

    - name: Handle workflow inputs and set environment
      run: |
        set -euo pipefail
        
        # Source the functions
        source /tmp/stack_functions.sh
        
        # Handle workflow dispatch inputs
        if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          [[ "${{ github.event.inputs.delete_stack_only }}" == "true" ]] && echo "DELETE_ONLY=true" >> $GITHUB_ENV
          [[ "${{ github.event.inputs.force_recreate }}" == "true" ]] && echo "FORCE_RECREATE=true" >> $GITHUB_ENV  
          [[ "${{ github.event.inputs.cleanup_all_resources }}" == "true" ]] && echo "CLEANUP_ALL=true" >> $GITHUB_ENV
          [[ "${{ github.event.inputs.skip_validation }}" == "true" ]] && echo "SKIP_VALIDATION=true" >> $GITHUB_ENV
        fi
        
        # Set deployment strategy based on trigger
        if [[ "${{ github.event_name }}" == "pull_request" ]]; then
          echo "DEPLOYMENT_MODE=validation" >> $GITHUB_ENV
          echo "üîç PR mode: Will validate template only"
        else
          echo "DEPLOYMENT_MODE=full" >> $GITHUB_ENV
          echo "üöÄ Full deployment mode"
        fi

    - name: Comprehensive orphaned resource cleanup
      if: env.CLEANUP_ALL == 'true'
      run: |
        set -euo pipefail
        
        # Source the functions
        source /tmp/stack_functions.sh
        
        # Get AWS Account ID
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        echo "üè¢ Account ID: $ACCOUNT_ID"
        
        # Define comprehensive resource patterns
        BUCKET_PATTERNS=(
          "sub-mig-logs-$ACCOUNT_ID"
          "sub-mig-web-$ACCOUNT_ID-prod" 
          "sub-mig-web-$ACCOUNT_ID-staging"
          "sub-mig-web-$ACCOUNT_ID-dev"
          "sub-mig-data-$ACCOUNT_ID-prod"
          "sub-mig-data-$ACCOUNT_ID-staging" 
          "sub-mig-data-$ACCOUNT_ID-dev"
        )
        
        # Clean up S3 buckets
        echo "üßπ Starting comprehensive S3 bucket cleanup..."
        CLEANED_BUCKETS=0
        
        for bucket_pattern in "${BUCKET_PATTERNS[@]}"; do
          if delete_s3_bucket_enhanced "$bucket_pattern"; then
            CLEANED_BUCKETS=$((CLEANED_BUCKETS + 1))
          fi
        done
        
        echo "‚úÖ Cleaned up $CLEANED_BUCKETS bucket(s)"
        
        # Cleanup CloudFormation stacks (if cleanup_all_resources is enabled)
        if [[ "${{ env.CLEANUP_ALL }}" == "true" ]]; then
          echo "üóëÔ∏è  Comprehensive stack cleanup requested..."
          
          # Find related stacks
          RELATED_STACKS=$(aws cloudformation list-stacks --query 'StackSummaries[?contains(StackName, `subscriber-migration`) && (StackStatus == `CREATE_FAILED` || StackStatus == `ROLLBACK_COMPLETE` || StackStatus == `UPDATE_ROLLBACK_COMPLETE`)].StackName' --output text 2>/dev/null || echo "")
          
          if [[ -n "$RELATED_STACKS" && "$RELATED_STACKS" != "None" ]]; then
            echo "üóëÔ∏è  Found related failed stacks: $RELATED_STACKS"
            for stack in $RELATED_STACKS; do
              echo "üóëÔ∏è  Deleting failed stack: $stack"
              delete_failed_stack_robust "$stack" "${{ env.AWS_REGION }}" || true
            done
          else
            echo "‚ÑπÔ∏è  No failed stacks found to clean up"
          fi
        fi

    - name: Safe stack status analysis and cleanup  
      run: |
        set -euo pipefail
        
        # Source the functions
        source /tmp/stack_functions.sh
        
        # Main stack analysis and cleanup logic
        STACK_NAME="${{ env.STACK_NAME }}"
        AWS_REGION="${{ env.AWS_REGION }}"
        
        echo "üîç Performing safe stack status analysis..."
        
        # Safe stack existence check
        if stack_exists "$STACK_NAME" "$AWS_REGION"; then
          CURRENT_STATUS=$(get_stack_status "$STACK_NAME" "$AWS_REGION")
          
          echo "üìä Stack exists:"
          echo "   Name: $STACK_NAME"
          echo "   Status: $CURRENT_STATUS"
          
          # Analyze stack condition
          case "$CURRENT_STATUS" in
            *_FAILED|*_ROLLBACK_COMPLETE)
              echo "üö® Stack is in failed state: $CURRENT_STATUS"
              
              # Show failure reason
              echo "üîç Analyzing failure reason..."
              aws cloudformation describe-stack-events --stack-name "$STACK_NAME" --region "$AWS_REGION" \
                --query 'StackEvents[?ResourceStatus == `CREATE_FAILED` || ResourceStatus == `UPDATE_FAILED`] | [0:5].[Timestamp,LogicalResourceId,ResourceStatusReason]' \
                --output table 2>/dev/null || echo "Could not retrieve failure details"
              
              echo "üßπ Attempting to clean up failed stack..."
              if delete_failed_stack_robust "$STACK_NAME" "$AWS_REGION"; then
                echo "STACK_CLEANED=true" >> $GITHUB_ENV
                echo "STACK_EXISTS=false" >> $GITHUB_ENV
              else
                echo "‚ö†Ô∏è  Failed to clean up stack, but continuing..."
                echo "STACK_CLEANUP_FAILED=true" >> $GITHUB_ENV
                echo "STACK_EXISTS=true" >> $GITHUB_ENV
              fi
              ;;
            *_IN_PROGRESS)
              echo "üîÑ Stack operation in progress: $CURRENT_STATUS"
              echo "‚è≥ Will wait for current operation to complete..."
              echo "STACK_EXISTS=true" >> $GITHUB_ENV
              echo "STACK_IN_PROGRESS=true" >> $GITHUB_ENV
              ;;
            *_COMPLETE)
              echo "‚úÖ Stack is healthy: $CURRENT_STATUS"
              echo "STACK_EXISTS=true" >> $GITHUB_ENV
              ;;
            *)
              echo "‚ùì Unknown stack status: $CURRENT_STATUS"
              echo "STACK_EXISTS=true" >> $GITHUB_ENV
              ;;
          esac
        else
          echo "üìù Stack does not exist: $STACK_NAME"
          echo "‚ú® This is perfect for a clean deployment!"
          echo "STACK_EXISTS=false" >> $GITHUB_ENV
        fi

    - name: Handle special workflow modes
      run: |
        set -euo pipefail
        
        # Source the functions
        source /tmp/stack_functions.sh
        
        # Delete only mode
        if [[ "${{ env.DELETE_ONLY }}" == "true" ]]; then
          echo "üóëÔ∏è  Delete-only mode activated"
          
          if [[ "${{ env.STACK_EXISTS }}" == "true" ]]; then
            echo "üóëÔ∏è  Deleting stack: ${{ env.STACK_NAME }}"
            if delete_failed_stack_robust "${{ env.STACK_NAME }}" "${{ env.AWS_REGION }}"; then
              echo "‚úÖ Stack deleted successfully"
            else
              echo "‚ùå Failed to delete stack"
              exit 1
            fi
          else
            echo "‚ÑπÔ∏è  Stack does not exist, nothing to delete"
          fi
          
          echo "üèÅ Delete-only operation completed"
          exit 0
        fi
        
        # Force recreate mode
        if [[ "${{ env.FORCE_RECREATE }}" == "true" && "${{ env.DEPLOYMENT_MODE }}" == "full" ]]; then
          echo "üîÑ Force recreate mode activated"
          
          if [[ "${{ env.STACK_EXISTS }}" == "true" ]]; then
            echo "üóëÔ∏è  Deleting existing stack for recreation..."
            if delete_failed_stack_robust "${{ env.STACK_NAME }}" "${{ env.AWS_REGION }}"; then
              echo "‚úÖ Existing stack deleted, proceeding with creation"
              echo "STACK_EXISTS=false" >> $GITHUB_ENV
            else
              echo "‚ùå Failed to delete existing stack"
              exit 1
            fi
          else
            echo "üìù Stack doesn't exist, proceeding with creation"
          fi
        fi

    - name: Comprehensive template validation
      if: env.DEPLOYMENT_MODE == 'full' && env.SKIP_VALIDATION != 'true'
      run: |
        echo "üîç Performing comprehensive template validation..."
        
        # Basic template validation
        echo "üìã Basic CloudFormation template validation..."
        if ! aws cloudformation validate-template --template-body "file://${{ env.TEMPLATE_FILE }}" --region ${{ env.AWS_REGION }}; then
          echo "‚ùå Template validation failed"
          exit 1
        fi
        
        # Advanced template analysis
        echo "üî¨ Advanced template analysis..."
        
        # Check for circular dependencies
        echo "üîÑ Checking for circular dependencies..."
        if grep -q "DependsOn" "${{ env.TEMPLATE_FILE }}"; then
          echo "‚ö†Ô∏è  Template contains DependsOn references - review for circular dependencies"
        fi
        
        # Check resource limits
        RESOURCE_COUNT=$(grep -c "Type: AWS::" "${{ env.TEMPLATE_FILE }}" || echo "0")
        echo "üìä Template contains $RESOURCE_COUNT resources"
        
        # Validate parameter file
        if [[ -f "aws/parameters.json" ]]; then
          echo "üìã Validating parameters file..."
          if ! jq empty aws/parameters.json 2>/dev/null; then
            echo "‚ùå Invalid JSON in parameters file"
            exit 1
          fi
        fi
        
        echo "‚úÖ Template validation completed successfully"

    - name: Execute ultra-robust CloudFormation deployment
      if: env.DEPLOYMENT_MODE == 'full'
      run: |
        set -euo pipefail
        
        # Source the functions
        source /tmp/stack_functions.sh
        
        STACK_NAME="${{ env.STACK_NAME }}"
        AWS_REGION="${{ env.AWS_REGION }}"
        TEMPLATE_FILE="${{ env.TEMPLATE_FILE }}"
        PARAMETERS_FILE="aws/parameters.json"
        MAX_ATTEMPTS="${{ env.MAX_DEPLOYMENT_ATTEMPTS }}"
        TIMEOUT="${{ env.DEPLOYMENT_TIMEOUT }}"
        RETRY_DELAY="${{ env.RETRY_DELAY }}"
        
        # Determine operation type
        if [[ "${{ env.STACK_EXISTS }}" == "true" && "${{ env.FORCE_RECREATE }}" != "true" ]]; then
          OPERATION="update-stack"
          echo "üîÑ Will update existing stack..."
        else
          OPERATION="create-stack"
          echo "üÜï Will create new stack..."
        fi
        
        echo "üöÄ Starting ultra-robust CloudFormation deployment..."
        echo "   Stack: $STACK_NAME"
        echo "   Region: $AWS_REGION"
        echo "   Operation: $OPERATION"
        echo "   Max attempts: $MAX_ATTEMPTS"
        
        ATTEMPT=1
        DEPLOYMENT_SUCCESS=false
        
        while [[ $ATTEMPT -le $MAX_ATTEMPTS ]]; do
          echo ""
          echo "üöÄ === DEPLOYMENT ATTEMPT $ATTEMPT OF $MAX_ATTEMPTS ==="
          
          # Build deployment command
          CMD="aws cloudformation $OPERATION"
          CMD="$CMD --stack-name $STACK_NAME"
          CMD="$CMD --template-body file://$TEMPLATE_FILE"
          CMD="$CMD --capabilities CAPABILITY_NAMED_IAM CAPABILITY_IAM"
          CMD="$CMD --region $AWS_REGION"
          
          # Add parameters if file exists
          if [[ -f "$PARAMETERS_FILE" ]]; then
            CMD="$CMD --parameters file://$PARAMETERS_FILE"
          fi
          
          # Add tags
          CMD="$CMD --tags Key=Project,Value=SubscriberMigration Key=Environment,Value=Production Key=DeployedBy,Value=GitHub-Actions Key=DeploymentAttempt,Value=$ATTEMPT"
          
          echo "üéØ Executing: $CMD"
          
          # Execute deployment command
          if eval "$CMD" 2>&1 | tee "deployment-attempt-$ATTEMPT.log"; then
            echo "‚úÖ Deployment command initiated successfully"
            
            # Monitor deployment
            echo "‚è≥ Monitoring deployment progress..."
            
            # Wait for completion
            if [[ "$OPERATION" == "create-stack" ]]; then
              if timeout $TIMEOUT aws cloudformation wait stack-create-complete --stack-name "$STACK_NAME" --region "$AWS_REGION" 2>/dev/null; then
                echo "üéâ Stack creation completed successfully!"
                DEPLOYMENT_SUCCESS=true
                break
              fi
            else
              if timeout $TIMEOUT aws cloudformation wait stack-update-complete --stack-name "$STACK_NAME" --region "$AWS_REGION" 2>/dev/null; then
                echo "üéâ Stack update completed successfully!"
                DEPLOYMENT_SUCCESS=true
                break
              fi
            fi
            
            # Check final status if wait failed
            FINAL_STATUS=$(get_stack_status "$STACK_NAME" "$AWS_REGION")
            echo "üìä Final status: $FINAL_STATUS"
            
            if [[ "$FINAL_STATUS" == *"_COMPLETE" ]]; then
              DEPLOYMENT_SUCCESS=true
              break
            fi
          else
            echo "‚ùå Deployment command failed on attempt $ATTEMPT"
          fi
          
          # Prepare for retry if not at max attempts
          if [[ $ATTEMPT -lt $MAX_ATTEMPTS ]]; then
            echo "üîÑ Preparing for retry..."
            
            # Clean up for retry
            delete_failed_stack_robust "$STACK_NAME" "$AWS_REGION" || true
            
            # Safe cleanup on retry (avoid deleting prod buckets!)
            if [[ "${{ env.CLEANUP_ALL }}" == "true" ]]; then
              echo "üßπ Destructive cleanup enabled for retry"
              ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
              delete_s3_bucket_enhanced "sub-mig-logs-$ACCOUNT_ID" || true
              delete_s3_bucket_enhanced "sub-mig-web-$ACCOUNT_ID-prod" || true
              delete_s3_bucket_enhanced "sub-mig-data-$ACCOUNT_ID-prod" || true
            else
              echo "‚ÑπÔ∏è Skipping destructive cleanup on retry (CLEANUP_ALL!=true)"
            fi
            
            # Always use create-stack for retries
            OPERATION="create-stack"
            
            echo "‚è∏Ô∏è  Waiting ${RETRY_DELAY}s before retry..."
            sleep $RETRY_DELAY
          fi
          
          ATTEMPT=$((ATTEMPT + 1))
        done
        
        # Final result
        if [[ "$DEPLOYMENT_SUCCESS" == "true" ]]; then
          echo "DEPLOYMENT_SUCCESS=true" >> $GITHUB_ENV
        else
          echo "DEPLOYMENT_SUCCESS=false" >> $GITHUB_ENV
          echo "üí• All deployment attempts failed"
          exit 1
        fi

    - name: Cache stack outputs for efficiency
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        
        echo "üìã Caching stack outputs to avoid repeated API calls..."
        
        # Single API call to get all outputs and save to file (using dynamic stack name)
        aws cloudformation describe-stacks --stack-name "${{ env.STACK_NAME }}" \
          --query 'Stacks[0].Outputs' --output json > /tmp/stack-outputs.json
        
        # Debug: Show all available stack outputs
        echo "üîç Available stack outputs:"
        cat /tmp/stack-outputs.json | jq -r '.[] | "\(.OutputKey): \(.OutputValue)"'
        
        # Parse outputs once and set environment variables for all subsequent steps
        SUBSCRIBER_TABLE=$(jq -r '.[] | select(.OutputKey=="SubscriberTableName") | .OutputValue' /tmp/stack-outputs.json)
        AUDIT_TABLE=$(jq -r '.[] | select(.OutputKey=="AuditLogTableName") | .OutputValue' /tmp/stack-outputs.json)
        JOBS_TABLE=$(jq -r '.[] | select(.OutputKey=="MigrationJobsTableName") | .OutputValue' /tmp/stack-outputs.json)
        UPLOAD_BUCKET=$(jq -r '.[] | select(.OutputKey=="MigrationUploadBucketName") | .OutputValue' /tmp/stack-outputs.json)
        FRONTEND_BUCKET=$(jq -r '.[] | select(.OutputKey=="FrontendBucketName") | .OutputValue' /tmp/stack-outputs.json)
        LEGACY_DB_ENDPOINT=$(jq -r '.[] | select(.OutputKey=="LegacyDBEndpoint") | .OutputValue' /tmp/stack-outputs.json)
        LEGACY_DB_SECRET=$(jq -r '.[] | select(.OutputKey=="LegacyDBSecretArn") | .OutputValue' /tmp/stack-outputs.json)
        MIGRATION_ARN=$(jq -r '.[] | select(.OutputKey=="MigrationProcessorArn") | .OutputValue' /tmp/stack-outputs.json)
        BACKEND_API_URL=$(jq -r '.[] | select(.OutputKey=="BackendApiUrl") | .OutputValue' /tmp/stack-outputs.json)
        FRONTEND_URL=$(jq -r '.[] | select(.OutputKey=="FrontendURL") | .OutputValue' /tmp/stack-outputs.json)
        BACKEND_LAMBDA_NAME=$(jq -r '.[] | select(.OutputKey=="BackendLambdaName") | .OutputValue' /tmp/stack-outputs.json)
        MIGRATION_LAMBDA_NAME=$(jq -r '.[] | select(.OutputKey=="MigrationProcessorFunctionName") | .OutputValue' /tmp/stack-outputs.json)
        
        # Optional: Export additional handy outputs for future steps
        BACKEND_API_ID=$(jq -r '.[] | select(.OutputKey=="BackendApiId") | .OutputValue' /tmp/stack-outputs.json)
        BACKEND_LAMBDA_ARN=$(jq -r '.[] | select(.OutputKey=="BackendLambdaArn") | .OutputValue' /tmp/stack-outputs.json)
        
        # Validate critical variables and provide better error messaging
        if [[ -z "$UPLOAD_BUCKET" || "$UPLOAD_BUCKET" == "null" ]]; then
          echo "‚ùå Critical error: Upload bucket not found in stack outputs"
          echo "Available outputs:"
          cat /tmp/stack-outputs.json | jq -r '.[] | "\(.OutputKey): \(.OutputValue)"'
          exit 1
        fi
        
        # Enhanced bucket verification with better error handling
        echo "üîç Verifying upload bucket exists: $UPLOAD_BUCKET"
        if aws s3api head-bucket --bucket "$UPLOAD_BUCKET" 2>/dev/null; then
          echo "‚úÖ Upload bucket verified: $UPLOAD_BUCKET"
        else
          echo "‚ö†Ô∏è  Upload bucket does not exist: $UPLOAD_BUCKET"
          echo "üîß This might be due to a CloudFormation stack inconsistency."
          echo "üîç Listing actual S3 buckets to debug:"
          aws s3 ls | grep -i sub-mig || echo "No matching buckets found"
          
          # Try to determine the correct bucket name
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          POSSIBLE_BUCKETS=(
            "sub-mig-data-$ACCOUNT_ID-prod"
            "sub-mig-uploads-$ACCOUNT_ID-prod"
            "subscriber-migration-data-$ACCOUNT_ID-prod"
            "subscriber-migration-uploads-$ACCOUNT_ID-prod"
          )
          
          echo "üîç Checking for possible bucket names:"
          FOUND_BUCKET=""
          for bucket in "${POSSIBLE_BUCKETS[@]}"; do
            echo "  Checking: $bucket"
            if aws s3api head-bucket --bucket "$bucket" 2>/dev/null; then
              echo "  ‚úÖ Found: $bucket"
              FOUND_BUCKET="$bucket"
              break
            else
              echo "  ‚ùå Not found: $bucket"
            fi
          done
          
          if [[ -n "$FOUND_BUCKET" ]]; then
            echo "üîß Using found bucket: $FOUND_BUCKET"
            UPLOAD_BUCKET="$FOUND_BUCKET"
          else
            echo "‚ùå No valid upload bucket found. Check your CloudFormation template."
            exit 1
          fi
        fi
        
        # Additional validations for all critical outputs
        for VAR in FRONTEND_BUCKET MIGRATION_ARN BACKEND_API_URL FRONTEND_URL BACKEND_LAMBDA_NAME MIGRATION_LAMBDA_NAME; do
          if [[ -z "${!VAR:-}" || "${!VAR}" == "null" ]]; then
            echo "‚ùå Critical output missing: $VAR"
            echo "Available outputs:"
            cat /tmp/stack-outputs.json | jq -r '.[] | "\(.OutputKey): \(.OutputValue)"'
            exit 1
          fi
        done
        
        # Security: Mask sensitive values in GitHub Actions logs
        echo "::add-mask::$SUBSCRIBER_TABLE"
        echo "::add-mask::$AUDIT_TABLE" 
        echo "::add-mask::$JOBS_TABLE"
        echo "::add-mask::$UPLOAD_BUCKET"
        echo "::add-mask::$FRONTEND_BUCKET"
        echo "::add-mask::$LEGACY_DB_ENDPOINT"
        echo "::add-mask::$LEGACY_DB_SECRET"
        echo "::add-mask::$MIGRATION_ARN"
        echo "::add-mask::$BACKEND_API_URL"
        echo "::add-mask::$FRONTEND_URL"
        echo "::add-mask::$BACKEND_LAMBDA_NAME"
        echo "::add-mask::$MIGRATION_LAMBDA_NAME"
        echo "::add-mask::$BACKEND_API_ID"
        echo "::add-mask::$BACKEND_LAMBDA_ARN"
        
        # Export all to environment for subsequent steps
        echo "SUBSCRIBER_TABLE=$SUBSCRIBER_TABLE" >> $GITHUB_ENV
        echo "AUDIT_TABLE=$AUDIT_TABLE" >> $GITHUB_ENV
        echo "JOBS_TABLE=$JOBS_TABLE" >> $GITHUB_ENV
        echo "UPLOAD_BUCKET=$UPLOAD_BUCKET" >> $GITHUB_ENV
        echo "FRONTEND_BUCKET=$FRONTEND_BUCKET" >> $GITHUB_ENV
        echo "LEGACY_DB_ENDPOINT=$LEGACY_DB_ENDPOINT" >> $GITHUB_ENV
        echo "LEGACY_DB_SECRET=$LEGACY_DB_SECRET" >> $GITHUB_ENV
        echo "MIGRATION_ARN=$MIGRATION_ARN" >> $GITHUB_ENV
        echo "BACKEND_API_URL=$BACKEND_API_URL" >> $GITHUB_ENV
        echo "FRONTEND_URL=$FRONTEND_URL" >> $GITHUB_ENV
        echo "BACKEND_LAMBDA_NAME=$BACKEND_LAMBDA_NAME" >> $GITHUB_ENV
        echo "MIGRATION_LAMBDA_NAME=$MIGRATION_LAMBDA_NAME" >> $GITHUB_ENV
        echo "BACKEND_API_ID=$BACKEND_API_ID" >> $GITHUB_ENV
        echo "BACKEND_LAMBDA_ARN=$BACKEND_LAMBDA_ARN" >> $GITHUB_ENV
        
        echo "‚úÖ Stack outputs cached and environment variables set"

    - name: Deploy Lambda code automatically
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        
        # Source the functions
        source /tmp/stack_functions.sh
        
        echo "üöÄ Deploying application code to Lambda functions..."
        
        # Backend Lambda - check multiple possible directory structures
        BACKEND_DIRS=("backend" "src" "lambda" "api" "backend/api")
        BACKEND_DIR=""
        for dir in "${BACKEND_DIRS[@]}"; do
          if [[ -d "$dir" ]]; then
            BACKEND_DIR="$dir"
            break
          fi
        done
        
        if [[ -n "$BACKEND_DIR" ]]; then
          echo "üì¶ Packaging backend Lambda from: $BACKEND_DIR"
          cd "$BACKEND_DIR"
          
          # Install production dependencies if package.json exists
          if [[ -f "package.json" ]]; then
            npm ci --omit=dev
            zip -r ../backend.zip . -x "*.git*" "__tests__/*"
          elif [[ -f "requirements.txt" ]]; then
            python3 -m pip install -r requirements.txt -t .
            zip -r ../backend.zip . -x "*.git*" "__pycache__/*" "*.pyc" "venv/*"
          else
            zip -r ../backend.zip . -x "*.git*" "node_modules/*" "__pycache__/*" "*.pyc" "venv/*"
          fi
          
          cd ..
          
          aws lambda update-function-code \
            --function-name "$BACKEND_LAMBDA_NAME" \
            --zip-file fileb://backend.zip
          
          # Wait for deployment to complete
          wait_for_lambda_ready "$BACKEND_LAMBDA_NAME" "deployment"
          
          echo "‚úÖ Backend Lambda code deployed from: $BACKEND_DIR"
        else
          echo "‚ö†Ô∏è  Backend directory not found (tried: ${BACKEND_DIRS[*]}), skipping"
        fi
        
        # Migration Processor - check multiple possible directory structures (including nested)
        MIGRATION_DIRS=(
          "migration-processor" 
          "migration" 
          "processor" 
          "lambda-processor" 
          "functions"
          "backend/migration-processor"
          "backend/migration_processor" 
          "backend/migration"
          "backend/processor"
          "src/migration-processor"
          "src/migration_processor"
          "src/migration"
        )
        MIGRATION_DIR=""
        for dir in "${MIGRATION_DIRS[@]}"; do
          if [[ -d "$dir" ]]; then
            MIGRATION_DIR="$dir"
            break
          fi
        done
        
        if [[ -n "$MIGRATION_DIR" ]]; then
          echo "üì¶ Packaging migration processor Lambda from: $MIGRATION_DIR"
          cd "$MIGRATION_DIR"
          
          # Install production dependencies if requirements.txt exists
          if [[ -f "requirements.txt" ]]; then
            python3 -m pip install -r requirements.txt -t .
            zip -r ../migration.zip . -x "*.git*" "__pycache__/*" "*.pyc" "venv/*"
          elif [[ -f "package.json" ]]; then
            npm ci --omit=dev
            zip -r ../migration.zip . -x "*.git*" "__tests__/*"
          else
            zip -r ../migration.zip . -x "*.git*" "node_modules/*" "__pycache__/*" "*.pyc" "venv/*"
          fi
          
          cd ..
          
          # Handle nested directory zipping correctly
          if [[ "$MIGRATION_DIR" == */* ]]; then
            # For nested dirs like "backend/migration-processor", move zip to root
            if [[ -f "${MIGRATION_DIR%/*}/migration.zip" ]]; then
              mv "${MIGRATION_DIR%/*}/migration.zip" ./migration.zip
            fi
          fi
          
          aws lambda update-function-code \
            --function-name "$MIGRATION_LAMBDA_NAME" \
            --zip-file fileb://migration.zip
          
          # Wait for deployment to complete
          wait_for_lambda_ready "$MIGRATION_LAMBDA_NAME" "deployment"
          
          echo "‚úÖ Migration processor code deployed from: $MIGRATION_DIR"
        else
          echo "‚ö†Ô∏è  Migration processor directory not found (tried: ${MIGRATION_DIRS[*]}), skipping"
          echo "üîç Available directories in project root:"
          find . -maxdepth 2 -type d -name "*migration*" -o -name "*processor*" | head -10
          echo "üîç Available directories in backend/:"
          if [[ -d "backend" ]]; then
            find backend/ -maxdepth 2 -type d 2>/dev/null | head -10
          fi
        fi

    - name: Debug and fix Lambda environment variables
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        
        # Source the functions
        source /tmp/stack_functions.sh
        
        echo "üîç Debugging and fixing Lambda configuration..."
        
        # Show current Lambda environment variables
        echo "üìã Current Backend Lambda environment:"
        aws lambda get-function-configuration --function-name "$BACKEND_LAMBDA_NAME" \
          --query 'Environment.Variables' --output json | jq '.' || echo "No environment variables set"
        
        echo "üìã Current Migration Lambda environment:"
        aws lambda get-function-configuration --function-name "$MIGRATION_LAMBDA_NAME" \
          --query 'Environment.Variables' --output json | jq '.' || echo "No environment variables set"
        
        # Wait for both Lambdas to be ready before configuration
        wait_for_lambda_ready "$BACKEND_LAMBDA_NAME" "configuration"
        wait_for_lambda_ready "$MIGRATION_LAMBDA_NAME" "configuration"
        
        # Update Backend Lambda with ALL required environment variables
        echo "‚öôÔ∏è  Updating Backend Lambda environment variables..."
        aws lambda update-function-configuration \
          --function-name "$BACKEND_LAMBDA_NAME" \
          --environment "Variables={
            ENVIRONMENT=prod,
            SUBSCRIBER_TABLE_NAME=$SUBSCRIBER_TABLE,
            AUDIT_LOG_TABLE_NAME=$AUDIT_TABLE,
            MIGRATION_JOBS_TABLE_NAME=$JOBS_TABLE,
            MIGRATION_UPLOAD_BUCKET_NAME=$UPLOAD_BUCKET,
            LEGACY_DB_SECRET_ARN=$LEGACY_DB_SECRET,
            LEGACY_DB_HOST=$LEGACY_DB_ENDPOINT,
            LEGACY_DB_PORT=3306,
            LEGACY_DB_NAME=legacydb,
            JWT_SECRET=subscriber-portal-jwt-secret-2025-production,
            FLASK_ENV=production,
            PROV_MODE=dual_prov,
            VERSION=2.0.0-production
          }"
        
        # Wait for backend configuration to complete
        echo "‚è≥ Waiting for Backend Lambda configuration to complete..."
        wait_for_lambda_ready "$BACKEND_LAMBDA_NAME" "post-configuration"
        
        # Update Migration Lambda with ALL required environment variables
        echo "‚öôÔ∏è  Updating Migration Lambda environment variables..."
        aws lambda update-function-configuration \
          --function-name "$MIGRATION_LAMBDA_NAME" \
          --environment "Variables={
            ENVIRONMENT=prod,
            UPLOAD_BUCKET=$UPLOAD_BUCKET,
            SUBSCRIBER_TABLE_NAME=$SUBSCRIBER_TABLE,
            JOBS_TABLE_NAME=$JOBS_TABLE,
            LEGACY_DB_ENDPOINT=$LEGACY_DB_ENDPOINT,
            LEGACY_DB_SECRET_ARN=$LEGACY_DB_SECRET,
            LEGACY_DB_HOST=$LEGACY_DB_ENDPOINT,
            LEGACY_DB_PORT=3306,
            LEGACY_DB_NAME=legacydb,
            PROV_MODE=dual_prov
          }"
        
        # Wait for migration configuration to complete  
        echo "‚è≥ Waiting for Migration Lambda configuration to complete..."
        wait_for_lambda_ready "$MIGRATION_LAMBDA_NAME" "post-configuration"
        
        echo "‚úÖ All Lambda environment variables configured and ready"
        
        # Show updated environment variables for verification
        echo "üìã Updated Backend Lambda environment:"
        aws lambda get-function-configuration --function-name "$BACKEND_LAMBDA_NAME" \
          --query 'Environment.Variables' --output json | jq '.'

    - name: Configure API Gateway CORS and S3 website settings
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        
        echo "üåê Configuring CORS and S3 website settings..."
        
        # Configure S3 website error document for React Router
        echo "üîß Setting S3 error document for React Router support..."
        aws s3 website "s3://$FRONTEND_BUCKET" \
          --index-document index.html \
          --error-document index.html
        
        echo "‚úÖ S3 website configuration updated"
        
        # Configure API Gateway CORS via AWS CLI
        echo "üîß Configuring API Gateway CORS..."
        
        # Add CORS to Gateway Responses for error handling
        echo "üì° Adding CORS headers to Gateway Responses..."
        
        # Update DEFAULT_4XX response
        aws apigateway put-gateway-response \
          --rest-api-id "$BACKEND_API_ID" \
          --response-type DEFAULT_4XX \
          --response-parameters "gatewayresponse.header.Access-Control-Allow-Origin='http://$FRONTEND_BUCKET.s3-website-us-east-1.amazonaws.com',gatewayresponse.header.Access-Control-Allow-Headers='Content-Type,Authorization,X-Requested-With,Accept,Origin',gatewayresponse.header.Access-Control-Allow-Methods='GET,POST,PUT,DELETE,OPTIONS'" \
          2>/dev/null || echo "‚ö†Ô∏è  Failed to update DEFAULT_4XX response (may not exist)"
        
        # Update DEFAULT_5XX response  
        aws apigateway put-gateway-response \
          --rest-api-id "$BACKEND_API_ID" \
          --response-type DEFAULT_5XX \
          --response-parameters "gatewayresponse.header.Access-Control-Allow-Origin='http://$FRONTEND_BUCKET.s3-website-us-east-1.amazonaws.com',gatewayresponse.header.Access-Control-Allow-Headers='Content-Type,Authorization,X-Requested-With,Accept,Origin',gatewayresponse.header.Access-Control-Allow-Methods='GET,POST,PUT,DELETE,OPTIONS'" \
          2>/dev/null || echo "‚ö†Ô∏è  Failed to update DEFAULT_5XX response (may not exist)"
        
        # Deploy API changes
        echo "üöÄ Deploying API Gateway changes..."
        aws apigateway create-deployment \
          --rest-api-id "$BACKEND_API_ID" \
          --stage-name prod \
          --description "Auto-configure CORS and deploy updated Lambda code"
        
        echo "‚úÖ API Gateway CORS configured and deployed"

    - name: Setup S3 notifications automatically
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail

        echo "üì° Setting up S3 ‚Üí Lambda notifications..."
        ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"

        # Get parameterized S3 filters and normalize them
        PREFIX="${{ github.event.inputs.s3_prefix || 'uploads/' }}"
        SUFFIX="${{ github.event.inputs.s3_suffix || '.csv' }}"

        # Normalize: ensure trailing slash on non-empty prefix
        if [[ -n "$PREFIX" && "${PREFIX: -1}" != "/" ]]; then PREFIX="${PREFIX}/"; fi

        # Normalize suffix: if bare word (no dot), add dot; otherwise keep as-is
        if [[ -n "$SUFFIX" && "$SUFFIX" != .* ]]; then SUFFIX=".$SUFFIX"; fi

        echo "üîç Using normalized filters: PREFIX='$PREFIX' SUFFIX='$SUFFIX'"

        # Ensure bucket & Lambda are in same region
        BUCKET_REGION=$(aws s3api get-bucket-location --bucket "$UPLOAD_BUCKET" --query 'LocationConstraint' --output text)
        [[ "$BUCKET_REGION" == "None" || "$BUCKET_REGION" == "null" ]] && BUCKET_REGION="us-east-1"
        if [[ "$BUCKET_REGION" != "${{ env.AWS_REGION }}" ]]; then
          echo "‚ùå Bucket region ($BUCKET_REGION) != Lambda region (${{ env.AWS_REGION }})"
          exit 1
        fi

        # Make permission id unique per bucket to avoid ResourceConflictException on reruns
        SID="s3invoke-from-${UPLOAD_BUCKET}"

        # Remove old permission silently (ok if not present)
        aws lambda remove-permission \
          --function-name "$MIGRATION_LAMBDA_NAME" \
          --statement-id "$SID" \
          2>/dev/null || true

        # Add permission (with source-account)
        aws lambda add-permission \
          --function-name "$MIGRATION_LAMBDA_NAME" \
          --statement-id "$SID" \
          --action lambda:InvokeFunction \
          --principal s3.amazonaws.com \
          --source-arn "arn:aws:s3:::$UPLOAD_BUCKET" \
          --source-account "$ACCOUNT_ID"

        # Build FilterRules array conditionally
        FILTER_RULES=()

        if [[ -n "$PREFIX" ]]; then
          FILTER_RULES+=("{\"Name\":\"prefix\",\"Value\":\"$PREFIX\"}")
        fi

        # Omit suffix rule entirely if empty
        if [[ -n "$SUFFIX" ]]; then
          FILTER_RULES+=("{\"Name\":\"suffix\",\"Value\":\"$SUFFIX\"}")
        fi

        # Join rules into JSON (either 1 or 2 entries, or empty)
        if [[ ${#FILTER_RULES[@]} -gt 0 ]]; then
          FILTER_JSON=$(printf ",\n                    %s" "${FILTER_RULES[@]}")
          FILTER_JSON=${FILTER_JSON:2} # strip leading comma+newline
          FILTER_BLOCK=",
              \"Filter\": {
                \"Key\": {
                  \"FilterRules\": [
                    $FILTER_JSON
                  ]
                }
              }"
        else
          FILTER_BLOCK=""
        fi

        # Fetch existing config (may be {})
        aws s3api get-bucket-notification-configuration --bucket "$UPLOAD_BUCKET" > current_notif.json 2>/dev/null || echo '{}' > current_notif.json

        # Write new lambda config
        cat > new_lambda.json <<EOF
        {
          "LambdaFunctionConfigurations": [
            {
              "Id": "MigrationProcessorTrigger",
              "LambdaFunctionArn": "$MIGRATION_ARN",
              "Events": ["s3:ObjectCreated:*"]$FILTER_BLOCK
            }
          ]
        }
        EOF

        # Merge: drop any existing with the same Id, then append ours
        python3 - <<'PY'
        import json
        from pathlib import Path

        cur = json.loads(Path("current_notif.json").read_text() or "{}")
        new = json.loads(Path("new_lambda.json").read_text())

        cur.setdefault("LambdaFunctionConfigurations", [])
        # Remove existing with same Id
        cur["LambdaFunctionConfigurations"] = [
            c for c in cur["LambdaFunctionConfigurations"]
            if c.get("Id") != "MigrationProcessorTrigger"
        ]
        # Append ours
        cur["LambdaFunctionConfigurations"].extend(new.get("LambdaFunctionConfigurations", []))

        # Ensure empty arrays for other sections if missing
        for k in ["TopicConfigurations","QueueConfigurations"]:
            cur.setdefault(k, [])

        Path("merged_notif.json").write_text(json.dumps(cur))
        PY

        # Apply merged notification config
        aws s3api put-bucket-notification-configuration \
          --bucket "$UPLOAD_BUCKET" \
          --notification-configuration file://merged_notif.json

        # Show final config (useful for debugging)
        aws s3api get-bucket-notification-configuration --bucket "$UPLOAD_BUCKET"
        
        echo "‚úÖ S3 notifications configured with PREFIX='$PREFIX' and SUFFIX='$SUFFIX'"

    - name: Deploy frontend automatically
      if: env.DEPLOYMENT_SUCCESS == 'true'  
      run: |
        set -euo pipefail
        
        echo "üåê Deploying React frontend..."
        
        # Check multiple possible frontend directory names
        FRONTEND_DIRS=("frontend" "web" "client" "ui" "app")
        FRONTEND_DIR=""
        for dir in "${FRONTEND_DIRS[@]}"; do
          if [[ -d "$dir" ]]; then
            FRONTEND_DIR="$dir"
            break
          fi
        done
        
        if [[ -n "$FRONTEND_DIR" ]]; then
          echo "üì¶ Building frontend from: $FRONTEND_DIR"
          cd "$FRONTEND_DIR"
          
          # Install dependencies and build
          if [[ -f "package.json" ]]; then
            echo "üì¶ Installing frontend dependencies with cache management..."
            
            # Clear npm cache to prevent corruption issues (DEFENSIVE FIX)
            echo "üßπ Clearing npm cache to prevent EINTEGRITY errors..."
            npm cache clean --force
            
            # Set npm to use a fresh cache directory to avoid runner corruption
            export npm_config_cache=/tmp/npm-cache-$$
            mkdir -p "/tmp/npm-cache-$$"
            
            # Set npm configuration for better reliability
            npm config set fetch-retries 3
            npm config set fetch-retry-factor 2
            npm config set fetch-retry-mintimeout 10000
            npm config set fetch-retry-maxtimeout 60000
            
            echo "üîß npm configuration:"
            echo "  Cache directory: $npm_config_cache"
            echo "  Retry settings: 3 attempts with exponential backoff"
            
            # Try npm ci first with enhanced reliability
            if ! npm ci --no-audit --no-fund --prefer-offline 2>/dev/null; then
              echo "‚ö†Ô∏è  npm ci failed, trying cache verification and cleanup..."
              
              # Clean up any partial installs
              rm -rf node_modules package-lock.json
              
              # Verify cache integrity
              npm cache verify || npm cache clean --force
              
              # Try npm install with fresh approach
              echo "üîÑ Attempting fresh npm install..."
              if ! npm install --no-audit --no-fund --prefer-offline; then
                echo "‚ö†Ô∏è  Standard npm install failed, trying with legacy resolver..."
                
                # Final fallback with legacy resolver and no integrity checks
                npm install --no-audit --no-fund --legacy-peer-deps --no-package-lock
                
                # Generate new package-lock.json
                echo "üîß Generating new package-lock.json..."
                npm install --package-lock-only --no-audit --no-fund
              fi
            fi
            
            echo "üèóÔ∏è  Building frontend..."
            npm run build
            
            # Upload to S3 (using cached environment variable with --no-progress for cleaner logs)
            echo "üì§ Uploading to S3..."
            aws s3 sync build/ "s3://$FRONTEND_BUCKET" --delete --no-progress
            
            echo "‚úÖ Frontend deployed from: $FRONTEND_DIR"
            echo "üåê Frontend URL: $FRONTEND_URL"
          else
            echo "‚ö†Ô∏è  package.json not found in $FRONTEND_DIR directory"
          fi
          
          cd ..
        else
          echo "‚ö†Ô∏è  Frontend directory not found (tried: ${FRONTEND_DIRS[*]}), skipping"
          echo "üîç Available directories:"
          ls -la . | grep ^d || echo "No directories found"
        fi

    - name: Initialize database schema conditionally
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        echo "üóÑÔ∏è  Attempting database schema initialization..."

        # Get password from secrets manager
        SECRET_VALUE=$(aws secretsmanager get-secret-value --secret-id "$LEGACY_DB_SECRET" --query 'SecretString' --output text)
        DB_PASSWORD=$(echo "$SECRET_VALUE" | jq -r '.password')
        
        # Security: Mask the database password
        echo "::add-mask::$DB_PASSWORD"
        
        # Quick TCP check (10s timeout) ‚Äî skip if not reachable
        if timeout 10 bash -c "cat < /dev/null > /dev/tcp/$LEGACY_DB_ENDPOINT/3306" 2>/dev/null; then
          echo "‚úÖ RDS endpoint reachable, running schema creation via mysql client"
          
          # Create SQL schema and execute using mysql client
          cat << 'EOF' > schema.sql
        CREATE DATABASE IF NOT EXISTS legacydb;
        USE legacydb;
        
        CREATE TABLE IF NOT EXISTS subscribers (
          id VARCHAR(64) PRIMARY KEY,
          uid VARCHAR(64) UNIQUE,
          imsi VARCHAR(64),
          msisdn VARCHAR(64),
          email VARCHAR(255),
          name VARCHAR(255),
          phone VARCHAR(20),
          status VARCHAR(50) DEFAULT 'active',
          plan_type VARCHAR(100) DEFAULT 'STANDARD_PREPAID',
          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
          updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
          INDEX idx_uid (uid),
          INDEX idx_imsi (imsi),
          INDEX idx_msisdn (msisdn),
          INDEX idx_email (email),
          INDEX idx_status (status)
        );
        
        CREATE TABLE IF NOT EXISTS migration_logs (
          id VARCHAR(64) PRIMARY KEY,
          job_id VARCHAR(64),
          file_name VARCHAR(255),
          total_records INT DEFAULT 0,
          processed_count INT DEFAULT 0,
          failed_count INT DEFAULT 0,
          status VARCHAR(50) DEFAULT 'processing',
          error_message TEXT,
          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
          completed_at TIMESTAMP NULL,
          INDEX idx_job_id (job_id),
          INDEX idx_status (status)
        );
        EOF
        
          MYSQL_PWD="$DB_PASSWORD" mysql -h "$LEGACY_DB_ENDPOINT" -u admin < schema.sql
          echo "‚úÖ Database schema initialized"
        else
          echo "‚ö†Ô∏è  RDS not reachable from GitHub runner. Skipping schema init."
          echo "‚ÑπÔ∏è  Consider initializing via a Lambda task or a private runner in your VPC."
        fi

    - name: Run comprehensive smoke tests
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        
        echo "üß™ Running comprehensive smoke tests..."
        
        # Wait a moment for all configurations to settle
        echo "‚è≥ Waiting 30 seconds for all configurations to settle..."
        sleep 30
        
        # Test API health with status code and detailed response
        echo "üîç Testing API health endpoint..."
        HEALTH_RESPONSE=$(curl -s "$BACKEND_API_URL/api/health" || echo "ERROR")
        echo "Health Response: $HEALTH_RESPONSE"
        
        if [[ "$HEALTH_RESPONSE" == *"healthy"* ]] || [[ "$HEALTH_RESPONSE" == *"success"* ]]; then
          echo "‚úÖ API health check passed"
        else
          echo "‚ùå API health check failed - Lambda may have configuration issues"
          echo "üîç Checking Backend Lambda logs..."
          aws logs describe-log-groups --log-group-name-prefix "/aws/lambda/subscriber-migration-portal-main-BackendLambda" --query 'logGroups[0].logGroupName' --output text | head -5 || echo "Could not find log group"
          
          # Show recent Lambda errors
          echo "üîç Recent Lambda errors (last 10 minutes):"
          START_TIME=$(date -d '10 minutes ago' --iso-8601)
          aws logs filter-log-events \
            --log-group-name "/aws/lambda/subscriber-migration-portal-main-BackendLambda-prod" \
            --start-time $(date -d "$START_TIME" +%s)000 \
            --filter-pattern "ERROR" \
            --query 'events[*].message' --output text | head -10 || echo "No recent errors found"
        fi
        
        # Test frontend
        echo "üîç Testing frontend availability..."
        if curl -f -s "$FRONTEND_URL" >/dev/null; then
          echo "‚úÖ Frontend accessible"
        else
          echo "‚ö†Ô∏è  Frontend not accessible yet"
        fi
        
        # Test S3 upload capability
        echo "üîç Testing S3 upload capability..."
        echo "test file" > test-upload.txt
        if aws s3 cp test-upload.txt "s3://$UPLOAD_BUCKET/test/test-upload.txt"; then
          echo "‚úÖ S3 upload test passed"
          aws s3 rm "s3://$UPLOAD_BUCKET/test/test-upload.txt" || true
        else
          echo "‚ö†Ô∏è  S3 upload test failed"
        fi
        rm -f test-upload.txt
        
        echo ""
        echo "üéâ === FULL DEPLOYMENT COMPLETED SUCCESSFULLY ==="
        echo "üåê Frontend: $FRONTEND_URL"
        echo "üì° API: $BACKEND_API_URL" 
        echo "üìÅ Upload Bucket: $UPLOAD_BUCKET"
        echo "üîê Test Login: admin / Admin@123"
        echo "‚úÖ All services deployed and configured automatically!"
        echo ""
        echo "üìã Next Steps:"
        echo "1. Visit the frontend URL to see your application"
        echo "2. Login with admin/Admin@123, operator/Operator@123, or guest/Guest@123"
        echo "3. Test file uploads through the UI"
        echo "4. Check CloudWatch logs for any issues"
        echo "5. Monitor DynamoDB tables for processed data"

    - name: Upload deployment logs
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: deployment-logs
        path: |
          deployment-attempt-*.log
          current_notif.json
          new_lambda.json
          merged_notif.json
          schema.sql
          aws/parameters.json
        if-no-files-found: ignore

    - name: Error reporting and cleanup
      if: failure()
      run: |
        set -euo pipefail
        
        # Source the functions
        source /tmp/stack_functions.sh
        
        echo "üí• === DEPLOYMENT WORKFLOW FAILED ==="
        
        STACK_NAME="${{ env.STACK_NAME }}"
        AWS_REGION="${{ env.AWS_REGION }}"
        
        # Generate error report
        echo ""
        echo "üìã === ERROR REPORT ==="
        echo "Timestamp: $(date -u)"
        echo "Stack Name: $STACK_NAME"
        echo "Region: $AWS_REGION"
        echo "Workflow: ${{ github.workflow }}"
        echo "Run ID: ${{ github.run_id }}"
        echo ""
        
        # Check stack status safely
        STACK_STATUS=$(get_stack_status "$STACK_NAME" "$AWS_REGION")
        echo "üìä Current Stack Status: $STACK_STATUS"
        
        if [[ "$STACK_STATUS" != "STACK_NOT_EXISTS" ]]; then
          echo ""
          echo "üìã Recent Stack Events:"
          aws cloudformation describe-stack-events --stack-name "$STACK_NAME" --region "$AWS_REGION" \
            --query 'StackEvents[0:20].[Timestamp,LogicalResourceId,ResourceType,ResourceStatus,ResourceStatusReason]' \
            --output table 2>/dev/null || echo "Could not retrieve stack events"
          
          # Cleanup failed stack
          if [[ "$STACK_STATUS" == *"_FAILED" || "$STACK_STATUS" == *"_ROLLBACK_COMPLETE" ]]; then
            echo ""
            echo "üßπ Automated cleanup..."
            delete_failed_stack_robust "$STACK_NAME" "$AWS_REGION" || true
            
            # Safe cleanup (only if CLEANUP_ALL is enabled)
            if [[ "${{ env.CLEANUP_ALL }}" == "true" ]]; then
              echo "üßπ Destructive S3 cleanup enabled (CLEANUP_ALL=true)"
              ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
              delete_s3_bucket_enhanced "sub-mig-logs-$ACCOUNT_ID" || true
              delete_s3_bucket_enhanced "sub-mig-web-$ACCOUNT_ID-prod" || true
              delete_s3_bucket_enhanced "sub-mig-data-$ACCOUNT_ID-prod" || true
            else
              echo "‚ÑπÔ∏è Skipping destructive S3 cleanup (CLEANUP_ALL!=true)"
            fi
          fi
        else
          echo "‚ÑπÔ∏è  Stack does not exist - no cleanup needed"
        fi
        
        echo ""
        echo "üíæ Error report completed"
        exit 1
