name: Enhanced Subscriber Migration Portal Deployment

on:
  push:
    branches: [ main ]
    paths:
      - 'aws/**'
      - '.github/workflows/**'
      - 'backend/**'
      - 'frontend/**'
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      force_recreate:
        description: 'Force recreate stack (true/false)'
        required: false
        default: 'false'
      cleanup_resources:
        description: 'Cleanup failed resources (true/false)'
        required: false
        default: 'false'

env:
  AWS_REGION: us-east-1
  STACK_NAME: subscriber-migration-portal-main
  TEMPLATE_FILE: aws/cloudformation.yaml

jobs:
  deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Install required tools
      run: |
        set -euo pipefail
        
        # Install AWS CLI v2
        curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
        unzip -q awscliv2.zip
        sudo ./aws/install --update
        
        # Install additional tools
        sudo apt-get update
        sudo apt-get install -y jq mysql-client zip python3-pip
        curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
        sudo apt-get install -y nodejs
        
        # Verify installations
        aws --version
        node --version
        python3 --version

    - name: Create deployment functions
      run: |
        cat > /tmp/functions.sh << 'EOF'
        #!/bin/bash
        
        stack_exists() {
          aws cloudformation describe-stacks --stack-name "$1" --region "$2" &>/dev/null
        }
        
        wait_for_lambda() {
          local function_name="$1"
          local max_wait=300
          local wait_interval=15
          local elapsed=0
          
          echo "‚è≥ Waiting for Lambda function '$function_name' to be ready..."
          
          while [[ $elapsed -lt $max_wait ]]; do
            STATE=$(aws lambda get-function --function-name "$function_name" --query 'Configuration.State' --output text 2>/dev/null || echo "UNKNOWN")
            STATUS=$(aws lambda get-function --function-name "$function_name" --query 'Configuration.LastUpdateStatus' --output text 2>/dev/null || echo "UNKNOWN")
            
            if [[ "$STATE" == "Active" && "$STATUS" == "Successful" ]]; then
              echo "‚úÖ Lambda function '$function_name' is ready"
              return 0
            fi
            
            sleep $wait_interval
            elapsed=$((elapsed + wait_interval))
          done
          
          echo "‚ö†Ô∏è Timeout waiting for Lambda function '$function_name'"
          return 1
        }
        EOF
        chmod +x /tmp/functions.sh

    - name: Create deployment parameters
      run: |
        source /tmp/functions.sh
        
        # Generate secure password
        if [[ -z "${{ secrets.LEGACY_DB_PASSWORD }}" ]]; then
          DB_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-20)
          echo "‚ö†Ô∏è Using auto-generated password"
        else
          DB_PASSWORD="${{ secrets.LEGACY_DB_PASSWORD }}"
        fi
        
        CURRENT_TIME=$(date +%Y-%m-%d-%H-%M-%S)
        
        cat > aws/parameters.json << EOF
        [
          {
            "ParameterKey": "Environment",
            "ParameterValue": "prod"
          },
          {
            "ParameterKey": "LegacyDbUsername",
            "ParameterValue": "admin"
          },
          {
            "ParameterKey": "LegacyDbPassword",
            "ParameterValue": "$DB_PASSWORD"
          },
          {
            "ParameterKey": "CurrentTime",
            "ParameterValue": "$CURRENT_TIME"
          }
        ]
        EOF
        
        echo "üìã Parameters file created with timestamp: $CURRENT_TIME"

    - name: Deploy CloudFormation stack
      run: |
        set -euo pipefail
        source /tmp/functions.sh
        
        echo "üöÄ Starting CloudFormation deployment..."
        
        # Handle force recreate
        if [[ "${{ github.event.inputs.force_recreate }}" == "true" ]]; then
          echo "üîÑ Force recreate requested"
          if stack_exists "$STACK_NAME" "$AWS_REGION"; then
            echo "üóëÔ∏è Deleting existing stack..."
            aws cloudformation delete-stack --stack-name "$STACK_NAME" --region "$AWS_REGION"
            aws cloudformation wait stack-delete-complete --stack-name "$STACK_NAME" --region "$AWS_REGION"
          fi
        fi
        
        # Determine operation
        if stack_exists "$STACK_NAME" "$AWS_REGION"; then
          OPERATION="update-stack"
          echo "üîÑ Updating existing stack..."
        else
          OPERATION="create-stack"
          echo "üÜï Creating new stack..."
        fi
        
        # Execute CloudFormation deployment
        aws cloudformation $OPERATION \
          --stack-name "$STACK_NAME" \
          --template-body "file://$TEMPLATE_FILE" \
          --parameters file://aws/parameters.json \
          --capabilities CAPABILITY_NAMED_IAM CAPABILITY_IAM \
          --region "$AWS_REGION" \
          --tags Key=Project,Value=SubscriberMigration Key=Environment,Value=Production Key=DeployedBy,Value=GitHub-Actions
        
        # Wait for completion
        if [[ "$OPERATION" == "create-stack" ]]; then
          echo "‚è≥ Waiting for stack creation (this may take 15-20 minutes)..."
          aws cloudformation wait stack-create-complete --stack-name "$STACK_NAME" --region "$AWS_REGION"
        else
          echo "‚è≥ Waiting for stack update..."
          aws cloudformation wait stack-update-complete --stack-name "$STACK_NAME" --region "$AWS_REGION"
        fi
        
        echo "‚úÖ CloudFormation deployment completed successfully"
        echo "DEPLOYMENT_SUCCESS=true" >> $GITHUB_ENV

    - name: Extract and cache stack outputs
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        
        echo "üìã Extracting stack outputs..."
        
        # Get all outputs in one API call
        aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
          --query 'Stacks[0].Outputs' --output json > outputs.json
        
        echo "üîç Available stack outputs:"
        cat outputs.json | jq -r '.[] | "\(.OutputKey): \(.OutputValue)"'
        
        # Parse critical outputs
        BACKEND_LAMBDA_NAME=$(jq -r '.[] | select(.OutputKey=="BackendLambdaName") | .OutputValue' outputs.json)
        MIGRATION_LAMBDA_NAME=$(jq -r '.[] | select(.OutputKey=="MigrationProcessorFunctionName") | .OutputValue' outputs.json)
        FRONTEND_BUCKET=$(jq -r '.[] | select(.OutputKey=="FrontendBucketName") | .OutputValue' outputs.json)
        UPLOAD_BUCKET=$(jq -r '.[] | select(.OutputKey=="MigrationUploadBucketName") | .OutputValue' outputs.json)
        BACKEND_API_URL=$(jq -r '.[] | select(.OutputKey=="BackendApiUrl") | .OutputValue' outputs.json)
        CLOUDFRONT_ID=$(jq -r '.[] | select(.OutputKey=="CloudFrontDistributionId") | .OutputValue' outputs.json)
        CLOUDFRONT_DOMAIN=$(jq -r '.[] | select(.OutputKey=="CloudFrontDomainName") | .OutputValue' outputs.json)
        HTTPS_FRONTEND_URL=$(jq -r '.[] | select(.OutputKey=="SecureFrontendURL") | .OutputValue' outputs.json)
        BACKEND_API_ID=$(jq -r '.[] | select(.OutputKey=="BackendApiId") | .OutputValue' outputs.json)
        
        # Export to environment for subsequent steps
        echo "BACKEND_LAMBDA_NAME=$BACKEND_LAMBDA_NAME" >> $GITHUB_ENV
        echo "MIGRATION_LAMBDA_NAME=$MIGRATION_LAMBDA_NAME" >> $GITHUB_ENV
        echo "FRONTEND_BUCKET=$FRONTEND_BUCKET" >> $GITHUB_ENV
        echo "UPLOAD_BUCKET=$UPLOAD_BUCKET" >> $GITHUB_ENV
        echo "BACKEND_API_URL=$BACKEND_API_URL" >> $GITHUB_ENV
        echo "CLOUDFRONT_ID=$CLOUDFRONT_ID" >> $GITHUB_ENV
        echo "CLOUDFRONT_DOMAIN=$CLOUDFRONT_DOMAIN" >> $GITHUB_ENV
        echo "HTTPS_FRONTEND_URL=$HTTPS_FRONTEND_URL" >> $GITHUB_ENV
        echo "BACKEND_API_ID=$BACKEND_API_ID" >> $GITHUB_ENV
        
        echo "‚úÖ Stack outputs extracted and cached"

    - name: Deploy enhanced backend Lambda code
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        source /tmp/functions.sh
        
        echo "üöÄ Deploying enhanced backend Lambda code..."
        
        if [[ -d "backend" ]]; then
          cd backend
          
          # Install dependencies
          echo "üì¶ Installing Python dependencies..."
          pip3 install -r requirements.txt -t . --upgrade
          
          # Create optimized deployment package
          echo "üì¶ Creating deployment package..."
          zip -r ../backend-enhanced.zip . -x \
            "*.git*" "__pycache__/*" "*.pyc" "venv/*" "env/*" \
            "tests/*" "*.test.py" ".pytest_cache/*" \
            "*.log" ".env" "*.env.*" "migration_processor/*"
          
          cd ..
          
          # Deploy to Lambda
          echo "üöÄ Deploying to Lambda function: $BACKEND_LAMBDA_NAME"
          aws lambda update-function-code \
            --function-name "$BACKEND_LAMBDA_NAME" \
            --zip-file fileb://backend-enhanced.zip
          
          # Wait for deployment to complete
          wait_for_lambda "$BACKEND_LAMBDA_NAME"
          
          echo "‚úÖ Backend Lambda code deployed successfully"
        else
          echo "‚ö†Ô∏è Backend directory not found"
        fi

    - name: Deploy migration processor Lambda code
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        source /tmp/functions.sh
        
        echo "üöÄ Deploying migration processor Lambda code..."
        
        if [[ -d "backend/migration_processor" ]]; then
          cd backend/migration_processor
          
          # Install dependencies if requirements.txt exists
          if [[ -f "requirements.txt" ]]; then
            pip3 install -r requirements.txt -t .
          fi
          
          # Create deployment package
          zip -r ../../migration-processor.zip . -x \
            "*.git*" "__pycache__/*" "*.pyc" "tests/*"
          
          cd ../..
          
          # Deploy to Lambda
          aws lambda update-function-code \
            --function-name "$MIGRATION_LAMBDA_NAME" \
            --zip-file fileb://migration-processor.zip
          
          wait_for_lambda "$MIGRATION_LAMBDA_NAME"
          
          echo "‚úÖ Migration processor Lambda deployed"
        else
          echo "‚ÑπÔ∏è Migration processor directory not found, using backend code"
          
          # Use main backend code as fallback
          cd backend
          zip -r ../migration-fallback.zip . -x \
            "*.git*" "__pycache__/*" "*.pyc"
          cd ..
          
          aws lambda update-function-code \
            --function-name "$MIGRATION_LAMBDA_NAME" \
            --zip-file fileb://migration-fallback.zip
          
          wait_for_lambda "$MIGRATION_LAMBDA_NAME"
        fi

    - name: Deploy enhanced frontend
      if: env.DEPLOYMENT_SUCCESS == 'true'  
      run: |
        set -euo pipefail
        
        echo "üåê Deploying enhanced React frontend..."
        
        if [[ -d "frontend" ]]; then
          cd frontend
          
          # Enhanced npm installation with cache management
          echo "üì¶ Installing frontend dependencies with enhanced error handling..."
          
          # Clear npm cache to prevent corruption
          npm cache clean --force
          export npm_config_cache=/tmp/npm-cache-$$
          mkdir -p "/tmp/npm-cache-$$"
          
          # Enhanced npm configuration
          npm config set fetch-retries 5
          npm config set fetch-retry-factor 2
          npm config set fetch-retry-mintimeout 10000
          npm config set fetch-retry-maxtimeout 60000
          
          # Try multiple installation strategies
          if ! npm ci --no-audit --no-fund --prefer-offline; then
            echo "‚ö†Ô∏è npm ci failed, trying npm install"
            rm -rf node_modules package-lock.json
            
            if ! npm install --no-audit --no-fund --prefer-offline; then
              echo "‚ö†Ô∏è Standard npm install failed, trying legacy resolver"
              npm install --no-audit --no-fund --legacy-peer-deps --no-package-lock
              npm install --package-lock-only --no-audit --no-fund
            fi
          fi
          
          # Build with production optimizations
          echo "üèóÔ∏è Building production frontend..."
          NODE_ENV=production npm run build
          
          # Upload to S3 with CloudFront-optimized headers
          echo "üì§ Uploading to S3 with CloudFront optimization..."
          
          # Static assets with long cache
          aws s3 sync build/static/ "s3://$FRONTEND_BUCKET/static/" \
            --delete \
            --cache-control "public, max-age=31536000, immutable" \
            --content-encoding gzip
          
          # HTML files with short cache
          aws s3 sync build/ "s3://$FRONTEND_BUCKET/" \
            --delete \
            --cache-control "public, max-age=300" \
            --exclude "static/*" --include "*.html"
          
          # Other files with medium cache
          aws s3 sync build/ "s3://$FRONTEND_BUCKET/" \
            --delete \
            --cache-control "public, max-age=86400" \
            --exclude "static/*" --exclude "*.html"
          
          cd ..
          
          # CloudFront cache invalidation
          if [[ -n "$CLOUDFRONT_ID" && "$CLOUDFRONT_ID" != "null" ]]; then
            echo "‚ôªÔ∏è Invalidating CloudFront cache..."
            INVALIDATION_ID=$(aws cloudfront create-invalidation \
              --distribution-id "$CLOUDFRONT_ID" \
              --paths "/*" \
              --query 'Invalidation.Id' --output text)
            
            echo "‚è≥ CloudFront invalidation started: $INVALIDATION_ID"
            echo "‚ÑπÔ∏è Cache invalidation will complete in the background"
          fi
          
          echo "‚úÖ Frontend deployed with CloudFront optimization"
        else
          echo "‚ö†Ô∏è Frontend directory not found"
        fi

    - name: Setup S3 notifications for migration processing
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        
        echo "üì° Setting up S3 notifications for migration processing..."
        
        # Get Migration Lambda ARN from outputs
        MIGRATION_ARN=$(jq -r '.[] | select(.OutputKey=="MigrationProcessorArn") | .OutputValue' outputs.json)
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        
        # Configure S3 bucket notification
        cat > notification-config.json << EOF
        {
          "LambdaFunctionConfigurations": [
            {
              "Id": "MigrationProcessorTrigger",
              "LambdaFunctionArn": "$MIGRATION_ARN",
              "Events": ["s3:ObjectCreated:*"],
              "Filter": {
                "Key": {
                  "FilterRules": [
                    {"Name": "prefix", "Value": "uploads/"},
                    {"Name": "suffix", "Value": ".csv"}
                  ]
                }
              }
            }
          ]
        }
        EOF
        
        # Apply notification configuration
        aws s3api put-bucket-notification-configuration \
          --bucket "$UPLOAD_BUCKET" \
          --notification-configuration file://notification-config.json
        
        echo "‚úÖ S3 notifications configured for automated migration processing"

    - name: Run comprehensive smoke tests
      if: env.DEPLOYMENT_SUCCESS == 'true'
      run: |
        set -euo pipefail
        source /tmp/functions.sh
        
        echo "üß™ Running comprehensive smoke tests..."
        
        # Wait for all services to settle
        echo "‚è≥ Waiting 60 seconds for all services to settle..."
        sleep 60
        
        # Test 1: Direct Lambda health check (MAIN FIX TEST)
        echo "üîç Test 1: Direct Lambda health check (empty event)..."
        aws lambda invoke \
          --function-name "$BACKEND_LAMBDA_NAME" \
          --payload '{}' \
          lambda-direct.json
        
        echo "Direct Lambda Response:"
        cat lambda-direct.json | jq '.'
        
        # Test 2: Direct Lambda with minimal event
        echo "üîç Test 2: Direct Lambda with minimal HTTP event..."
        aws lambda invoke \
          --function-name "$BACKEND_LAMBDA_NAME" \
          --payload '{"httpMethod":"GET","path":"/api/health"}' \
          lambda-http.json
        
        echo "HTTP Lambda Response:"
        cat lambda-http.json | jq '.'
        
        # Test 3: API Gateway health endpoint
        echo "üîç Test 3: API Gateway health endpoint..."
        HEALTH_RESPONSE=$(curl -s -w "HTTP_CODE:%{http_code}" "$BACKEND_API_URL/api/health")
        echo "API Health Response: $HEALTH_RESPONSE"
        
        # Test 4: Alternative health endpoint
        echo "üîç Test 4: Alternative health endpoint..."
        ALT_HEALTH=$(curl -s -w "HTTP_CODE:%{http_code}" "$BACKEND_API_URL/health")
        echo "Alternative Health: $ALT_HEALTH"
        
        # Test 5: Login endpoint functionality
        echo "üîç Test 5: Login endpoint..."
        LOGIN_TEST=$(curl -s -X POST "$BACKEND_API_URL/api/auth/login" \
          -H "Content-Type: application/json" \
          -d '{"username":"admin","password":"Admin@123"}' \
          -w "HTTP_CODE:%{http_code}")
        echo "Login Test: $LOGIN_TEST"
        
        # Test 6: CloudFront HTTPS frontend
        echo "üîç Test 6: Testing secure HTTPS frontend..."
        if curl -f -s "$HTTPS_FRONTEND_URL" >/dev/null; then
          echo "‚úÖ HTTPS frontend accessible"
        else
          echo "‚ö†Ô∏è HTTPS frontend not yet accessible (CloudFront may still be deploying)"
        fi
        
        # Test 7: S3 upload capability
        echo "üîç Test 7: Testing S3 upload capability..."
        echo "Enterprise test upload - $(date)" > test-upload.txt
        if aws s3 cp test-upload.txt "s3://$UPLOAD_BUCKET/test/deployment-test.txt"; then
          echo "‚úÖ S3 upload test passed"
          aws s3 rm "s3://$UPLOAD_BUCKET/test/deployment-test.txt"
        else
          echo "‚ö†Ô∏è S3 upload test failed"
        fi
        rm -f test-upload.txt
        
        # Test 8: DynamoDB table access
        echo "üîç Test 8: Testing DynamoDB table access..."
        aws dynamodb describe-table --table-name "subscriber-table-prod" \
          --query 'Table.TableStatus' --output text > /dev/null
        echo "‚úÖ DynamoDB tables accessible"
        
        echo ""
        echo "üéâ === ENHANCED DEPLOYMENT COMPLETED SUCCESSFULLY ==="
        echo ""
        echo "üîê **SECURE HTTPS FRONTEND**: $HTTPS_FRONTEND_URL"
        echo "üì° **API ENDPOINT**: $BACKEND_API_URL"
        echo "‚òÅÔ∏è **CLOUDFRONT ID**: $CLOUDFRONT_ID"
        echo "üìÅ **UPLOAD BUCKET**: $UPLOAD_BUCKET"
        echo ""
        echo "üîê **LOGIN CREDENTIALS**:"
        echo "   ‚Ä¢ admin / Admin@123 (Full Access)"
        echo "   ‚Ä¢ operator / Operator@123 (Read/Write)"  
        echo "   ‚Ä¢ guest / Guest@123 (Read Only)"
        echo ""
        echo "‚úÖ **ALL SERVICES DEPLOYED WITH ENTERPRISE FEATURES!
