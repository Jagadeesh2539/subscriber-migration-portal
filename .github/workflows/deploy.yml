name: üöÄ Production Deployment - Enterprise Grade

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_DEFAULT_REGION: us-east-1
  STACK_NAME: subscriber-migration-portal-prod
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'
  # Timeouts and retry settings
  CLEANUP_TIMEOUT_MINUTES: 15
  RDS_DELETE_TIMEOUT_MINUTES: 12
  STACK_DELETE_TIMEOUT_MINUTES: 15
  MAX_RETRY_ATTEMPTS: 5

jobs:
  validate:
    name: üîç Validate Architecture
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install validation tools
        run: |
          set -euo pipefail
          pip install --upgrade pip
          pip install aws-sam-cli boto3 jq
      
      - name: Validate SAM Template
        run: |
          set -euo pipefail
          cd aws
          
          echo "üîç Validating SAM template syntax..."
          if sam validate --template template.yaml --region ${{ env.AWS_DEFAULT_REGION }}; then
            echo "‚úÖ SAM template is valid"
          else
            echo "‚ùå SAM template validation failed"
            exit 1
          fi
      
      - name: Validate Step Functions Definitions
        run: |
          set -euo pipefail
          
          if [ ! -d "aws/stepfunctions" ]; then
            echo "‚ö†Ô∏è No Step Functions directory found, skipping validation"
            exit 0
          fi
          
          echo "üîç Validating Step Functions definitions..."
          
          for file in aws/stepfunctions/*.json; do
            if [[ -f "$file" ]]; then
              filename=$(basename "$file")
              echo "  Validating: $filename"
              
              if ! jq empty "$file" 2>/dev/null; then
                echo "  ‚ùå Invalid JSON in $file"
                exit 1
              fi
              
              if ! jq -e '.StartAt' "$file" >/dev/null 2>&1; then
                echo "  ‚ùå Missing StartAt in $file"
                exit 1
              fi
              
              if ! jq -e '.States' "$file" >/dev/null 2>&1; then
                echo "  ‚ùå Missing States in $file"
                exit 1
              fi
              
              echo "  ‚úÖ Valid: $filename"
            fi
          done
          
          echo "‚úÖ All validations passed"

  discover-infrastructure:
    name: üîç Discover VPC Infrastructure
    runs-on: ubuntu-latest
    needs: validate
    outputs:
      vpc-id: ${{ steps.discover.outputs.vpc_id }}
      private-subnet-1: ${{ steps.discover.outputs.private_subnet_1 }}
      private-subnet-2: ${{ steps.discover.outputs.private_subnet_2 }}
      public-subnet-1: ${{ steps.discover.outputs.public_subnet_1 }}
      public-subnet-2: ${{ steps.discover.outputs.public_subnet_2 }}
    steps:
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
      
      - name: üîç Auto-discover VPC and Subnets with validation
        id: discover
        run: |
          set -euo pipefail
          
          echo "üîç Discovering VPC infrastructure in ${{ env.AWS_DEFAULT_REGION }}..."
          
          # Discover VPC
          VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=is-default,Values=true" \
            --query 'Vpcs[0].VpcId' \
            --output text 2>/dev/null || echo "None")
          
          if [[ "$VPC_ID" == "None" || -z "$VPC_ID" ]]; then
            echo "‚ö†Ô∏è No default VPC found, searching for any available VPC..."
            VPC_ID=$(aws ec2 describe-vpcs \
              --query 'Vpcs[0].VpcId' \
              --output text 2>/dev/null || echo "None")
          fi
          
          if [[ "$VPC_ID" == "None" || -z "$VPC_ID" ]]; then
            echo "‚ùå CRITICAL: No VPC found in region ${{ env.AWS_DEFAULT_REGION }}"
            echo "Please create a VPC or use a different region"
            exit 1
          fi
          
          echo "‚úÖ Found VPC: $VPC_ID"
          
          # Validate VPC state
          VPC_STATE=$(aws ec2 describe-vpcs \
            --vpc-ids "$VPC_ID" \
            --query 'Vpcs[0].State' \
            --output text 2>/dev/null || echo "unknown")
          
          if [[ "$VPC_STATE" != "available" ]]; then
            echo "‚ùå VPC is not in available state: $VPC_STATE"
            exit 1
          fi
          
          # Discover private subnets
          echo "üîç Discovering private subnets..."
          PRIVATE_SUBNETS=($(aws ec2 describe-subnets \
            --filters "Name=vpc-id,Values=$VPC_ID" "Name=map-public-ip-on-launch,Values=false" \
            --query 'Subnets[?State==`available`].SubnetId' \
            --output text || echo ""))
          
          PRIVATE_1=${PRIVATE_SUBNETS[0]:-""}
          PRIVATE_2=${PRIVATE_SUBNETS[1]:-""}
          
          # Discover public subnets
          echo "üîç Discovering public subnets..."
          PUBLIC_SUBNETS=($(aws ec2 describe-subnets \
            --filters "Name=vpc-id,Values=$VPC_ID" "Name=map-public-ip-on-launch,Values=true" \
            --query 'Subnets[?State==`available`].SubnetId' \
            --output text || echo ""))
          
          PUBLIC_1=${PUBLIC_SUBNETS[0]:-""}
          PUBLIC_2=${PUBLIC_SUBNETS[1]:-""}
          
          # Validation
          if [[ -z "$PRIVATE_1" || -z "$PRIVATE_2" ]]; then
            echo "‚ùå CRITICAL: Need at least 2 private subnets in VPC $VPC_ID"
            echo "Found private subnets: ${PRIVATE_SUBNETS[@]:-none}"
            echo ""
            echo "Available subnets in VPC:"
            aws ec2 describe-subnets \
              --filters "Name=vpc-id,Values=$VPC_ID" \
              --query 'Subnets[].[SubnetId,AvailabilityZone,MapPublicIpOnLaunch,State]' \
              --output table
            exit 1
          fi
          
          # Verify subnets are in different AZs
          AZ_1=$(aws ec2 describe-subnets --subnet-ids "$PRIVATE_1" --query 'Subnets[0].AvailabilityZone' --output text)
          AZ_2=$(aws ec2 describe-subnets --subnet-ids "$PRIVATE_2" --query 'Subnets[0].AvailabilityZone' --output text)
          
          if [[ "$AZ_1" == "$AZ_2" ]]; then
            echo "‚ö†Ô∏è WARNING: Both private subnets are in the same AZ ($AZ_1)"
            echo "This may impact high availability"
          fi
          
          echo ""
          echo "‚úÖ Infrastructure discovered and validated:"
          echo "  VPC:           $VPC_ID (state: $VPC_STATE)"
          echo "  Private 1:     $PRIVATE_1 (AZ: $AZ_1)"
          echo "  Private 2:     $PRIVATE_2 (AZ: $AZ_2)"
          echo "  Public 1:      ${PUBLIC_1:-<none>}"
          echo "  Public 2:      ${PUBLIC_2:-<none>}"
          
          # Export outputs
          echo "vpc_id=$VPC_ID" >> $GITHUB_OUTPUT
          echo "private_subnet_1=$PRIVATE_1" >> $GITHUB_OUTPUT
          echo "private_subnet_2=$PRIVATE_2" >> $GITHUB_OUTPUT
          echo "public_subnet_1=$PUBLIC_1" >> $GITHUB_OUTPUT
          echo "public_subnet_2=$PUBLIC_2" >> $GITHUB_OUTPUT

  cleanup-and-deploy:
    name: üèóÔ∏è Cleanup & Deploy Infrastructure
    runs-on: ubuntu-latest
    needs: [validate, discover-infrastructure]
    timeout-minutes: 45
    environment: production
    outputs:
      api-endpoint: ${{ steps.export-outputs.outputs.api_endpoint }}
      schema-function-name: ${{ steps.export-outputs.outputs.schema_function_name }}
      deployment-status: ${{ steps.deploy-status.outputs.status }}
    steps:
      - uses: actions/checkout@v4
      
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
      
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: üî• COMPREHENSIVE CLEANUP with retry logic
        id: cleanup
        timeout-minutes: 15
        continue-on-error: false
        run: |
          set -euo pipefail
          STACK="${{ env.STACK_NAME }}"
          
          echo "üî• ============================================"
          echo "üî•  COMPREHENSIVE CLEANUP - PRODUCTION GRADE"
          echo "üî• ============================================"
          echo ""
          
          # Function: Retry command with exponential backoff
          retry_command() {
            local max_attempts=$1
            shift
            local command=("$@")
            local attempt=1
            local delay=5
            
            while [ $attempt -le $max_attempts ]; do
              if "${command[@]}" 2>/dev/null; then
                return 0
              fi
              
              if [ $attempt -lt $max_attempts ]; then
                echo "    ‚è≥ Retry $attempt/$max_attempts in ${delay}s..."
                sleep $delay
                delay=$((delay * 2))  # Exponential backoff
              fi
              attempt=$((attempt + 1))
            done
            
            return 1
          }
          
          # Function: Wait for resource deletion with timeout
          wait_for_deletion() {
            local resource_type=$1
            local check_command=$2
            local max_wait=$3
            local interval=${4:-10}
            
            echo "  ‚è≥ Waiting for $resource_type deletion (max ${max_wait}s)..."
            
            for ((i=0; i<max_wait; i+=interval)); do
              if ! eval "$check_command" 2>/dev/null; then
                echo "  ‚úÖ $resource_type deleted"
                return 0
              fi
              
              if [ $((i % 60)) -eq 0 ] && [ $i -gt 0 ]; then
                echo "    ‚è≥ Still waiting... ($((i/60)) min elapsed)"
              fi
              
              sleep $interval
            done
            
            echo "  ‚ö†Ô∏è Timeout waiting for $resource_type deletion"
            return 1
          }
          
          # Step 1: Check and handle CloudFormation stack
          echo "üìä STEP 1: CloudFormation Stack Status Check"
          echo "=============================================="
          
          if aws cloudformation describe-stacks --stack-name "$STACK" >/dev/null 2>&1; then
            STATUS=$(aws cloudformation describe-stacks \
              --stack-name "$STACK" \
              --query 'Stacks[0].StackStatus' \
              --output text)
            
            echo "  Current status: $STATUS"
            
            case "$STATUS" in
              ROLLBACK_COMPLETE|ROLLBACK_FAILED|CREATE_FAILED|DELETE_FAILED|UPDATE_ROLLBACK_COMPLETE|UPDATE_ROLLBACK_FAILED)
                echo "  üóëÔ∏è Stack in bad state - initiating deletion..."
                
                if aws cloudformation delete-stack --stack-name "$STACK"; then
                  echo "  ‚úÖ Delete initiated"
                  
                  # Wait with timeout
                  echo "  ‚è≥ Waiting for stack deletion (max ${{ env.STACK_DELETE_TIMEOUT_MINUTES }} min)..."
                  if timeout $((${{ env.STACK_DELETE_TIMEOUT_MINUTES }} * 60)) \
                     aws cloudformation wait stack-delete-complete --stack-name "$STACK" 2>/dev/null; then
                    echo "  ‚úÖ Stack deleted via CloudFormation"
                  else
                    echo "  ‚ö†Ô∏è Stack deletion timeout - will clean resources manually"
                  fi
                else
                  echo "  ‚ö†Ô∏è Stack deletion failed - will clean resources manually"
                fi
                ;;
              
              DELETE_IN_PROGRESS)
                echo "  ‚è≥ Stack deletion already in progress..."
                sleep 30
                ;;
              
              CREATE_COMPLETE|UPDATE_COMPLETE)
                echo "  ‚úÖ Stack is healthy - will update"
                ;;
              
              CREATE_IN_PROGRESS|UPDATE_IN_PROGRESS)
                echo "  ‚è≥ Stack operation in progress - waiting 60s..."
                sleep 60
                ;;
              
              *)
                echo "  ‚ö†Ô∏è Unexpected status: $STATUS"
                ;;
            esac
          else
            echo "  ‚úÖ No existing stack found"
          fi
          
          echo ""
          echo "üßπ STEP 2: Resource-Level Cleanup (Parallel)"
          echo "=============================================="
          
          # Step 2.1: Lambda ENIs (CRITICAL - must be deleted first)
          echo ""
          echo "üîå [2.1] Lambda Network Interfaces (ENIs)..."
          ENIS=$(aws ec2 describe-network-interfaces \
            --filters "Name=description,Values=*AWS Lambda VPC ENI*" "Name=status,Values=available" \
            --query 'NetworkInterfaces[].NetworkInterfaceId' \
            --output text 2>/dev/null || true)
          
          if [[ -n "$ENIS" ]]; then
            for eni in $ENIS; do
              echo "  üóëÔ∏è Deleting ENI: $eni"
              retry_command 3 aws ec2 delete-network-interface --network-interface-id "$eni" &
            done
            wait
            echo "  ‚úÖ Lambda ENIs cleanup initiated"
          else
            echo "  ‚úÖ No Lambda ENIs found"
          fi
          
          # Step 2.2: RDS Instances (with proper wait)
          echo ""
          echo "üóÑÔ∏è [2.2] RDS Database Instances..."
          RDS_INSTANCES=$(aws rds describe-db-instances \
            --query "DBInstances[?contains(DBInstanceIdentifier, '$STACK')].DBInstanceIdentifier" \
            --output text 2>/dev/null || true)
          
          if [[ -n "$RDS_INSTANCES" ]]; then
            for db in $RDS_INSTANCES; do
              DB_STATUS=$(aws rds describe-db-instances \
                --db-instance-identifier "$db" \
                --query 'DBInstances[0].DBInstanceStatus' \
                --output text 2>/dev/null || echo "not-found")
              
              echo "  üìä RDS: $db (status: $DB_STATUS)"
              
              if [[ "$DB_STATUS" == "deleting" ]]; then
                echo "    ‚è≥ Already deleting"
              elif [[ "$DB_STATUS" != "not-found" ]]; then
                echo "    üóëÔ∏è Initiating deletion..."
                aws rds delete-db-instance \
                  --db-instance-identifier "$db" \
                  --skip-final-snapshot \
                  --delete-automated-backups 2>/dev/null || true
              fi
            done
            
            # Wait for RDS deletion with timeout
            wait_for_deletion "RDS instances" \
              "aws rds describe-db-instances --query \"DBInstances[?contains(DBInstanceIdentifier, '$STACK')]\" --output text" \
              $((${{ env.RDS_DELETE_TIMEOUT_MINUTES }} * 60)) \
              15 || echo "  ‚ö†Ô∏è Proceeding despite RDS timeout"
          else
            echo "  ‚úÖ No RDS instances found"
          fi
          
          # Step 2.3: VPC Endpoints
          echo ""
          echo "üîó [2.3] VPC Endpoints..."
          VPCE_COUNT=0
          for vpce in $(aws ec2 describe-vpc-endpoints --query 'VpcEndpoints[].VpcEndpointId' --output text 2>/dev/null || true); do
            TAGS=$(aws ec2 describe-vpc-endpoints \
              --vpc-endpoint-ids "$vpce" \
              --query 'VpcEndpoints[0].Tags[?Key==`aws:cloudformation:stack-name`].Value' \
              --output text 2>/dev/null || true)
            
            if echo "$TAGS" | grep -q "$STACK"; then
              echo "  üóëÔ∏è Deleting VPC Endpoint: $vpce"
              retry_command 3 aws ec2 delete-vpc-endpoints --vpc-endpoint-ids "$vpce" &
              VPCE_COUNT=$((VPCE_COUNT + 1))
            fi
          done
          wait
          
          if [ $VPCE_COUNT -gt 0 ]; then
            echo "  ‚úÖ Deleted $VPCE_COUNT VPC endpoint(s)"
            sleep 30  # Wait for VPC endpoints to fully delete
          else
            echo "  ‚úÖ No VPC endpoints found"
          fi
          
          # Step 2.4: RDS Subnet Groups (after RDS instances)
          echo ""
          echo "üîß [2.4] RDS Subnet Groups..."
          for attempt in {1..5}; do
            SUBNET_GROUPS=$(aws rds describe-db-subnet-groups \
              --query "DBSubnetGroups[?contains(DBSubnetGroupName, '$STACK')].DBSubnetGroupName" \
              --output text 2>/dev/null || true)
            
            if [[ -z "$SUBNET_GROUPS" ]]; then
              echo "  ‚úÖ No RDS subnet groups found"
              break
            fi
            
            echo "  üîÑ Attempt $attempt/5..."
            for sg in $SUBNET_GROUPS; do
              if aws rds delete-db-subnet-group --db-subnet-group-name "$sg" 2>/dev/null; then
                echo "    ‚úÖ Deleted: $sg"
              else
                echo "    ‚è≠Ô∏è Still in use: $sg"
              fi
            done
            
            [ $attempt -lt 5 ] && sleep 15
          done
          
          # Step 2.5: S3 Buckets
          echo ""
          echo "ü™£ [2.5] S3 Buckets..."
          BUCKETS=$(aws s3api list-buckets \
            --query 'Buckets[].Name' \
            --output text 2>/dev/null | tr '\t' '\n' | grep "$STACK" 2>/dev/null || true)
          
          if [[ -n "$BUCKETS" ]]; then
            for bucket in $BUCKETS; do
              echo "  üóëÔ∏è Emptying bucket: $bucket"
              aws s3 rm "s3://$bucket" --recursive 2>/dev/null || true
              aws s3 rb "s3://$bucket" --force 2>/dev/null || true &
            done
            wait
            echo "  ‚úÖ S3 buckets cleaned"
          else
            echo "  ‚úÖ No S3 buckets found"
          fi
          
          # Step 2.6: Secrets Manager
          echo ""
          echo "üîê [2.6] Secrets Manager..."
          SECRETS=$(aws secretsmanager list-secrets \
            --query 'SecretList[].Name' \
            --output text 2>/dev/null | tr '\t' '\n' | grep "$STACK" 2>/dev/null || true)
          
          if [[ -n "$SECRETS" ]]; then
            for secret in $SECRETS; do
              echo "  üóëÔ∏è Deleting secret: $secret"
              retry_command 3 aws secretsmanager delete-secret \
                --secret-id "$secret" \
                --force-delete-without-recovery &
            done
            wait
            echo "  ‚úÖ Secrets deleted"
          else
            echo "  ‚úÖ No secrets found"
          fi
          
          # Step 2.7: Security Groups (with retries)
          echo ""
          echo "üõ°Ô∏è [2.7] Security Groups..."
          for attempt in {1..5}; do
            SG_DELETED=0
            echo "  üîÑ Attempt $attempt/5..."
            
            for sg in $(aws ec2 describe-security-groups \
              --query 'SecurityGroups[?GroupName!=`default`].GroupId' \
              --output text 2>/dev/null || true); do
              
              SG_NAME=$(aws ec2 describe-security-groups \
                --group-ids "$sg" \
                --query 'SecurityGroups[0].GroupName' \
                --output text 2>/dev/null || true)
              
              if echo "$SG_NAME" | grep -q "$STACK"; then
                if aws ec2 delete-security-group --group-id "$sg" 2>/dev/null; then
                  echo "    ‚úÖ Deleted: $sg ($SG_NAME)"
                  SG_DELETED=$((SG_DELETED + 1))
                fi
              fi
            done
            
            [ $SG_DELETED -eq 0 ] && break
            [ $attempt -lt 5 ] && sleep 20
          done
          echo "  ‚úÖ Security groups cleanup complete"
          
          # Step 2.8: Lambda Layers
          echo ""
          echo "üì¶ [2.8] Lambda Layers..."
          LAYERS=$(aws lambda list-layers \
            --query 'Layers[].LayerName' \
            --output text 2>/dev/null | tr '\t' '\n' | grep "$STACK" 2>/dev/null || true)
          
          if [[ -n "$LAYERS" ]]; then
            for layer in $LAYERS; do
              echo "  üóëÔ∏è Deleting layer: $layer"
              for version in $(aws lambda list-layer-versions \
                --layer-name "$layer" \
                --query 'LayerVersions[].Version' \
                --output text 2>/dev/null || true); do
                aws lambda delete-layer-version \
                  --layer-name "$layer" \
                  --version-number "$version" 2>/dev/null &
              done
            done
            wait
            echo "  ‚úÖ Lambda layers deleted"
          else
            echo "  ‚úÖ No Lambda layers found"
          fi
          
          # Step 2.9: CloudWatch Logs
          echo ""
          echo "üìù [2.9] CloudWatch Log Groups..."
          for prefix in "/aws/lambda/${STACK}" "/aws/vendedlogs/states/${STACK}"; do
            LOGS=$(aws logs describe-log-groups \
              --log-group-name-prefix "$prefix" \
              --query 'logGroups[].logGroupName' \
              --output text 2>/dev/null || true)
            
            if [[ -n "$LOGS" ]]; then
              for lg in $LOGS; do
                aws logs delete-log-group --log-group-name "$lg" 2>/dev/null &
              done
            fi
          done
          wait
          echo "  ‚úÖ Log groups cleaned"
          
          echo ""
          echo "‚úÖ ============================================"
          echo "‚úÖ  CLEANUP COMPLETED SUCCESSFULLY"
          echo "‚úÖ ============================================"

      - name: Install SAM CLI and dependencies
        run: |
          pip install --upgrade pip
          pip install aws-sam-cli boto3 jq

      - name: üöÄ Build SAM Application
        id: sam-build
        run: |
          set -euo pipefail
          cd aws
          
          echo "üî® Building SAM application..."
          
          if sam build --template template.yaml; then
            echo "‚úÖ SAM build successful"
            echo "build_status=success" >> $GITHUB_OUTPUT
          else
            echo "‚ùå SAM build failed"
            echo "build_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: üöÄ Deploy SAM Application
        id: sam-deploy
        run: |
          set -euo pipefail
          cd aws
          
          # Setup deployment bucket
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          BUCKET="sam-deployment-${ACCOUNT_ID}-${{ env.AWS_DEFAULT_REGION }}"
          
          echo "üì¶ Preparing S3 deployment bucket: $BUCKET"
          
          if ! aws s3api head-bucket --bucket "$BUCKET" 2>/dev/null; then
            echo "üÜï Creating deployment bucket..."
            if [[ "${{ env.AWS_DEFAULT_REGION }}" == "us-east-1" ]]; then
              aws s3api create-bucket --bucket "$BUCKET"
            else
              aws s3api create-bucket \
                --bucket "$BUCKET" \
                --create-bucket-configuration LocationConstraint="${{ env.AWS_DEFAULT_REGION }}"
            fi
            
            # Enable versioning for safety
            aws s3api put-bucket-versioning \
              --bucket "$BUCKET" \
              --versioning-configuration Status=Enabled
            
            echo "‚úÖ Deployment bucket created"
          else
            echo "‚úÖ Deployment bucket exists"
          fi
          
          # Generate secure JWT secret
          JWT_SECRET=$(openssl rand -base64 48)
          
          # Get infrastructure from discovery
          VPC_ID="${{ needs.discover-infrastructure.outputs.vpc-id }}"
          PRIVATE_1="${{ needs.discover-infrastructure.outputs.private-subnet-1 }}"
          PRIVATE_2="${{ needs.discover-infrastructure.outputs.private-subnet-2 }}"
          PUBLIC_1="${{ needs.discover-infrastructure.outputs.public-subnet-1 }}"
          PUBLIC_2="${{ needs.discover-infrastructure.outputs.public-subnet-2 }}"
          
          echo ""
          echo "üîß Deployment Configuration:"
          echo "  VPC:        $VPC_ID"
          echo "  Private 1:  $PRIVATE_1"
          echo "  Private 2:  $PRIVATE_2"
          echo "  Public 1:   ${PUBLIC_1:-<none>}"
          echo "  Public 2:   ${PUBLIC_2:-<none>}"
          
          # Build parameter overrides
          PARAMS=(
            "Stage=prod"
            "JwtSecret=$JWT_SECRET"
            "CorsOrigins=https://yourdomain.com"
            "VpcId=$VPC_ID"
            "PrivateSubnetId1=$PRIVATE_1"
            "PrivateSubnetId2=$PRIVATE_2"
          )
          
          if [[ -n "$PUBLIC_1" ]]; then
            PARAMS+=("PublicSubnetId1=$PUBLIC_1")
          fi
          
          if [[ -n "$PUBLIC_2" ]]; then
            PARAMS+=("PublicSubnetId2=$PUBLIC_2")
          fi
          
          echo ""
          echo "üì¶ Deploying stack with ${#PARAMS[@]} parameters..."
          
          # Deploy with retries
          MAX_DEPLOY_RETRIES=3
          DEPLOY_ATTEMPT=1
          
          while [ $DEPLOY_ATTEMPT -le $MAX_DEPLOY_RETRIES ]; do
            echo "üöÄ Deployment attempt $DEPLOY_ATTEMPT/$MAX_DEPLOY_RETRIES..."
            
            if sam deploy \
              --stack-name "${{ env.STACK_NAME }}" \
              --region ${{ env.AWS_DEFAULT_REGION }} \
              --s3-bucket "$BUCKET" \
              --parameter-overrides "${PARAMS[@]}" \
              --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \
              --no-fail-on-empty-changeset \
              --no-confirm-changeset \
              --on-failure ROLLBACK 2>&1 | tee deploy.log; then
              
              echo "‚úÖ SAM deployment successful"
              echo "deploy_status=success" >> $GITHUB_OUTPUT
              break
            else
              echo "‚ùå Deployment attempt $DEPLOY_ATTEMPT failed"
              
              if [ $DEPLOY_ATTEMPT -lt $MAX_DEPLOY_RETRIES ]; then
                echo "‚è≥ Waiting 30s before retry..."
                sleep 30
              else
                echo "‚ùå All deployment attempts failed"
                echo "deploy_status=failed" >> $GITHUB_OUTPUT
                cat deploy.log || true
                exit 1
              fi
            fi
            
            DEPLOY_ATTEMPT=$((DEPLOY_ATTEMPT + 1))
          done

      - name: üì§ Export Stack Outputs
        id: export-outputs
        run: |
          set -euo pipefail
          STACK="${{ env.STACK_NAME }}"
          
          echo "üì§ Fetching CloudFormation outputs..."
          
          # Wait for stack to be in stable state
          for i in {1..30}; do
            STATUS=$(aws cloudformation describe-stacks \
              --stack-name "$STACK" \
              --query 'Stacks[0].StackStatus' \
              --output text 2>/dev/null || echo "NOT_FOUND")
            
            if [[ "$STATUS" =~ (CREATE_COMPLETE|UPDATE_COMPLETE) ]]; then
              echo "‚úÖ Stack is ready: $STATUS"
              break
            elif [[ "$STATUS" =~ (FAILED|ROLLBACK) ]]; then
              echo "‚ùå Stack in error state: $STATUS"
              exit 1
            fi
            
            echo "‚è≥ Waiting for stack to stabilize... ($i/30)"
            sleep 10
          done
          
          # Get outputs
          API_ENDPOINT=$(aws cloudformation describe-stacks \
            --stack-name "$STACK" \
            --query 'Stacks[0].Outputs[?OutputKey==`ApiEndpoint`].OutputValue' \
            --output text)
          
          SCHEMA_FUNCTION_NAME=$(aws cloudformation describe-stacks \
            --stack-name "$STACK" \
            --query 'Stacks[0].Outputs[?OutputKey==`SchemaInitializerFunctionName`].OutputValue' \
            --output text)
          
          if [[ -z "$API_ENDPOINT" || "$API_ENDPOINT" == "None" ]]; then
            echo "‚ùå API endpoint not found in outputs"
            exit 1
          fi
          
          if [[ -z "$SCHEMA_FUNCTION_NAME" || "$SCHEMA_FUNCTION_NAME" == "None" ]]; then
            echo "‚ùå Schema function name not found in outputs"
            exit 1
          fi
          
          echo "api_endpoint=$API_ENDPOINT" >> $GITHUB_OUTPUT
          echo "schema_function_name=$SCHEMA_FUNCTION_NAME" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Outputs exported:"
          echo "  API Endpoint: $API_ENDPOINT"
          echo "  Schema Function: $SCHEMA_FUNCTION_NAME"
      
      - name: üìä Deployment Status Summary
        id: deploy-status
        run: |
          echo "status=success" >> $GITHUB_OUTPUT
          echo "‚úÖ Deployment phase completed successfully"

  initialize-database:
    name: üóÉÔ∏è Initialize Database Schema
    runs-on: ubuntu-latest
    needs: cleanup-and-deploy
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
      
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: pip install boto3
      
      - name: üóÉÔ∏è Parse SQL Schema File
        id: parse-sql
        run: |
          set -euo pipefail
          
          if [ -f database/rds_schema_update.sql ]; then
            echo "üìÑ Parsing SQL schema file..."
            
            python3 <<'PYEOF'
          import json
          import sys
          
          try:
              with open('database/rds_schema_update.sql', 'r', encoding='utf-8') as f:
                  sql = f.read()
              
              # Split by semicolon and filter out comments and empty statements
              statements = [
                  s.strip() 
                  for s in sql.split(';') 
                  if s.strip() and not s.strip().startswith('--') and len(s.strip()) > 5
              ]
              
              with open('sql_statements.json', 'w') as out:
                  json.dump(statements, out, indent=2)
              
              print(f"‚úÖ Successfully parsed {len(statements)} SQL statements")
              sys.exit(0)
              
          except Exception as e:
              print(f"‚ùå Error parsing SQL file: {str(e)}")
              sys.exit(1)
          PYEOF
            
          else
            echo "‚ö†Ô∏è No SQL schema file found at database/rds_schema_update.sql"
            echo "Using default empty schema"
            echo '[]' > sql_statements.json
          fi
      
      - name: üöÄ Invoke Schema Initializer Lambda
        timeout-minutes: 8
        run: |
          set -euo pipefail
          STACK="${{ env.STACK_NAME }}"
          
          echo "üîç Locating schema initializer Lambda..."
          
          FUNCTION_NAME="${{ needs.cleanup-and-deploy.outputs.schema-function-name }}"
          
          if [[ -z "$FUNCTION_NAME" || "$FUNCTION_NAME" == "None" ]]; then
            echo "‚ùå Schema initializer Lambda function not found"
            echo "Available stack outputs:"
            aws cloudformation describe-stacks \
              --stack-name "$STACK" \
              --query 'Stacks[0].Outputs[].[OutputKey,OutputValue]' \
              --output table
            exit 1
          fi
          
          echo "‚úÖ Found function: $FUNCTION_NAME"
          
          # Verify function exists and is active
          FUNCTION_STATE=$(aws lambda get-function \
            --function-name "$FUNCTION_NAME" \
            --query 'Configuration.State' \
            --output text 2>/dev/null || echo "NOT_FOUND")
          
          if [[ "$FUNCTION_STATE" != "Active" ]]; then
            echo "‚ö†Ô∏è Lambda function state: $FUNCTION_STATE"
            echo "Waiting for function to become active..."
            
            for i in {1..30}; do
              FUNCTION_STATE=$(aws lambda get-function \
                --function-name "$FUNCTION_NAME" \
                --query 'Configuration.State' \
                --output text 2>/dev/null || echo "NOT_FOUND")
              
              if [[ "$FUNCTION_STATE" == "Active" ]]; then
                echo "‚úÖ Function is now active"
                break
              fi
              
              echo "‚è≥ Waiting... ($i/30)"
              sleep 10
            done
          fi
          
          # Load and validate SQL statements
          SQL_STATEMENTS=$(cat sql_statements.json)
          STMT_COUNT=$(echo "$SQL_STATEMENTS" | jq 'length')
          
          echo "üìù Prepared payload with $STMT_COUNT SQL statements"
          
          # Create Lambda payload
          PAYLOAD=$(jq -n --argjson stmts "$SQL_STATEMENTS" '{sql_statements: $stmts}')
          
          # Invoke Lambda with retry
          MAX_RETRIES=3
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "üì§ Invoking schema initializer (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)..."
            
            if aws lambda invoke \
              --function-name "$FUNCTION_NAME" \
              --payload "$PAYLOAD" \
              --cli-binary-format raw-in-base64-out \
              --log-type Tail \
              response.json 2>&1; then
              
              echo "‚úÖ Lambda invocation successful"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚è≥ Retrying in 10 seconds..."
                sleep 10
              else
                echo "‚ùå Lambda invocation failed after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done
          
          # Parse and validate response
          echo ""
          echo "üì• Lambda Response:"
          cat response.json | jq '.' || cat response.json
          
          # Check for Lambda execution errors
          if jq -e '.errorMessage' response.json >/dev/null 2>&1; then
            echo ""
            echo "‚ùå Lambda execution error:"
            jq -r '.errorMessage' response.json
            exit 1
          fi
          
          # Parse response body
          BODY=$(jq -r '.body' response.json 2>/dev/null || echo "null")
          
          if [[ "$BODY" == "null" || -z "$BODY" ]]; then
            echo "‚ùå No response body returned from Lambda"
            exit 1
          fi
          
          # Extract execution summary
          SUCCESS=$(echo "$BODY" | jq -r '.success // false')
          ERRORS=$(echo "$BODY" | jq -r '.summary.errors // 0')
          EXECUTED=$(echo "$BODY" | jq -r '.summary.executed // 0')
          SKIPPED=$(echo "$BODY" | jq -r '.summary.skipped // 0')
          TOTAL=$(echo "$BODY" | jq -r '.summary.total // 0')
          
          echo ""
          echo "üìä Schema Initialization Summary:"
          echo "  ‚úÖ Executed: $EXECUTED"
          echo "  ‚è≠Ô∏è  Skipped:  $SKIPPED (already exists)"
          echo "  ‚ùå Errors:   $ERRORS"
          echo "  üìä Total:    $TOTAL"
          
          # Determine overall success
          if [[ "$SUCCESS" == "true" ]]; then
            echo ""
            echo "‚úÖ Schema initialization completed successfully!"
            exit 0
          elif [[ "$EXECUTED" -gt 0 && "$ERRORS" -le 10 ]]; then
            echo ""
            echo "‚úÖ Schema initialization completed (errors are likely duplicates)"
            exit 0
          elif [[ "$EXECUTED" -lt 3 && "$ERRORS" -gt 10 ]]; then
            echo ""
            echo "‚ùå Critical schema initialization failure"
            echo ""
            echo "Detailed errors:"
            echo "$BODY" | jq '.results[] | select(.status == "error")'
            exit 1
          else
            echo ""
            echo "‚ö†Ô∏è Schema initialization completed with warnings"
            echo "Proceeding with deployment..."
            exit 0
          fi

  deploy-frontend:
    name: üåê Deploy Frontend
    runs-on: ubuntu-latest
    needs: [cleanup-and-deploy, initialize-database]
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4
      
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
      
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      
      - name: üì¶ Install Dependencies with retry
        run: |
          set -euo pipefail
          cd frontend
          
          echo "üì¶ Installing frontend dependencies..."
          
          # Try npm ci first (fastest)
          if [[ -f package-lock.json ]]; then
            echo "Attempting npm ci..."
            if npm ci 2>&1; then
              echo "‚úÖ npm ci succeeded"
              exit 0
            fi
            
            echo "‚ö†Ô∏è npm ci failed, trying with legacy peer deps..."
            rm -rf node_modules
            
            if npm ci --legacy-peer-deps 2>&1; then
              echo "‚úÖ npm ci --legacy-peer-deps succeeded"
              exit 0
            fi
            
            echo "‚ö†Ô∏è npm ci --legacy-peer-deps failed, using npm install..."
            rm -rf node_modules package-lock.json
          fi
          
          # Fallback to npm install
          if npm install --legacy-peer-deps 2>&1; then
            echo "‚úÖ npm install succeeded"
          else
            echo "‚ùå All npm install attempts failed"
            exit 1
          fi
          
          # Generate lockfile for next time
          if [[ ! -f package-lock.json ]]; then
            npm install --package-lock-only
          fi
      
      - name: üèóÔ∏è Build React Application
        run: |
          set -euo pipefail
          cd frontend
          
          echo "üèóÔ∏è Building React application for production..."
          
          # Create environment file
          API_ENDPOINT="${{ needs.cleanup-and-deploy.outputs.api-endpoint }}"
          
          if [[ -z "$API_ENDPOINT" || "$API_ENDPOINT" == "None" ]]; then
            echo "‚ùå API endpoint not available"
            exit 1
          fi
          
          cat > .env.production << EOF
          REACT_APP_API_URL=$API_ENDPOINT
          REACT_APP_STAGE=prod
          REACT_APP_VERSION=$(date +%Y%m%d-%H%M%S)
          EOF
          
          echo "üìã Build configuration:"
          cat .env.production
          
          # Build with production optimizations
          if CI=false npm run build; then
            echo "‚úÖ Build successful"
            
            # Verify build output
            if [[ ! -d build ]]; then
              echo "‚ùå Build directory not found"
              exit 1
            fi
            
            if [[ ! -f build/index.html ]]; then
              echo "‚ùå index.html not found in build"
              exit 1
            fi
            
            echo "üìä Build size:"
            du -sh build/
          else
            echo "‚ùå Build failed"
            exit 1
          fi
      
      - name: üöÄ Deploy to S3 with CDN optimization
        run: |
          set -euo pipefail
          FRONTEND_BUCKET="${{ env.STACK_NAME }}-frontend"
          
          echo "ü™£ Deploying to S3 bucket: $FRONTEND_BUCKET"
          
          # Create bucket if needed
          if ! aws s3api head-bucket --bucket "$FRONTEND_BUCKET" 2>/dev/null; then
            echo "üÜï Creating S3 bucket..."
            
            if [[ "${{ env.AWS_DEFAULT_REGION }}" == "us-east-1" ]]; then
              aws s3api create-bucket --bucket "$FRONTEND_BUCKET"
            else
              aws s3api create-bucket \
                --bucket "$FRONTEND_BUCKET" \
                --create-bucket-configuration LocationConstraint="${{ env.AWS_DEFAULT_REGION }}"
            fi
          fi
          
          # Upload static assets with long cache
          echo "üì§ Uploading static assets..."
          aws s3 sync frontend/build/ "s3://$FRONTEND_BUCKET" \
            --delete \
            --cache-control "public,max-age=31536000,immutable" \
            --exclude "*.html" \
            --exclude "service-worker.js" \
            --exclude "asset-manifest.json"
          
          # Upload HTML files with no-cache
          echo "üì§ Uploading HTML files..."
          aws s3 sync frontend/build/ "s3://$FRONTEND_BUCKET" \
            --exclude "*" \
            --include "*.html" \
            --include "service-worker.js" \
            --include "asset-manifest.json" \
            --cache-control "no-cache,no-store,must-revalidate"
          
          # Configure website hosting
          echo "üåê Configuring static website hosting..."
          aws s3api put-bucket-website \
            --bucket "$FRONTEND_BUCKET" \
            --website-configuration '{
              "IndexDocument": {"Suffix": "index.html"},
              "ErrorDocument": {"Key": "index.html"}
            }'
          
          # Set bucket policy for public access
          echo "üîì Setting public access policy..."
          aws s3api put-bucket-policy \
            --bucket "$FRONTEND_BUCKET" \
            --policy '{
              "Version": "2012-10-17",
              "Statement": [{
                "Sid": "PublicReadGetObject",
                "Effect": "Allow",
                "Principal": "*",
                "Action": "s3:GetObject",
                "Resource": "arn:aws:s3:::'$FRONTEND_BUCKET'/*"
              }]
            }'
          
          # Disable block public access
          aws s3api put-public-access-block \
            --bucket "$FRONTEND_BUCKET" \
            --public-access-block-configuration \
            "BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false"
          
          WEBSITE_URL="http://$FRONTEND_BUCKET.s3-website-${{ env.AWS_DEFAULT_REGION }}.amazonaws.com"
          
          echo ""
          echo "‚úÖ Frontend deployment successful!"
          echo "üåê Website URL: $WEBSITE_URL"

  smoke-tests:
    name: üß™ Smoke Tests & Validation
    runs-on: ubuntu-latest
    needs: [cleanup-and-deploy, initialize-database, deploy-frontend]
    timeout-minutes: 10
    steps:
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: üß™ Comprehensive Smoke Tests
        env:
          API_ENDPOINT: ${{ needs.cleanup-and-deploy.outputs.api-endpoint }}
        run: |
          set -euo pipefail
          
          echo "üß™ Starting comprehensive smoke tests"
          echo "API Endpoint: $API_ENDPOINT"
          echo "======================================"
          
          # Test 1: Health Check with retry
          echo ""
          echo "üè• Test 1: API Health Check"
          RETRY_COUNT=0
          MAX_RETRIES=24  # 4 minutes max
          RETRY_DELAY=10
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if curl -sf "${API_ENDPOINT}/health" -o health_response.txt 2>/dev/null; then
              echo "‚úÖ Health check passed (attempt $((RETRY_COUNT + 1)))"
              
              # Validate JSON response
              if python3 -m json.tool < health_response.txt >/dev/null 2>&1; then
                echo "‚úÖ Valid JSON response"
                cat health_response.txt | python3 -m json.tool
              fi
              
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚è≥ Health check failed, retry $RETRY_COUNT/$MAX_RETRIES in ${RETRY_DELAY}s..."
                sleep $RETRY_DELAY
              else
                echo "‚ö†Ô∏è Health check timeout after $MAX_RETRIES attempts"
                echo "‚ö†Ô∏è This is non-fatal - API may still be warming up"
              fi
            fi
          done
          
          # Test 2: API Gateway Connectivity
          echo ""
          echo "üåê Test 2: API Gateway Status"
          if curl -I "${API_ENDPOINT}/health" 2>/dev/null | head -1; then
            echo "‚úÖ API Gateway is responding"
          else
            echo "‚ö†Ô∏è API Gateway check inconclusive"
          fi
          
          # Test 3: Frontend Accessibility
          echo ""
          echo "üåê Test 3: Frontend Website"
          FRONTEND_URL="http://${{ env.STACK_NAME }}-frontend.s3-website-${{ env.AWS_DEFAULT_REGION }}.amazonaws.com"
          
          if curl -sf "$FRONTEND_URL" >/dev/null 2>&1; then
            echo "‚úÖ Frontend is accessible at: $FRONTEND_URL"
          else
            echo "‚ö†Ô∏è Frontend may still be propagating"
          fi
          
          echo ""
          echo "‚úÖ Smoke tests completed"

  deployment-summary:
    name: üìä Deployment Summary
    runs-on: ubuntu-latest
    needs: [cleanup-and-deploy, discover-infrastructure, initialize-database, deploy-frontend, smoke-tests]
    if: always()
    steps:
      - name: üéâ Generate Deployment Report
        run: |
          echo "üéÜ ============================================================"
          echo "üéÜ  PRODUCTION DEPLOYMENT COMPLETE"
          echo "üéÜ ============================================================"
          echo ""
          echo "üìä Deployment Summary:"
          echo "  Stack Name:          ${{ env.STACK_NAME }}"
          echo "  Region:              ${{ env.AWS_DEFAULT_REGION }}"
          echo "  Timestamp:           $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo ""
          echo "üèóÔ∏è Infrastructure:"
          echo "  VPC ID:              ${{ needs.discover-infrastructure.outputs.vpc-id }}"
          echo "  Private Subnet 1:    ${{ needs.discover-infrastructure.outputs.private-subnet-1 }}"
          echo "  Private Subnet 2:    ${{ needs.discover-infrastructure.outputs.private-subnet-2 }}"
          echo "  Public Subnet 1:     ${{ needs.discover-infrastructure.outputs.public-subnet-1 }}"
          echo "  Public Subnet 2:     ${{ needs.discover-infrastructure.outputs.public-subnet-2 }}"
          echo ""
          echo "üîó Endpoints:"
          echo "  API Endpoint:        ${{ needs.cleanup-and-deploy.outputs.api-endpoint }}"
          echo "  API Health:          ${{ needs.cleanup-and-deploy.outputs.api-endpoint }}/health"
          echo "  Frontend:            http://${{ env.STACK_NAME }}-frontend.s3-website-${{ env.AWS_DEFAULT_REGION }}.amazonaws.com"
          echo "  Schema Function:     ${{ needs.cleanup-and-deploy.outputs.schema-function-name }}"
          echo ""
          echo "‚úÖ Deployed Components:"
          echo "  ‚úÖ CloudFormation Stack"
          echo "  ‚úÖ API Gateway"
          echo "  ‚úÖ Lambda Functions (VPC-enabled)"
          echo "  ‚úÖ Step Functions (Migration, Audit, Export)"
          echo "  ‚úÖ DynamoDB Tables (Cloud Storage)"
          echo "  ‚úÖ RDS MySQL 8.0 (Legacy Database)"
          echo "  ‚úÖ VPC Endpoints (Secure connectivity)"
          echo "  ‚úÖ Security Groups"
          echo "  ‚úÖ Secrets Manager"
          echo "  ‚úÖ S3 Buckets (Frontend + Uploads)"
          echo "  ‚úÖ CloudWatch Logs"
          echo "  ‚úÖ React Frontend"
          echo ""
          echo "üéØ Deployment Status:"
          
          # Check all job statuses
          CLEANUP_STATUS="${{ needs.cleanup-and-deploy.result }}"
          DB_STATUS="${{ needs.initialize-database.result }}"
          FRONTEND_STATUS="${{ needs.deploy-frontend.result }}"
          SMOKE_STATUS="${{ needs.smoke-tests.result }}"
          
          echo "  Cleanup & Deploy:    $CLEANUP_STATUS"
          echo "  Database Init:       $DB_STATUS"
          echo "  Frontend Deploy:     $FRONTEND_STATUS"
          echo "  Smoke Tests:         $SMOKE_STATUS"
          echo ""
          
          if [[ "$CLEANUP_STATUS" == "success" ]] && \
             [[ "$DB_STATUS" == "success" ]] && \
             [[ "$FRONTEND_STATUS" == "success" ]]; then
            echo "üéâ ============================================================"
            echo "üéâ  DEPLOYMENT SUCCESSFUL - ALL SYSTEMS OPERATIONAL"
            echo "üéâ ============================================================"
            exit 0
          elif [[ "$CLEANUP_STATUS" == "success" ]]; then
            echo "‚ö†Ô∏è ============================================================"
            echo "‚ö†Ô∏è  INFRASTRUCTURE DEPLOYED - MINOR ISSUES DETECTED"
            echo "‚ö†Ô∏è ============================================================"
            echo ""
            echo "üõ†Ô∏è Troubleshooting:"
            echo "  1. Check CloudWatch Logs for detailed error messages"
            echo "  2. Verify RDS database connectivity from VPC"
            echo "  3. Check Lambda function IAM permissions"
            echo "  4. Validate VPC endpoint configurations"
            echo "  5. Review Step Functions execution history"
            exit 0
          else
            echo "‚ùå ============================================================"
            echo "‚ùå  DEPLOYMENT FAILED - REVIEW LOGS"
            echo "‚ùå ============================================================"
            exit 1
          fi

permissions:
  contents: read
  id-token: write