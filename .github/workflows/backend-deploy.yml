name: Backend - Build & Deploy (Lambda)

on:
  push:
    branches: [ "main" ]
    paths:
      - "backend/**"
      - ".github/workflows/backend-deploy.yml"
      - "infrastructure/**"
  workflow_dispatch:
    inputs:
      force_recreate:
        description: 'Force recreate stack (true/false)'
        required: false
        default: 'false'
        type: choice
        options: ['false','true']
      cleanup_failed:
        description: 'Cleanup failed resources (true/false)'
        required: false
        default: 'false'
        type: choice
        options: ['false','true']

permissions:
  contents: read
  id-token: write

env:
  AWS_REGION: ${{ vars.AWS_REGION || 'us-east-1' }}
  LAMBDA_FUNCTION_NAME: ${{ vars.LAMBDA_FUNCTION_NAME }}
  API_GATEWAY_ID: ${{ vars.API_GATEWAY_ID }}
  API_BASE_URL: https://${{ vars.API_GATEWAY_ID }}.execute-api.${{ vars.AWS_REGION || 'us-east-1' }}.amazonaws.com/prod
  PYTHON_VERSION: "3.11"
  FORCE_RECREATE: ${{ inputs.force_recreate || vars.FORCE_RECREATE || 'false' }}
  CLEANUP_FAILED: ${{ inputs.cleanup_failed || vars.CLEANUP_FAILED || 'false' }}

jobs:
  prepare-infra:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ vars.AWS_ROLE_ARN || '' }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Resolve resource names
        id: names
        run: |
          echo "SUB_TABLE=${{ vars.SUBSCRIBER_TABLE_NAME || 'subscriber-table' }}" >> $GITHUB_OUTPUT
          echo "MIG_TABLE=${{ vars.MIGRATION_JOBS_TABLE_NAME || 'migration-jobs-table' }}" >> $GITHUB_OUTPUT
          echo "AUD_TABLE=${{ vars.AUDIT_LOG_TABLE_NAME || 'audit-log-table' }}" >> $GITHUB_OUTPUT
          echo "FRONTEND_BUCKET=${{ vars.S3_FRONTEND_BUCKET || '' }}" >> $GITHUB_OUTPUT
          echo "UPLOAD_BUCKET=${{ vars.MIGRATION_UPLOAD_BUCKET_NAME || '' }}" >> $GITHUB_OUTPUT
          echo "STACK_NAME=${{ vars.CF_STACK_NAME || 'subscriber-migration-stack' }}" >> $GITHUB_OUTPUT

      - name: Cleanup failed CloudFormation stacks (optional)
        if: env.CLEANUP_FAILED == 'true'
        run: |
          set -e
          STACK="${{ steps.names.outputs.STACK_NAME }}"
          STATUS=$(aws cloudformation describe-stacks --stack-name "$STACK" --query 'Stacks[0].StackStatus' --output text 2>/dev/null || echo 'NONE')
          echo "Current stack status: $STATUS"
          case "$STATUS" in
            DELETE_FAILED|ROLLBACK_COMPLETE|ROLLBACK_FAILED|CREATE_FAILED)
              echo "Deleting failed stack $STACK"
              aws cloudformation delete-stack --stack-name "$STACK"
              aws cloudformation wait stack-delete-complete --stack-name "$STACK" || true
              ;;
            *)
              echo "No failed stack deletion required"
              ;;
          esac

      - name: Cleanup orphaned resources (optional)
        if: env.CLEANUP_FAILED == 'true'
        run: |
          set -e
          # DynamoDB tables
          for T in "${{ steps.names.outputs.SUB_TABLE }}" "${{ steps.names.outputs.MIG_TABLE }}" "${{ steps.names.outputs.AUD_TABLE }}"; do
            if [ -n "$T" ] && aws dynamodb describe-table --table-name "$T" >/dev/null 2>&1; then
              echo "Deleting DynamoDB table $T"
              aws dynamodb delete-table --table-name "$T"
              aws dynamodb wait table-not-exists --table-name "$T"
            fi
          done
          # S3 buckets
          for B in "${{ steps.names.outputs.FRONTEND_BUCKET }}" "${{ steps.names.outputs.UPLOAD_BUCKET }}"; do
            if [ -n "$B" ] && aws s3api head-bucket --bucket "$B" 2>/dev/null; then
              echo "Emptying and deleting S3 bucket $B"
              aws s3 rm "s3://$B" --recursive || true
              aws s3api delete-bucket --bucket "$B" || true
            fi
          done
          # Step Functions state machines (name prefix)
          for ARN in $(aws stepfunctions list-state-machines --query "stateMachines[?starts_with(name, 'subscriber-migration')].stateMachineArn" --output text); do
            echo "Deleting state machine $ARN"
            aws stepfunctions delete-state-machine --state-machine-arn "$ARN" || true
          done
          # SQS queues (name prefix)
          for URL in $(aws sqs list-queues --queue-name-prefix "subscriber-migration" --query 'QueueUrls[]' --output text); do
            echo "Deleting SQS queue $URL"
            aws sqs delete-queue --queue-url "$URL" || true
          done

      - name: Force recreate stack (optional)
        if: env.FORCE_RECREATE == 'true'
        run: |
          set -e
          STACK="${{ steps.names.outputs.STACK_NAME }}"
          echo "Force re-creating $STACK"
          if aws cloudformation describe-stacks --stack-name "$STACK" >/dev/null 2>&1; then
            aws cloudformation delete-stack --stack-name "$STACK"
            aws cloudformation wait stack-delete-complete --stack-name "$STACK" || true
          fi
          if [ -f infrastructure/cloudformation/stack.yaml ]; then
            aws cloudformation deploy \
              --template-file infrastructure/cloudformation/stack.yaml \
              --stack-name "$STACK" \
              --capabilities CAPABILITY_NAMED_IAM \
              --parameter-overrides \
                SubscriberTableName=${{ steps.names.outputs.SUB_TABLE }} \
                MigrationJobsTableName=${{ steps.names.outputs.MIG_TABLE }} \
                AuditLogTableName=${{ steps.names.outputs.AUD_TABLE }}
          else
            echo "No CloudFormation template found, skipping provisioning"
          fi

  build-test-package:
    needs: prepare-infra
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install backend deps
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest flake8 bandit safety

      - name: Lint
        working-directory: backend
        run: flake8 --max-line-length 120 .

      - name: Security scan (bandit)
        working-directory: backend
        run: bandit -q -r . || true

      - name: Dependency audit (safety)
        working-directory: backend
        run: safety check --full-report || true

      - name: Run tests
        working-directory: backend
        run: pytest -q

      - name: Package Lambda artifact
        working-directory: backend
        run: |
          mkdir -p build
          pip install -r requirements.txt -t build/
          cp -R src build/src || true
          cp app.py build/
          cd build && zip -r ../lambda.zip .

      - uses: actions/upload-artifact@v4
        with:
          name: lambda-zip
          path: backend/lambda.zip

  deploy:
    needs: build-test-package
    runs-on: ubuntu-latest
    environment: production
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: lambda-zip
          path: dist

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ vars.AWS_ROLE_ARN || '' }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Ensure Lambda env vars
        run: |
          aws lambda update-function-configuration \
            --function-name "$LAMBDA_FUNCTION_NAME" \
            --environment "Variables={SUBSCRIBER_TABLE_NAME=${{ vars.SUBSCRIBER_TABLE_NAME || 'subscriber-table' }},MIGRATION_JOBS_TABLE_NAME=${{ vars.MIGRATION_JOBS_TABLE_NAME || 'migration-jobs-table' }},AUDIT_LOG_TABLE_NAME=${{ vars.AUDIT_LOG_TABLE_NAME || 'audit-log-table' }},PROVISIONING_MODES=legacy,cloud,dual_prov,JWT_SECRET=${{ secrets.JWT_SECRET || 'change-me' }},USERS_SECRET_ARN=${{ secrets.USERS_SECRET_ARN || '' }},LEGACY_DB_SECRET_ARN=${{ secrets.LEGACY_DB_SECRET_ARN || '' }}}" || true

      - name: Capture previous alias version
        id: prev
        run: |
          set -e
          PREV=$(aws lambda get-alias --function-name "$LAMBDA_FUNCTION_NAME" --name prod --query 'FunctionVersion' --output text 2>/dev/null || echo "0")
          echo "prev=$PREV" >> $GITHUB_OUTPUT

      - name: Update Lambda code
        run: |
          aws lambda update-function-code \
            --function-name "$LAMBDA_FUNCTION_NAME" \
            --zip-file "fileb://dist/lambda.zip"
          aws lambda wait function-updated --function-name "$LAMBDA_FUNCTION_NAME"

      - name: Publish new Lambda version
        id: publish
        run: |
          VERSION=$(aws lambda publish-version --function-name "$LAMBDA_FUNCTION_NAME" --query 'Version' --output text)
          echo "VERSION=$VERSION" >> $GITHUB_OUTPUT

      - name: Shift alias to new version (blue/green)
        run: |
          if ! aws lambda get-alias --function-name "$LAMBDA_FUNCTION_NAME" --name prod >/dev/null 2>&1; then
            aws lambda create-alias --function-name "$LAMBDA_FUNCTION_NAME" --name prod --function-version "${{ steps.publish.outputs.VERSION }}"
          else
            aws lambda update-alias --function-name "$LAMBDA_FUNCTION_NAME" --name prod --function-version "${{ steps.publish.outputs.VERSION }}"
          fi

      - name: Smoke tests
        run: |
          set -e
          BASE="$API_BASE_URL"
          curl -fsS "$BASE/api/health"
          TOKEN=$(curl -fsS -X POST "$BASE/api/auth/login" -H "Content-Type: application/json" -d '{"username":"admin","password":"Admin@123"}' | jq -r '.token')
          test -n "$TOKEN"
          curl -fsS "$BASE/api/subscribers/stats" -H "Authorization: Bearer $TOKEN"

      - name: Done
        run: echo "Backend deployed successfully"
